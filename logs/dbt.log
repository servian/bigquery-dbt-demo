2020-05-24 13:06:57.523689 (MainThread): Running with dbt=0.16.1
2020-05-24 13:06:57.894637 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-24 13:06:57.896294 (MainThread): Tracking: tracking
2020-05-24 13:06:57.902969 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ba3b400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ba4c5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ba4c580>]}
2020-05-24 13:06:57.926481 (MainThread): Partial parsing not enabled
2020-05-24 13:06:57.929351 (MainThread): Parsing macros/core.sql
2020-05-24 13:06:57.935947 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-24 13:06:57.944726 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-24 13:06:57.946897 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-24 13:06:57.963503 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-24 13:06:57.997556 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-24 13:06:58.019249 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-24 13:06:58.021602 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-24 13:06:58.028721 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-24 13:06:58.041775 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-24 13:06:58.048573 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-24 13:06:58.055120 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-24 13:06:58.060239 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-24 13:06:58.061411 (MainThread): Parsing macros/etc/query.sql
2020-05-24 13:06:58.063450 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-24 13:06:58.065997 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-24 13:06:58.069132 (MainThread): Parsing macros/etc/datetime.sql
2020-05-24 13:06:58.079599 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-24 13:06:58.082047 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-24 13:06:58.083684 (MainThread): Parsing macros/adapters/common.sql
2020-05-24 13:06:58.125433 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-24 13:06:58.126837 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-24 13:06:58.127985 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-24 13:06:58.129656 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-24 13:06:58.132488 (MainThread): Parsing macros/etc.sql
2020-05-24 13:06:58.133714 (MainThread): Parsing macros/catalog.sql
2020-05-24 13:06:58.142229 (MainThread): Parsing macros/adapters.sql
2020-05-24 13:06:58.164741 (MainThread): Parsing macros/materializations/seed.sql
2020-05-24 13:06:58.166879 (MainThread): Parsing macros/materializations/view.sql
2020-05-24 13:06:58.168829 (MainThread): Parsing macros/materializations/table.sql
2020-05-24 13:06:58.178706 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-24 13:06:58.191006 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-24 13:06:58.209316 (MainThread): Partial parsing not enabled
2020-05-24 13:06:58.239504 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.data_by_reigon".
2020-05-24 13:06:58.239631 (MainThread): Opening a new connection, currently in state init
2020-05-24 13:06:58.253687 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.total_reigons".
2020-05-24 13:06:58.253808 (MainThread): Opening a new connection, currently in state closed
2020-05-24 13:06:58.308023 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bbd5460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bd4ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bd49070>]}
2020-05-24 13:06:58.308243 (MainThread): Flushing usage events
2020-05-24 13:06:59.571526 (MainThread): Connection 'model.dbt_servian_demo.total_reigons' was properly closed.
2020-05-24 13:06:59.571820 (MainThread): Encountered an error:
2020-05-24 13:06:59.572025 (MainThread): Compilation Error in model total_reigons (models/covid_19_italy_insights/total_reigons.sql)
  Model 'model.dbt_servian_demo.total_reigons' (models/covid_19_italy_insights/total_reigons.sql) depends on source 'covid19_italy.data_by_reigon' which was not found
2020-05-24 13:06:59.579204 (MainThread): Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 338, in load_all
    manifest = loader.create_manifest()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 323, in create_manifest
    self.process_manifest(manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 301, in process_manifest
    process_sources(manifest, project_name)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 587, in process_sources
    _process_sources_for_node(manifest, current_project, node)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 572, in _process_sources_for_node
    dbt.utils.invalid_source_fail_unless_test(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/utils.py", line 347, in invalid_source_fail_unless_test
    dbt.exceptions.source_target_not_found(node, target_name,
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/exceptions.py", line 502, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model total_reigons (models/covid_19_italy_insights/total_reigons.sql)
  Model 'model.dbt_servian_demo.total_reigons' (models/covid_19_italy_insights/total_reigons.sql) depends on source 'covid19_italy.data_by_reigon' which was not found

2020-05-24 13:08:28.544245 (MainThread): Running with dbt=0.16.1
2020-05-24 13:08:29.212924 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-24 13:08:29.214102 (MainThread): Tracking: tracking
2020-05-24 13:08:29.222345 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118b2ef70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118b40640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118b40610>]}
2020-05-24 13:08:29.245935 (MainThread): Partial parsing not enabled
2020-05-24 13:08:29.248156 (MainThread): Parsing macros/core.sql
2020-05-24 13:08:29.254240 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-24 13:08:29.263253 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-24 13:08:29.265536 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-24 13:08:29.282653 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-24 13:08:29.317027 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-24 13:08:29.338659 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-24 13:08:29.341159 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-24 13:08:29.348097 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-24 13:08:29.362200 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-24 13:08:29.368988 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-24 13:08:29.375145 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-24 13:08:29.380123 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-24 13:08:29.381246 (MainThread): Parsing macros/etc/query.sql
2020-05-24 13:08:29.382799 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-24 13:08:29.384862 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-24 13:08:29.387205 (MainThread): Parsing macros/etc/datetime.sql
2020-05-24 13:08:29.396647 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-24 13:08:29.398940 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-24 13:08:29.400518 (MainThread): Parsing macros/adapters/common.sql
2020-05-24 13:08:29.442432 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-24 13:08:29.444008 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-24 13:08:29.445264 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-24 13:08:29.446941 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-24 13:08:29.449790 (MainThread): Parsing macros/etc.sql
2020-05-24 13:08:29.450846 (MainThread): Parsing macros/catalog.sql
2020-05-24 13:08:29.459394 (MainThread): Parsing macros/adapters.sql
2020-05-24 13:08:29.480637 (MainThread): Parsing macros/materializations/seed.sql
2020-05-24 13:08:29.482760 (MainThread): Parsing macros/materializations/view.sql
2020-05-24 13:08:29.484680 (MainThread): Parsing macros/materializations/table.sql
2020-05-24 13:08:29.494847 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-24 13:08:29.508519 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-24 13:08:29.527016 (MainThread): Partial parsing not enabled
2020-05-24 13:08:29.557935 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.data_by_reigon".
2020-05-24 13:08:29.558073 (MainThread): Opening a new connection, currently in state init
2020-05-24 13:08:29.571896 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.total_reigons".
2020-05-24 13:08:29.571994 (MainThread): Opening a new connection, currently in state closed
2020-05-24 13:08:29.628016 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118cc84f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118e44ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118d91f40>]}
2020-05-24 13:08:29.628240 (MainThread): Flushing usage events
2020-05-24 13:08:30.635821 (MainThread): Connection 'model.dbt_servian_demo.total_reigons' was properly closed.
2020-05-24 13:08:30.636083 (MainThread): Encountered an error:
2020-05-24 13:08:30.636282 (MainThread): Compilation Error in model total_reigons (models/covid_19_italy_insights/total_reigons.sql)
  Model 'model.dbt_servian_demo.total_reigons' (models/covid_19_italy_insights/total_reigons.sql) depends on source 'bigquery-public-data.covid19_italy.data_by_reigon' which was not found
2020-05-24 13:08:30.643813 (MainThread): Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 338, in load_all
    manifest = loader.create_manifest()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 323, in create_manifest
    self.process_manifest(manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 301, in process_manifest
    process_sources(manifest, project_name)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 587, in process_sources
    _process_sources_for_node(manifest, current_project, node)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 572, in _process_sources_for_node
    dbt.utils.invalid_source_fail_unless_test(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/utils.py", line 347, in invalid_source_fail_unless_test
    dbt.exceptions.source_target_not_found(node, target_name,
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/exceptions.py", line 502, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model total_reigons (models/covid_19_italy_insights/total_reigons.sql)
  Model 'model.dbt_servian_demo.total_reigons' (models/covid_19_italy_insights/total_reigons.sql) depends on source 'bigquery-public-data.covid19_italy.data_by_reigon' which was not found

2020-05-24 13:22:27.281767 (MainThread): Running with dbt=0.16.1
2020-05-24 13:22:28.035470 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-24 13:22:28.036802 (MainThread): Tracking: tracking
2020-05-24 13:22:28.045738 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b5dbee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b5ec5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b5ec580>]}
2020-05-24 13:22:28.068194 (MainThread): Partial parsing not enabled
2020-05-24 13:22:28.071053 (MainThread): Parsing macros/core.sql
2020-05-24 13:22:28.076497 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-24 13:22:28.085434 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-24 13:22:28.088046 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-24 13:22:28.105856 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-24 13:22:28.140053 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-24 13:22:28.161608 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-24 13:22:28.163742 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-24 13:22:28.169761 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-24 13:22:28.182634 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-24 13:22:28.189824 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-24 13:22:28.196089 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-24 13:22:28.201036 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-24 13:22:28.202174 (MainThread): Parsing macros/etc/query.sql
2020-05-24 13:22:28.203684 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-24 13:22:28.205964 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-24 13:22:28.208682 (MainThread): Parsing macros/etc/datetime.sql
2020-05-24 13:22:28.218017 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-24 13:22:28.220310 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-24 13:22:28.221911 (MainThread): Parsing macros/adapters/common.sql
2020-05-24 13:22:28.263126 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-24 13:22:28.264470 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-24 13:22:28.265640 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-24 13:22:28.267256 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-24 13:22:28.270071 (MainThread): Parsing macros/etc.sql
2020-05-24 13:22:28.271075 (MainThread): Parsing macros/catalog.sql
2020-05-24 13:22:28.279336 (MainThread): Parsing macros/adapters.sql
2020-05-24 13:22:28.300428 (MainThread): Parsing macros/materializations/seed.sql
2020-05-24 13:22:28.302547 (MainThread): Parsing macros/materializations/view.sql
2020-05-24 13:22:28.304497 (MainThread): Parsing macros/materializations/table.sql
2020-05-24 13:22:28.314330 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-24 13:22:28.326812 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-24 13:22:28.345102 (MainThread): Partial parsing not enabled
2020-05-24 13:22:28.375774 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.total_reigons".
2020-05-24 13:22:28.375907 (MainThread): Opening a new connection, currently in state init
2020-05-24 13:22:28.595954 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 1 source
2020-05-24 13:22:28.597354 (MainThread): 
2020-05-24 13:22:28.597518 (MainThread): 23:22:28 | Concurrency: 1 threads (target='dev')
2020-05-24 13:22:28.597638 (MainThread): 23:22:28 | 
2020-05-24 13:22:28.601513 (Thread-1): Began running node model.dbt_servian_demo.total_reigons
2020-05-24 13:22:28.601912 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.total_reigons".
2020-05-24 13:22:28.602022 (Thread-1): Opening a new connection, currently in state init
2020-05-24 13:22:28.602126 (Thread-1): Compiling model.dbt_servian_demo.total_reigons
2020-05-24 13:22:28.618738 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.total_reigons"
2020-05-24 13:22:28.619360 (Thread-1): finished collecting timing info
2020-05-24 13:22:28.619641 (Thread-1): finished collecting timing info
2020-05-24 13:22:28.620056 (Thread-1): Finished running node model.dbt_servian_demo.total_reigons
2020-05-24 13:22:28.620805 (MainThread): Connection 'model.dbt_servian_demo.total_reigons' was properly closed.
2020-05-24 13:22:28.620920 (MainThread): Connection 'model.dbt_servian_demo.total_reigons' was properly closed.
2020-05-24 13:22:28.623846 (MainThread): 23:22:28 | Done.
2020-05-24 13:22:28.624028 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b845be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b8ae3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b8ae070>]}
2020-05-24 13:22:28.624238 (MainThread): Flushing usage events
2020-05-24 13:23:23.280660 (MainThread): Running with dbt=0.16.1
2020-05-24 13:23:23.643293 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-24 13:23:23.643891 (MainThread): Tracking: tracking
2020-05-24 13:23:23.650027 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a372f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a3875e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a3875b0>]}
2020-05-24 13:23:23.670689 (MainThread): Partial parsing not enabled
2020-05-24 13:23:23.672406 (MainThread): Parsing macros/core.sql
2020-05-24 13:23:23.676854 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-24 13:23:23.686242 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-24 13:23:23.688019 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-24 13:23:23.703914 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-24 13:23:23.736514 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-24 13:23:23.757227 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-24 13:23:23.759087 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-24 13:23:23.765049 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-24 13:23:23.778093 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-24 13:23:23.784537 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-24 13:23:23.790597 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-24 13:23:23.795263 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-24 13:23:23.796178 (MainThread): Parsing macros/etc/query.sql
2020-05-24 13:23:23.797179 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-24 13:23:23.798721 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-24 13:23:23.800677 (MainThread): Parsing macros/etc/datetime.sql
2020-05-24 13:23:23.809212 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-24 13:23:23.811085 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-24 13:23:23.812097 (MainThread): Parsing macros/adapters/common.sql
2020-05-24 13:23:23.853136 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-24 13:23:23.854275 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-24 13:23:23.855148 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-24 13:23:23.856209 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-24 13:23:23.858445 (MainThread): Parsing macros/etc.sql
2020-05-24 13:23:23.859087 (MainThread): Parsing macros/catalog.sql
2020-05-24 13:23:23.866552 (MainThread): Parsing macros/adapters.sql
2020-05-24 13:23:23.887079 (MainThread): Parsing macros/materializations/seed.sql
2020-05-24 13:23:23.888914 (MainThread): Parsing macros/materializations/view.sql
2020-05-24 13:23:23.890268 (MainThread): Parsing macros/materializations/table.sql
2020-05-24 13:23:23.899209 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-24 13:23:23.910662 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-24 13:23:23.928440 (MainThread): Partial parsing not enabled
2020-05-24 13:23:23.957412 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.total_reigons".
2020-05-24 13:23:23.957522 (MainThread): Opening a new connection, currently in state init
2020-05-24 13:23:24.168461 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 1 source
2020-05-24 13:23:24.169826 (MainThread): 
2020-05-24 13:23:24.169993 (MainThread): 23:23:24 | Concurrency: 1 threads (target='dev')
2020-05-24 13:23:24.170110 (MainThread): 23:23:24 | 
2020-05-24 13:23:24.172947 (Thread-1): Began running node model.dbt_servian_demo.total_reigons
2020-05-24 13:23:24.173308 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.total_reigons".
2020-05-24 13:23:24.173419 (Thread-1): Opening a new connection, currently in state init
2020-05-24 13:23:24.173521 (Thread-1): Compiling model.dbt_servian_demo.total_reigons
2020-05-24 13:23:24.190303 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.total_reigons"
2020-05-24 13:23:24.190736 (Thread-1): finished collecting timing info
2020-05-24 13:23:24.191008 (Thread-1): finished collecting timing info
2020-05-24 13:23:24.191408 (Thread-1): Finished running node model.dbt_servian_demo.total_reigons
2020-05-24 13:23:24.192190 (MainThread): Connection 'model.dbt_servian_demo.total_reigons' was properly closed.
2020-05-24 13:23:24.192296 (MainThread): Connection 'model.dbt_servian_demo.total_reigons' was properly closed.
2020-05-24 13:23:24.195008 (MainThread): 23:23:24 | Done.
2020-05-24 13:23:24.195185 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a6252b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a4f6610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a4f65e0>]}
2020-05-24 13:23:24.195369 (MainThread): Flushing usage events
2020-05-24 13:23:36.544589 (MainThread): Running with dbt=0.16.1
2020-05-24 13:23:36.905914 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-24 13:23:36.906672 (MainThread): Tracking: tracking
2020-05-24 13:23:36.912578 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121ec0eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121ed0580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121ed0550>]}
2020-05-24 13:23:36.933090 (MainThread): Partial parsing not enabled
2020-05-24 13:23:36.934833 (MainThread): Parsing macros/core.sql
2020-05-24 13:23:36.939230 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-24 13:23:36.946881 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-24 13:23:36.948623 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-24 13:23:36.964837 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-24 13:23:36.998130 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-24 13:23:37.019128 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-24 13:23:37.020942 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-24 13:23:37.026728 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-24 13:23:37.038917 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-24 13:23:37.045350 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-24 13:23:37.051248 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-24 13:23:37.055848 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-24 13:23:37.056746 (MainThread): Parsing macros/etc/query.sql
2020-05-24 13:23:37.057746 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-24 13:23:37.059279 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-24 13:23:37.061216 (MainThread): Parsing macros/etc/datetime.sql
2020-05-24 13:23:37.069945 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-24 13:23:37.071842 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-24 13:23:37.072939 (MainThread): Parsing macros/adapters/common.sql
2020-05-24 13:23:37.114471 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-24 13:23:37.115625 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-24 13:23:37.116498 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-24 13:23:37.117540 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-24 13:23:37.119740 (MainThread): Parsing macros/etc.sql
2020-05-24 13:23:37.120371 (MainThread): Parsing macros/catalog.sql
2020-05-24 13:23:37.127763 (MainThread): Parsing macros/adapters.sql
2020-05-24 13:23:37.148426 (MainThread): Parsing macros/materializations/seed.sql
2020-05-24 13:23:37.150312 (MainThread): Parsing macros/materializations/view.sql
2020-05-24 13:23:37.151689 (MainThread): Parsing macros/materializations/table.sql
2020-05-24 13:23:37.160999 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-24 13:23:37.172885 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-24 13:23:37.191018 (MainThread): Partial parsing not enabled
2020-05-24 13:23:37.220357 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.total_reigons".
2020-05-24 13:23:37.220467 (MainThread): Opening a new connection, currently in state init
2020-05-24 13:23:37.413331 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 1 source
2020-05-24 13:23:37.414745 (MainThread): 
2020-05-24 13:23:37.415062 (MainThread): Acquiring new bigquery connection "master".
2020-05-24 13:23:37.415160 (MainThread): Opening a new connection, currently in state closed
2020-05-24 13:23:37.418443 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-24 13:23:37.418697 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-24 13:23:37.421723 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-24 13:23:39.548055 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-24 13:23:39.548354 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-24 13:23:39.548509 (ThreadPoolExecutor-0_0): Creating schema "graham-hamza-bq-dbt-webinar.covid_19_italy_insights".
2020-05-24 13:23:39.548726 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-24 13:23:40.451864 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-24 13:23:41.884657 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-24 13:23:41.885034 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly create_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-24 13:23:41.885352 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-24 13:23:42.398277 (MainThread): 23:23:42 | Concurrency: 1 threads (target='dev')
2020-05-24 13:23:42.398592 (MainThread): 23:23:42 | 
2020-05-24 13:23:42.403190 (Thread-1): Began running node model.dbt_servian_demo.total_reigons
2020-05-24 13:23:42.403405 (Thread-1): 23:23:42 | 1 of 1 START table model covid_19_italy_insights.total_reigons....... [RUN]
2020-05-24 13:23:42.403722 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.total_reigons".
2020-05-24 13:23:42.403823 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-24 13:23:42.403948 (Thread-1): Compiling model.dbt_servian_demo.total_reigons
2020-05-24 13:23:42.422118 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.total_reigons"
2020-05-24 13:23:42.422605 (Thread-1): finished collecting timing info
2020-05-24 13:23:42.553883 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.total_reigons"
2020-05-24 13:23:42.554528 (Thread-1): On model.dbt_servian_demo.total_reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.total_reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`total_reigons`
  
  
  OPTIONS()
  as (
    SELECT
  COUNT(DISTINCT(region_name)) AS Total_Italy_reigons
FROM
  from `bigquery-public-data`.`covid19_italy`.`data_by_reigon`
  );
    
2020-05-24 13:23:43.375468 (Thread-1): finished collecting timing info
2020-05-24 13:23:43.376018 (Thread-1): Database Error in model total_reigons (models/covid_19_italy_insights/total_reigons.sql)
  Syntax error: Unexpected keyword FROM at [12:3]
  compiled SQL at target/run/dbt_servian_demo/covid_19_italy_insights/total_reigons.sql
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Syntax error: Unexpected keyword FROM at [12:3]

(job ID: 03ae6074-ed00-47c7-a6f5-3bf946036c1f)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.total_reigons"} */
   2:
   3:
   4:  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`total_reigons`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    SELECT
  10:  COUNT(DISTINCT(region_name)) AS Total_Italy_reigons
  11:FROM
  12:  from `bigquery-public-data`.`covid19_italy`.`data_by_reigon`
  13:  );
  14:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 229, in macro
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 217, in execute
    return self.connections.execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model total_reigons (models/covid_19_italy_insights/total_reigons.sql)
  Syntax error: Unexpected keyword FROM at [12:3]
  compiled SQL at target/run/dbt_servian_demo/covid_19_italy_insights/total_reigons.sql
2020-05-24 13:23:43.385437 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7530a875-04d7-42bf-a41a-3ae776449400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121f2f6a0>]}
2020-05-24 13:23:43.385783 (Thread-1): 23:23:43 | 1 of 1 ERROR creating table model covid_19_italy_insights.total_reigons [ERROR in 0.98s]
2020-05-24 13:23:43.385935 (Thread-1): Finished running node model.dbt_servian_demo.total_reigons
2020-05-24 13:23:43.387226 (MainThread): 23:23:43 | 
2020-05-24 13:23:43.387381 (MainThread): 23:23:43 | Finished running 1 table model in 5.97s.
2020-05-24 13:23:43.387523 (MainThread): Connection 'master' was left open.
2020-05-24 13:23:43.387605 (MainThread): Connection 'model.dbt_servian_demo.total_reigons' was left open.
2020-05-24 13:23:43.390896 (MainThread): 
2020-05-24 13:23:43.391035 (MainThread): Completed with 1 error and 0 warnings:
2020-05-24 13:23:43.391150 (MainThread): 
2020-05-24 13:23:43.391258 (MainThread): Database Error in model total_reigons (models/covid_19_italy_insights/total_reigons.sql)
2020-05-24 13:23:43.391357 (MainThread):   Syntax error: Unexpected keyword FROM at [12:3]
2020-05-24 13:23:43.391447 (MainThread):   compiled SQL at target/run/dbt_servian_demo/covid_19_italy_insights/total_reigons.sql
2020-05-24 13:23:43.391545 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2020-05-24 13:23:43.391737 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122132850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1221e2820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1221e2a30>]}
2020-05-24 13:23:43.391937 (MainThread): Flushing usage events
2020-05-24 13:25:02.553767 (MainThread): Running with dbt=0.16.1
2020-05-24 13:25:02.975732 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-24 13:25:02.976315 (MainThread): Tracking: tracking
2020-05-24 13:25:02.983127 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11698efd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11699e6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11699e670>]}
2020-05-24 13:25:03.004508 (MainThread): Partial parsing not enabled
2020-05-24 13:25:03.006253 (MainThread): Parsing macros/core.sql
2020-05-24 13:25:03.010585 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-24 13:25:03.018161 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-24 13:25:03.019883 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-24 13:25:03.035670 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-24 13:25:03.068509 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-24 13:25:03.088957 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-24 13:25:03.090852 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-24 13:25:03.098127 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-24 13:25:03.111063 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-24 13:25:03.117428 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-24 13:25:03.123232 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-24 13:25:03.127848 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-24 13:25:03.128773 (MainThread): Parsing macros/etc/query.sql
2020-05-24 13:25:03.129763 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-24 13:25:03.131491 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-24 13:25:03.133440 (MainThread): Parsing macros/etc/datetime.sql
2020-05-24 13:25:03.141981 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-24 13:25:03.144025 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-24 13:25:03.145007 (MainThread): Parsing macros/adapters/common.sql
2020-05-24 13:25:03.185029 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-24 13:25:03.186140 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-24 13:25:03.187007 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-24 13:25:03.188036 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-24 13:25:03.190242 (MainThread): Parsing macros/etc.sql
2020-05-24 13:25:03.190873 (MainThread): Parsing macros/catalog.sql
2020-05-24 13:25:03.198272 (MainThread): Parsing macros/adapters.sql
2020-05-24 13:25:03.219209 (MainThread): Parsing macros/materializations/seed.sql
2020-05-24 13:25:03.221130 (MainThread): Parsing macros/materializations/view.sql
2020-05-24 13:25:03.222545 (MainThread): Parsing macros/materializations/table.sql
2020-05-24 13:25:03.231898 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-24 13:25:03.243835 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-24 13:25:03.262037 (MainThread): Partial parsing not enabled
2020-05-24 13:25:03.291191 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.total_reigons".
2020-05-24 13:25:03.291302 (MainThread): Opening a new connection, currently in state init
2020-05-24 13:25:03.502948 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 1 source
2020-05-24 13:25:03.504325 (MainThread): 
2020-05-24 13:25:03.504646 (MainThread): Acquiring new bigquery connection "master".
2020-05-24 13:25:03.504745 (MainThread): Opening a new connection, currently in state closed
2020-05-24 13:25:03.506951 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-24 13:25:03.507080 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-24 13:25:03.508175 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-24 13:25:04.976925 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-24 13:25:06.348130 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-24 13:25:06.348624 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-24 13:25:06.348947 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-24 13:25:06.778619 (MainThread): 23:25:06 | Concurrency: 1 threads (target='dev')
2020-05-24 13:25:06.778945 (MainThread): 23:25:06 | 
2020-05-24 13:25:06.783770 (Thread-1): Began running node model.dbt_servian_demo.total_reigons
2020-05-24 13:25:06.783994 (Thread-1): 23:25:06 | 1 of 1 START table model covid_19_italy_insights.total_reigons....... [RUN]
2020-05-24 13:25:06.784308 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.total_reigons".
2020-05-24 13:25:06.784406 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-24 13:25:06.784550 (Thread-1): Compiling model.dbt_servian_demo.total_reigons
2020-05-24 13:25:06.802949 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.total_reigons"
2020-05-24 13:25:06.803425 (Thread-1): finished collecting timing info
2020-05-24 13:25:06.925554 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.total_reigons"
2020-05-24 13:25:06.925968 (Thread-1): On model.dbt_servian_demo.total_reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.total_reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`total_reigons`
  
  
  OPTIONS()
  as (
    SELECT
  COUNT(DISTINCT(region_name)) AS Total_Italy_reigons
FROM
	`bigquery-public-data`.`covid19_italy`.`data_by_reigon`
  );
    
2020-05-24 13:25:07.733487 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.total_reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`total_reigons`
  
  
  OPTIONS()
  as (
    SELECT
  COUNT(DISTINCT(region_name)) AS Total_Italy_reigons
FROM
	`bigquery-public-data`.`covid19_italy`.`data_by_reigon`
  );
    
2020-05-24 13:25:07.733746 (Thread-1): 404 Not found: Table bigquery-public-data:covid19_italy.data_by_reigon was not found in location US

(job ID: 2e2d9ad9-6f2e-4ead-a168-032e66caa640)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.total_reigons"} */
   2:
   3:
   4:  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`total_reigons`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    SELECT
  10:  COUNT(DISTINCT(region_name)) AS Total_Italy_reigons
  11:FROM
  12:	`bigquery-public-data`.`covid19_italy`.`data_by_reigon`
  13:  );
  14:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-24 13:25:07.734022 (Thread-1): finished collecting timing info
2020-05-24 13:25:07.734684 (Thread-1): Runtime Error in model total_reigons (models/covid_19_italy_insights/total_reigons.sql)
  404 Not found: Table bigquery-public-data:covid19_italy.data_by_reigon was not found in location US
  
  (job ID: 2e2d9ad9-6f2e-4ead-a168-032e66caa640)
  
                                                                  -----Query Job SQL Follows-----                                                                
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.total_reigons"} */
     2:
     3:
     4:  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`total_reigons`
     5:  
     6:  
     7:  OPTIONS()
     8:  as (
     9:    SELECT
    10:  COUNT(DISTINCT(region_name)) AS Total_Italy_reigons
    11:FROM
    12:	`bigquery-public-data`.`covid19_italy`.`data_by_reigon`
    13:  );
    14:    
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table bigquery-public-data:covid19_italy.data_by_reigon was not found in location US

(job ID: 2e2d9ad9-6f2e-4ead-a168-032e66caa640)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.total_reigons"} */
   2:
   3:
   4:  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`total_reigons`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    SELECT
  10:  COUNT(DISTINCT(region_name)) AS Total_Italy_reigons
  11:FROM
  12:	`bigquery-public-data`.`covid19_italy`.`data_by_reigon`
  13:  );
  14:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 229, in macro
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 217, in execute
    return self.connections.execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 98, in exception_handler
    raise RuntimeException(str(e))
dbt.exceptions.RuntimeException: Runtime Error in model total_reigons (models/covid_19_italy_insights/total_reigons.sql)
  404 Not found: Table bigquery-public-data:covid19_italy.data_by_reigon was not found in location US
  
  (job ID: 2e2d9ad9-6f2e-4ead-a168-032e66caa640)
  
                                                                  -----Query Job SQL Follows-----                                                                
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.total_reigons"} */
     2:
     3:
     4:  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`total_reigons`
     5:  
     6:  
     7:  OPTIONS()
     8:  as (
     9:    SELECT
    10:  COUNT(DISTINCT(region_name)) AS Total_Italy_reigons
    11:FROM
    12:	`bigquery-public-data`.`covid19_italy`.`data_by_reigon`
    13:  );
    14:    
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-24 13:25:07.738184 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39a83be6-60a2-446a-83a3-235bc4e76fd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116a092b0>]}
2020-05-24 13:25:07.738495 (Thread-1): 23:25:07 | 1 of 1 ERROR creating table model covid_19_italy_insights.total_reigons [ERROR in 0.95s]
2020-05-24 13:25:07.738664 (Thread-1): Finished running node model.dbt_servian_demo.total_reigons
2020-05-24 13:25:07.739921 (MainThread): 23:25:07 | 
2020-05-24 13:25:07.740068 (MainThread): 23:25:07 | Finished running 1 table model in 4.24s.
2020-05-24 13:25:07.740190 (MainThread): Connection 'master' was left open.
2020-05-24 13:25:07.740280 (MainThread): Connection 'model.dbt_servian_demo.total_reigons' was left open.
2020-05-24 13:25:07.743710 (MainThread): 
2020-05-24 13:25:07.743850 (MainThread): Completed with 1 error and 0 warnings:
2020-05-24 13:25:07.743966 (MainThread): 
2020-05-24 13:25:07.744083 (MainThread): Runtime Error in model total_reigons (models/covid_19_italy_insights/total_reigons.sql)
2020-05-24 13:25:07.744186 (MainThread):   404 Not found: Table bigquery-public-data:covid19_italy.data_by_reigon was not found in location US
2020-05-24 13:25:07.744280 (MainThread):   
2020-05-24 13:25:07.744370 (MainThread):   (job ID: 2e2d9ad9-6f2e-4ead-a168-032e66caa640)
2020-05-24 13:25:07.744457 (MainThread):   
2020-05-24 13:25:07.744557 (MainThread):                                                                   -----Query Job SQL Follows-----                                                                
2020-05-24 13:25:07.744645 (MainThread):   
2020-05-24 13:25:07.744731 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-24 13:25:07.744818 (MainThread):      1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.total_reigons"} */
2020-05-24 13:25:07.744907 (MainThread):      2:
2020-05-24 13:25:07.744993 (MainThread):      3:
2020-05-24 13:25:07.745079 (MainThread):      4:  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`total_reigons`
2020-05-24 13:25:07.745167 (MainThread):      5:  
2020-05-24 13:25:07.745255 (MainThread):      6:  
2020-05-24 13:25:07.745343 (MainThread):      7:  OPTIONS()
2020-05-24 13:25:07.745429 (MainThread):      8:  as (
2020-05-24 13:25:07.745516 (MainThread):      9:    SELECT
2020-05-24 13:25:07.745601 (MainThread):     10:  COUNT(DISTINCT(region_name)) AS Total_Italy_reigons
2020-05-24 13:25:07.745686 (MainThread):     11:FROM
2020-05-24 13:25:07.745773 (MainThread):     12:	`bigquery-public-data`.`covid19_italy`.`data_by_reigon`
2020-05-24 13:25:07.745860 (MainThread):     13:  );
2020-05-24 13:25:07.745945 (MainThread):     14:    
2020-05-24 13:25:07.746032 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-24 13:25:07.746127 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2020-05-24 13:25:07.746318 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116b66610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116c27820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116c27100>]}
2020-05-24 13:25:07.746506 (MainThread): Flushing usage events
2020-05-24 13:26:55.671672 (MainThread): Running with dbt=0.16.1
2020-05-24 13:26:56.364671 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-24 13:26:56.367055 (MainThread): Tracking: tracking
2020-05-24 13:26:56.376655 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d5c2eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d5d1580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d5d1550>]}
2020-05-24 13:26:56.399335 (MainThread): Partial parsing not enabled
2020-05-24 13:26:56.401612 (MainThread): Parsing macros/core.sql
2020-05-24 13:26:56.407214 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-24 13:26:56.416197 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-24 13:26:56.418426 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-24 13:26:56.435149 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-24 13:26:56.471975 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-24 13:26:56.493715 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-24 13:26:56.496550 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-24 13:26:56.503926 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-24 13:26:56.517698 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-24 13:26:56.524540 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-24 13:26:56.530817 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-24 13:26:56.535824 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-24 13:26:56.536943 (MainThread): Parsing macros/etc/query.sql
2020-05-24 13:26:56.538313 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-24 13:26:56.540485 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-24 13:26:56.543371 (MainThread): Parsing macros/etc/datetime.sql
2020-05-24 13:26:56.553917 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-24 13:26:56.556405 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-24 13:26:56.558017 (MainThread): Parsing macros/adapters/common.sql
2020-05-24 13:26:56.599819 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-24 13:26:56.601128 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-24 13:26:56.602226 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-24 13:26:56.603616 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-24 13:26:56.606284 (MainThread): Parsing macros/etc.sql
2020-05-24 13:26:56.607463 (MainThread): Parsing macros/catalog.sql
2020-05-24 13:26:56.615810 (MainThread): Parsing macros/adapters.sql
2020-05-24 13:26:56.636929 (MainThread): Parsing macros/materializations/seed.sql
2020-05-24 13:26:56.639138 (MainThread): Parsing macros/materializations/view.sql
2020-05-24 13:26:56.641011 (MainThread): Parsing macros/materializations/table.sql
2020-05-24 13:26:56.650638 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-24 13:26:56.662735 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-24 13:26:56.681769 (MainThread): Partial parsing not enabled
2020-05-24 13:26:56.711712 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.total_reigons".
2020-05-24 13:26:56.711830 (MainThread): Opening a new connection, currently in state init
2020-05-24 13:26:56.930288 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 1 source
2020-05-24 13:26:56.931779 (MainThread): 
2020-05-24 13:26:56.932126 (MainThread): Acquiring new bigquery connection "master".
2020-05-24 13:26:56.932228 (MainThread): Opening a new connection, currently in state closed
2020-05-24 13:26:56.935085 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-24 13:26:56.935217 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-24 13:26:56.937123 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-24 13:26:58.746880 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-24 13:27:00.117290 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-24 13:27:00.117775 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-24 13:27:00.118023 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-24 13:27:00.571675 (MainThread): 23:27:00 | Concurrency: 1 threads (target='dev')
2020-05-24 13:27:00.571999 (MainThread): 23:27:00 | 
2020-05-24 13:27:00.579277 (Thread-1): Began running node model.dbt_servian_demo.total_reigons
2020-05-24 13:27:00.579565 (Thread-1): 23:27:00 | 1 of 1 START table model covid_19_italy_insights.total_reigons....... [RUN]
2020-05-24 13:27:00.579987 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.total_reigons".
2020-05-24 13:27:00.580096 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-24 13:27:00.580227 (Thread-1): Compiling model.dbt_servian_demo.total_reigons
2020-05-24 13:27:00.598627 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.total_reigons"
2020-05-24 13:27:00.599073 (Thread-1): finished collecting timing info
2020-05-24 13:27:00.722803 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.total_reigons"
2020-05-24 13:27:00.723229 (Thread-1): On model.dbt_servian_demo.total_reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.total_reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`total_reigons`
  
  
  OPTIONS()
  as (
    SELECT
  COUNT(DISTINCT(region_name)) AS Total_Italy_reigons
FROM
	`bigquery-public-data`.`covid19_italy`.`data_by_region`
  );
    
2020-05-24 13:27:04.581157 (Thread-1): finished collecting timing info
2020-05-24 13:27:04.582087 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e83e9c04-611a-4cd1-a9ce-4a14d5d5f627', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d62e6a0>]}
2020-05-24 13:27:04.582458 (Thread-1): 23:27:04 | 1 of 1 OK created table model covid_19_italy_insights.total_reigons.. [CREATE TABLE (1) in 4.00s]
2020-05-24 13:27:04.582636 (Thread-1): Finished running node model.dbt_servian_demo.total_reigons
2020-05-24 13:27:04.584099 (MainThread): 23:27:04 | 
2020-05-24 13:27:04.584255 (MainThread): 23:27:04 | Finished running 1 table model in 7.65s.
2020-05-24 13:27:04.584381 (MainThread): Connection 'master' was left open.
2020-05-24 13:27:04.584475 (MainThread): Connection 'model.dbt_servian_demo.total_reigons' was left open.
2020-05-24 13:27:04.589668 (MainThread): 
2020-05-24 13:27:04.589942 (MainThread): Completed successfully
2020-05-24 13:27:04.590084 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-05-24 13:27:04.590315 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d765640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d75e6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d75e6a0>]}
2020-05-24 13:27:04.590543 (MainThread): Flushing usage events
2020-05-24 13:52:14.982272 (MainThread): Running with dbt=0.16.1
2020-05-24 13:52:15.719074 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-24 13:52:15.720536 (MainThread): Tracking: tracking
2020-05-24 13:52:15.730329 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f742fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f7516a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f751670>]}
2020-05-24 13:52:15.753344 (MainThread): Partial parsing not enabled
2020-05-24 13:52:15.756365 (MainThread): Parsing macros/core.sql
2020-05-24 13:52:15.762010 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-24 13:52:15.771080 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-24 13:52:15.773864 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-24 13:52:15.792510 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-24 13:52:15.827248 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-24 13:52:15.848255 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-24 13:52:15.850577 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-24 13:52:15.857515 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-24 13:52:15.870178 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-24 13:52:15.876706 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-24 13:52:15.882797 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-24 13:52:15.887674 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-24 13:52:15.888851 (MainThread): Parsing macros/etc/query.sql
2020-05-24 13:52:15.890514 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-24 13:52:15.892844 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-24 13:52:15.895733 (MainThread): Parsing macros/etc/datetime.sql
2020-05-24 13:52:15.905955 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-24 13:52:15.908878 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-24 13:52:15.910641 (MainThread): Parsing macros/adapters/common.sql
2020-05-24 13:52:15.953321 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-24 13:52:15.954708 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-24 13:52:15.955809 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-24 13:52:15.957445 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-24 13:52:15.960178 (MainThread): Parsing macros/etc.sql
2020-05-24 13:52:15.961250 (MainThread): Parsing macros/catalog.sql
2020-05-24 13:52:15.969470 (MainThread): Parsing macros/adapters.sql
2020-05-24 13:52:15.990965 (MainThread): Parsing macros/materializations/seed.sql
2020-05-24 13:52:15.993095 (MainThread): Parsing macros/materializations/view.sql
2020-05-24 13:52:15.995141 (MainThread): Parsing macros/materializations/table.sql
2020-05-24 13:52:16.005510 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-24 13:52:16.017727 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-24 13:52:16.035401 (MainThread): Partial parsing not enabled
2020-05-24 13:52:16.066436 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-24 13:52:16.066582 (MainThread): Opening a new connection, currently in state init
2020-05-24 13:52:16.082004 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-24 13:52:16.082147 (MainThread): Opening a new connection, currently in state closed
2020-05-24 13:52:16.090088 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-24 13:52:16.090220 (MainThread): Opening a new connection, currently in state closed
2020-05-24 13:52:16.165670 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-24 13:52:16.320437 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 2 sources
2020-05-24 13:52:16.322868 (MainThread): 
2020-05-24 13:52:16.323182 (MainThread): Acquiring new bigquery connection "master".
2020-05-24 13:52:16.323277 (MainThread): Opening a new connection, currently in state closed
2020-05-24 13:52:16.330088 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-24 13:52:16.330344 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-24 13:52:16.333653 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-24 13:52:18.849799 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-24 13:52:20.255260 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-24 13:52:20.255729 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-24 13:52:20.255980 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-24 13:52:20.673077 (MainThread): 23:52:20 | Concurrency: 1 threads (target='dev')
2020-05-24 13:52:20.673345 (MainThread): 23:52:20 | 
2020-05-24 13:52:20.680449 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-24 13:52:20.680748 (Thread-1): 23:52:20 | 1 of 3 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-05-24 13:52:20.681123 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-24 13:52:20.681237 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-24 13:52:20.681373 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-24 13:52:20.699710 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-24 13:52:20.700180 (Thread-1): finished collecting timing info
2020-05-24 13:52:20.824911 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-24 13:52:20.825637 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-24 13:52:24.540654 (Thread-1): finished collecting timing info
2020-05-24 13:52:24.541579 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0adb9921-fe6b-4e93-976b-bd62e6e3fdaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f9af910>]}
2020-05-24 13:52:24.541961 (Thread-1): 23:52:24 | 1 of 3 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 3.86s]
2020-05-24 13:52:24.542150 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-24 13:52:24.542330 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-24 13:52:24.542642 (Thread-1): 23:52:24 | 2 of 3 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-05-24 13:52:24.543008 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-24 13:52:24.543138 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-05-24 13:52:24.543263 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-24 13:52:24.551466 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-24 13:52:24.551936 (Thread-1): finished collecting timing info
2020-05-24 13:52:24.556960 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-24 13:52:24.557392 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-24 13:52:27.415063 (Thread-1): finished collecting timing info
2020-05-24 13:52:27.415960 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0adb9921-fe6b-4e93-976b-bd62e6e3fdaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f9aff10>]}
2020-05-24 13:52:27.416289 (Thread-1): 23:52:27 | 2 of 3 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 2.87s]
2020-05-24 13:52:27.416471 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-24 13:52:27.416944 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-24 13:52:27.417137 (Thread-1): 23:52:27 | 3 of 3 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-05-24 13:52:27.417648 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-24 13:52:27.417877 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-05-24 13:52:27.418011 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-24 13:52:27.426873 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-24 13:52:27.427305 (Thread-1): finished collecting timing info
2020-05-24 13:52:27.432294 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-24 13:52:27.432771 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
  );
    
2020-05-24 13:52:30.506876 (Thread-1): finished collecting timing info
2020-05-24 13:52:30.507784 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0adb9921-fe6b-4e93-976b-bd62e6e3fdaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f97a9d0>]}
2020-05-24 13:52:30.508291 (Thread-1): 23:52:30 | 3 of 3 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.09s]
2020-05-24 13:52:30.508453 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-24 13:52:30.509634 (MainThread): 23:52:30 | 
2020-05-24 13:52:30.509786 (MainThread): 23:52:30 | Finished running 3 table models in 14.19s.
2020-05-24 13:52:30.509910 (MainThread): Connection 'master' was left open.
2020-05-24 13:52:30.510004 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-05-24 13:52:30.519260 (MainThread): 
2020-05-24 13:52:30.519492 (MainThread): Completed successfully
2020-05-24 13:52:30.519732 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-05-24 13:52:30.520012 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f7bfd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f9b0070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f97a9d0>]}
2020-05-24 13:52:30.520227 (MainThread): Flushing usage events
2020-05-24 13:56:33.510563 (MainThread): Running with dbt=0.16.1
2020-05-24 13:56:34.202192 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-24 13:56:34.203541 (MainThread): Tracking: tracking
2020-05-24 13:56:34.212321 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123cbdfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123cd06d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123cd06a0>]}
2020-05-24 13:56:34.235330 (MainThread): Partial parsing not enabled
2020-05-24 13:56:34.237812 (MainThread): Parsing macros/core.sql
2020-05-24 13:56:34.243350 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-24 13:56:34.252188 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-24 13:56:34.254574 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-24 13:56:34.271899 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-24 13:56:34.305837 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-24 13:56:34.326724 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-24 13:56:34.329261 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-24 13:56:34.335992 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-24 13:56:34.349349 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-24 13:56:34.356233 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-24 13:56:34.362666 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-24 13:56:34.367602 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-24 13:56:34.368885 (MainThread): Parsing macros/etc/query.sql
2020-05-24 13:56:34.370465 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-24 13:56:34.372795 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-24 13:56:34.375631 (MainThread): Parsing macros/etc/datetime.sql
2020-05-24 13:56:34.385715 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-24 13:56:34.388109 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-24 13:56:34.389703 (MainThread): Parsing macros/adapters/common.sql
2020-05-24 13:56:34.430962 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-24 13:56:34.432307 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-24 13:56:34.433425 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-24 13:56:34.435051 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-24 13:56:34.437930 (MainThread): Parsing macros/etc.sql
2020-05-24 13:56:34.439323 (MainThread): Parsing macros/catalog.sql
2020-05-24 13:56:34.447331 (MainThread): Parsing macros/adapters.sql
2020-05-24 13:56:34.469192 (MainThread): Parsing macros/materializations/seed.sql
2020-05-24 13:56:34.471772 (MainThread): Parsing macros/materializations/view.sql
2020-05-24 13:56:34.473853 (MainThread): Parsing macros/materializations/table.sql
2020-05-24 13:56:34.483645 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-24 13:56:34.496741 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-24 13:56:34.515094 (MainThread): Partial parsing not enabled
2020-05-24 13:56:34.545459 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-24 13:56:34.545598 (MainThread): Opening a new connection, currently in state init
2020-05-24 13:56:34.561217 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-24 13:56:34.561349 (MainThread): Opening a new connection, currently in state closed
2020-05-24 13:56:34.569031 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-24 13:56:34.569129 (MainThread): Opening a new connection, currently in state closed
2020-05-24 13:56:34.643272 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-24 13:56:34.797280 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 2 sources
2020-05-24 13:56:34.799566 (MainThread): 
2020-05-24 13:56:34.799855 (MainThread): Acquiring new bigquery connection "master".
2020-05-24 13:56:34.799946 (MainThread): Opening a new connection, currently in state closed
2020-05-24 13:56:34.805811 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-24 13:56:34.805926 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-24 13:56:34.808231 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-24 13:56:36.601101 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-24 13:56:37.929070 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-24 13:56:37.929560 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-24 13:56:37.929848 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-24 13:56:38.340379 (MainThread): 23:56:38 | Concurrency: 1 threads (target='dev')
2020-05-24 13:56:38.340642 (MainThread): 23:56:38 | 
2020-05-24 13:56:38.346077 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-24 13:56:38.346331 (Thread-1): 23:56:38 | 1 of 3 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-05-24 13:56:38.346692 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-24 13:56:38.346805 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-24 13:56:38.346955 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-24 13:56:38.365011 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-24 13:56:38.365509 (Thread-1): finished collecting timing info
2020-05-24 13:56:38.404994 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-24 13:56:39.134157 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-24 13:56:39.134596 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-24 13:56:42.628070 (Thread-1): finished collecting timing info
2020-05-24 13:56:42.628994 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b6eda68-8d5d-404e-ab83-9e5450b76dfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123d96550>]}
2020-05-24 13:56:42.629386 (Thread-1): 23:56:42 | 1 of 3 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 4.28s]
2020-05-24 13:56:42.629569 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-24 13:56:42.629748 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-24 13:56:42.630058 (Thread-1): 23:56:42 | 2 of 3 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-05-24 13:56:42.630425 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-24 13:56:42.630554 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-05-24 13:56:42.630678 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-24 13:56:42.638479 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-24 13:56:42.638908 (Thread-1): finished collecting timing info
2020-05-24 13:56:42.642919 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-24 13:56:43.045386 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-24 13:56:43.046062 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-24 13:56:46.283319 (Thread-1): finished collecting timing info
2020-05-24 13:56:46.284211 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b6eda68-8d5d-404e-ab83-9e5450b76dfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123e084f0>]}
2020-05-24 13:56:46.284541 (Thread-1): 23:56:46 | 2 of 3 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.65s]
2020-05-24 13:56:46.284717 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-24 13:56:46.285306 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-24 13:56:46.285532 (Thread-1): 23:56:46 | 3 of 3 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-05-24 13:56:46.285893 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-24 13:56:46.286023 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-05-24 13:56:46.286156 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-24 13:56:46.294999 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-24 13:56:46.295415 (Thread-1): finished collecting timing info
2020-05-24 13:56:46.299347 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-24 13:56:46.694778 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-24 13:56:46.695388 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-05-24 13:56:49.867345 (Thread-1): finished collecting timing info
2020-05-24 13:56:49.868229 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b6eda68-8d5d-404e-ab83-9e5450b76dfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123ef6ca0>]}
2020-05-24 13:56:49.868552 (Thread-1): 23:56:49 | 3 of 3 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.58s]
2020-05-24 13:56:49.868733 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-24 13:56:49.870391 (MainThread): 23:56:49 | 
2020-05-24 13:56:49.870551 (MainThread): 23:56:49 | Finished running 3 table models in 15.07s.
2020-05-24 13:56:49.870678 (MainThread): Connection 'master' was left open.
2020-05-24 13:56:49.870775 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-05-24 13:56:49.879091 (MainThread): 
2020-05-24 13:56:49.879242 (MainThread): Completed successfully
2020-05-24 13:56:49.879371 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-05-24 13:56:49.879583 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123f604f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123d0d880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123d978b0>]}
2020-05-24 13:56:49.879790 (MainThread): Flushing usage events
2020-05-25 11:56:53.473437 (MainThread): Running with dbt=0.16.1
2020-05-25 11:56:53.841208 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-25 11:56:53.843076 (MainThread): Tracking: tracking
2020-05-25 11:56:53.848790 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bf22760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bf33820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bf337f0>]}
2020-05-25 11:56:53.869461 (MainThread): Partial parsing not enabled
2020-05-25 11:56:53.871840 (MainThread): Parsing macros/core.sql
2020-05-25 11:56:53.877665 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 11:56:53.885647 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 11:56:53.888159 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 11:56:53.904822 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 11:56:53.937982 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 11:56:53.959427 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 11:56:53.961879 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 11:56:53.968064 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 11:56:53.980526 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 11:56:53.987121 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 11:56:53.993240 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 11:56:53.998089 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 11:56:53.999194 (MainThread): Parsing macros/etc/query.sql
2020-05-25 11:56:54.000685 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 11:56:54.002807 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 11:56:54.005226 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 11:56:54.014466 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 11:56:54.016747 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 11:56:54.018232 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 11:56:54.058815 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 11:56:54.060089 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 11:56:54.061160 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 11:56:54.062780 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 11:56:54.065669 (MainThread): Parsing macros/etc.sql
2020-05-25 11:56:54.067067 (MainThread): Parsing macros/catalog.sql
2020-05-25 11:56:54.075067 (MainThread): Parsing macros/adapters.sql
2020-05-25 11:56:54.096297 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 11:56:54.098879 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 11:56:54.100937 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 11:56:54.110533 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 11:56:54.123439 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 11:56:54.143199 (MainThread): Partial parsing not enabled
2020-05-25 11:56:54.174007 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 11:56:54.174134 (MainThread): Opening a new connection, currently in state init
2020-05-25 11:56:54.189467 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 11:56:54.189609 (MainThread): Opening a new connection, currently in state closed
2020-05-25 11:56:54.196890 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 11:56:54.197019 (MainThread): Opening a new connection, currently in state closed
2020-05-25 11:56:54.265517 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-25 11:56:54.417367 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 2 sources
2020-05-25 11:56:54.419630 (MainThread): 
2020-05-25 11:56:54.419780 (MainThread): 21:56:54 | Concurrency: 1 threads (target='dev')
2020-05-25 11:56:54.419891 (MainThread): 21:56:54 | 
2020-05-25 11:56:54.425321 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 11:56:54.425702 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 11:56:54.425807 (Thread-1): Opening a new connection, currently in state init
2020-05-25 11:56:54.425904 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 11:56:54.440711 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 11:56:54.441105 (Thread-1): finished collecting timing info
2020-05-25 11:56:54.441346 (Thread-1): finished collecting timing info
2020-05-25 11:56:54.441701 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 11:56:54.441826 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 11:56:54.442051 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 11:56:54.442139 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 11:56:54.442222 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 11:56:54.448353 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 11:56:54.448663 (Thread-1): finished collecting timing info
2020-05-25 11:56:54.448882 (Thread-1): finished collecting timing info
2020-05-25 11:56:54.449214 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 11:56:54.449556 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 11:56:54.449821 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 11:56:54.449913 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 11:56:54.450067 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 11:56:54.457515 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 11:56:54.457920 (Thread-1): finished collecting timing info
2020-05-25 11:56:54.458148 (Thread-1): finished collecting timing info
2020-05-25 11:56:54.458503 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 11:56:54.459224 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Per_Reigons' was properly closed.
2020-05-25 11:56:54.459323 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-05-25 11:56:54.466737 (MainThread): 21:56:54 | Done.
2020-05-25 11:56:54.466978 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c0bafd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bf939d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bf93820>]}
2020-05-25 11:56:54.467219 (MainThread): Flushing usage events
2020-05-25 11:56:56.453044 (MainThread): Running with dbt=0.16.1
2020-05-25 11:56:56.822453 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-25 11:56:56.823169 (MainThread): Tracking: tracking
2020-05-25 11:56:56.829037 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e839fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e8496d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e8496a0>]}
2020-05-25 11:56:56.849889 (MainThread): Partial parsing not enabled
2020-05-25 11:56:56.851711 (MainThread): Parsing macros/core.sql
2020-05-25 11:56:56.855991 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 11:56:56.863489 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 11:56:56.865189 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 11:56:56.881196 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 11:56:56.914135 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 11:56:56.934359 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 11:56:56.936189 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 11:56:56.942061 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 11:56:56.954361 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 11:56:56.960873 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 11:56:56.966847 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 11:56:56.971552 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 11:56:56.972470 (MainThread): Parsing macros/etc/query.sql
2020-05-25 11:56:56.973496 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 11:56:56.975051 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 11:56:56.977022 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 11:56:56.985646 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 11:56:56.987555 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 11:56:56.988588 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 11:56:57.029523 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 11:56:57.030619 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 11:56:57.031484 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 11:56:57.032512 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 11:56:57.034687 (MainThread): Parsing macros/etc.sql
2020-05-25 11:56:57.035320 (MainThread): Parsing macros/catalog.sql
2020-05-25 11:56:57.042563 (MainThread): Parsing macros/adapters.sql
2020-05-25 11:56:57.062925 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 11:56:57.064767 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 11:56:57.066126 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 11:56:57.075468 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 11:56:57.087127 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 11:56:57.104939 (MainThread): Partial parsing not enabled
2020-05-25 11:56:57.134264 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 11:56:57.134383 (MainThread): Opening a new connection, currently in state init
2020-05-25 11:56:57.148613 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 11:56:57.148715 (MainThread): Opening a new connection, currently in state closed
2020-05-25 11:56:57.154924 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 11:56:57.155010 (MainThread): Opening a new connection, currently in state closed
2020-05-25 11:56:57.221739 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-25 11:56:57.371087 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 2 sources
2020-05-25 11:56:57.373289 (MainThread): 
2020-05-25 11:56:57.373598 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 11:56:57.373685 (MainThread): Opening a new connection, currently in state closed
2020-05-25 11:56:57.380379 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-25 11:56:57.380587 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-25 11:56:57.381517 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 11:56:58.780077 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 11:56:58.780430 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-25 11:56:58.780606 (ThreadPoolExecutor-0_0): Creating schema "graham-hamza-bq-dbt-webinar.covid_19_italy_insights".
2020-05-25 11:56:58.780799 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 11:56:59.500177 (MainThread): Connection 'master' was properly closed.
2020-05-25 11:56:59.500424 (MainThread): Connection 'create_graham-hamza-bq-dbt-webinar_covid_19_italy_insights' was left open.
2020-05-25 11:56:59.500832 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e9b69a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e8cecd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e8aebb0>]}
2020-05-25 11:56:59.501289 (MainThread): Flushing usage events
2020-05-25 11:57:00.521118 (MainThread): Encountered an error:
2020-05-25 11:57:00.521379 (MainThread): Database Error
  Access Denied: Project graham-hamza-bq-dbt-webinar: User does not have bigquery.datasets.create permission in project graham-hamza-bq-dbt-webinar.
2020-05-25 11:57:00.537852 (MainThread): Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in fn
    return client.create_dataset(dataset, exists_ok=True)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 460, in create_dataset
    api_response = self._call_api(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.Forbidden: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/graham-hamza-bq-dbt-webinar/datasets: Access Denied: Project graham-hamza-bq-dbt-webinar: User does not have bigquery.datasets.create permission in project graham-hamza-bq-dbt-webinar.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 371, in run
    result = self.execute_with_hooks(selected_uids)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 331, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/run.py", line 199, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 472, in create_schemas
    create_future.result()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 440, in create_schema
    adapter.create_schema(db, schema)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 296, in create_schema
    self.connections.create_dataset(database, schema)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 332, in create_dataset
    self._retry_and_handle(msg='create dataset', conn=conn, fn=fn)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 88, in exception_handler
    self.handle_error(e, message)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Access Denied: Project graham-hamza-bq-dbt-webinar: User does not have bigquery.datasets.create permission in project graham-hamza-bq-dbt-webinar.

2020-05-25 11:57:01.470368 (MainThread): Running with dbt=0.16.1
2020-05-25 11:57:01.833996 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-05-25 11:57:01.834885 (MainThread): Tracking: tracking
2020-05-25 11:57:01.840604 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115554f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1155646a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115564670>]}
2020-05-25 11:57:01.841146 (MainThread): Checking target/*
2020-05-25 11:57:01.845142 (MainThread):  Cleaned target/*
2020-05-25 11:57:01.845311 (MainThread): Checking dbt_modules/*
2020-05-25 11:57:01.845705 (MainThread):  Cleaned dbt_modules/*
2020-05-25 11:57:01.845811 (MainThread): Finished cleaning all paths.
2020-05-25 11:57:01.846001 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115554f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115564610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115564640>]}
2020-05-25 11:57:01.846193 (MainThread): Flushing usage events
2020-05-25 12:02:29.221782 (MainThread): Running with dbt=0.16.1
2020-05-25 12:02:29.657416 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-25 12:02:29.658761 (MainThread): Tracking: tracking
2020-05-25 12:02:29.664788 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bacc700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11badf7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11badf790>]}
2020-05-25 12:02:29.685434 (MainThread): Partial parsing not enabled
2020-05-25 12:02:29.687798 (MainThread): Parsing macros/core.sql
2020-05-25 12:02:29.692834 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:02:29.701054 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:02:29.703513 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:02:29.720333 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:02:29.753752 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:02:29.774607 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:02:29.776918 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:02:29.783218 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:02:29.795625 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:02:29.802264 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:02:29.808445 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:02:29.813344 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:02:29.814435 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:02:29.815951 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:02:29.818232 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:02:29.820851 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:02:29.830139 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:02:29.832415 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:02:29.833913 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:02:29.874518 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:02:29.875827 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:02:29.876938 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:02:29.878384 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:02:29.881134 (MainThread): Parsing macros/etc.sql
2020-05-25 12:02:29.882188 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:02:29.892063 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:02:29.916179 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:02:29.918845 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:02:29.920900 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:02:29.931164 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:02:29.943488 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:02:29.961831 (MainThread): Partial parsing not enabled
2020-05-25 12:02:29.992402 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:02:29.992545 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:02:30.007995 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:02:30.008132 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:02:30.015339 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:02:30.015464 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:02:30.083425 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-25 12:02:30.236042 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 2 sources
2020-05-25 12:02:30.238279 (MainThread): 
2020-05-25 12:02:30.238435 (MainThread): 22:02:30 | Concurrency: 1 threads (target='dev')
2020-05-25 12:02:30.238545 (MainThread): 22:02:30 | 
2020-05-25 12:02:30.243309 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:02:30.243714 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:02:30.243813 (Thread-1): Opening a new connection, currently in state init
2020-05-25 12:02:30.243904 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:02:30.258817 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:02:30.259404 (Thread-1): finished collecting timing info
2020-05-25 12:02:30.259653 (Thread-1): finished collecting timing info
2020-05-25 12:02:30.260024 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:02:30.260150 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:02:30.260383 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:02:30.260469 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:02:30.260552 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:02:30.266745 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:02:30.267074 (Thread-1): finished collecting timing info
2020-05-25 12:02:30.267291 (Thread-1): finished collecting timing info
2020-05-25 12:02:30.267622 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:02:30.268017 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:02:30.268268 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:02:30.268355 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:02:30.268435 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:02:30.275781 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:02:30.276168 (Thread-1): finished collecting timing info
2020-05-25 12:02:30.276391 (Thread-1): finished collecting timing info
2020-05-25 12:02:30.276737 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:02:30.277446 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Per_Reigons' was properly closed.
2020-05-25 12:02:30.277543 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-05-25 12:02:30.284071 (MainThread): 22:02:30 | Done.
2020-05-25 12:02:30.284253 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bb9fee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bb6cf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bb6cc10>]}
2020-05-25 12:02:30.284446 (MainThread): Flushing usage events
2020-05-25 12:02:32.226617 (MainThread): Running with dbt=0.16.1
2020-05-25 12:02:32.585326 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-25 12:02:32.585989 (MainThread): Tracking: tracking
2020-05-25 12:02:32.592107 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123497850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1234a77f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1234a77c0>]}
2020-05-25 12:02:32.612390 (MainThread): Partial parsing not enabled
2020-05-25 12:02:32.614054 (MainThread): Parsing macros/core.sql
2020-05-25 12:02:32.618280 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:02:32.625681 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:02:32.627663 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:02:32.643408 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:02:32.677602 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:02:32.697283 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:02:32.699032 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:02:32.704759 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:02:32.716693 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:02:32.723105 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:02:32.729015 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:02:32.733649 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:02:32.734549 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:02:32.735555 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:02:32.737107 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:02:32.739062 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:02:32.747732 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:02:32.749606 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:02:32.750619 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:02:32.791703 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:02:32.792835 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:02:32.793724 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:02:32.794768 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:02:32.796995 (MainThread): Parsing macros/etc.sql
2020-05-25 12:02:32.797642 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:02:32.805058 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:02:32.825940 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:02:32.827765 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:02:32.829114 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:02:32.838385 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:02:32.850037 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:02:32.867987 (MainThread): Partial parsing not enabled
2020-05-25 12:02:32.897094 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:02:32.897215 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:02:32.911695 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:02:32.911793 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:02:32.917992 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:02:32.918078 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:02:32.984098 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-25 12:02:33.136351 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 2 sources
2020-05-25 12:02:33.138667 (MainThread): 
2020-05-25 12:02:33.138951 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 12:02:33.139039 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:02:33.144963 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-25 12:02:33.145082 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-25 12:02:33.146016 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:02:34.527618 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:02:36.345127 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 12:02:36.345613 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-25 12:02:36.345846 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:02:36.772399 (MainThread): 22:02:36 | Concurrency: 1 threads (target='dev')
2020-05-25 12:02:36.772681 (MainThread): 22:02:36 | 
2020-05-25 12:02:36.776388 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:02:36.776606 (Thread-1): 22:02:36 | 1 of 3 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-05-25 12:02:36.776927 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:02:36.777028 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 12:02:36.777152 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:02:36.794914 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:02:36.795338 (Thread-1): finished collecting timing info
2020-05-25 12:02:36.833824 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:02:37.553148 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:02:37.553738 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:02:40.599114 (Thread-1): finished collecting timing info
2020-05-25 12:02:40.600012 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '714e1423-a8ff-43c0-902f-82b803794b42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1237205b0>]}
2020-05-25 12:02:40.600389 (Thread-1): 22:02:40 | 1 of 3 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 3.82s]
2020-05-25 12:02:40.600559 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:02:40.600728 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:02:40.600895 (Thread-1): 22:02:40 | 2 of 3 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-05-25 12:02:40.601343 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:02:40.601472 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-05-25 12:02:40.601589 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:02:40.609689 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:02:40.610144 (Thread-1): finished collecting timing info
2020-05-25 12:02:40.614089 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:02:41.108428 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:02:41.109093 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:02:44.477073 (Thread-1): finished collecting timing info
2020-05-25 12:02:44.477957 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '714e1423-a8ff-43c0-902f-82b803794b42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1237c0b20>]}
2020-05-25 12:02:44.478283 (Thread-1): 22:02:44 | 2 of 3 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.88s]
2020-05-25 12:02:44.478460 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:02:44.479051 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:02:44.479244 (Thread-1): 22:02:44 | 3 of 3 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-05-25 12:02:44.479702 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:02:44.479859 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-05-25 12:02:44.479974 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:02:44.489058 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:02:44.489477 (Thread-1): finished collecting timing info
2020-05-25 12:02:44.493465 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:02:44.906839 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:02:44.907470 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-05-25 12:02:48.192200 (Thread-1): finished collecting timing info
2020-05-25 12:02:48.193091 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '714e1423-a8ff-43c0-902f-82b803794b42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123740ac0>]}
2020-05-25 12:02:48.193426 (Thread-1): 22:02:48 | 3 of 3 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.71s]
2020-05-25 12:02:48.193603 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:02:48.195066 (MainThread): 22:02:48 | 
2020-05-25 12:02:48.195248 (MainThread): 22:02:48 | Finished running 3 table models in 15.06s.
2020-05-25 12:02:48.195387 (MainThread): Connection 'master' was left open.
2020-05-25 12:02:48.195490 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-05-25 12:02:48.204136 (MainThread): 
2020-05-25 12:02:48.204291 (MainThread): Completed successfully
2020-05-25 12:02:48.204476 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-05-25 12:02:48.204724 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1237187f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123534610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123534970>]}
2020-05-25 12:02:48.204940 (MainThread): Flushing usage events
2020-05-25 12:02:50.458640 (MainThread): Running with dbt=0.16.1
2020-05-25 12:02:50.819228 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-05-25 12:02:50.820299 (MainThread): Tracking: tracking
2020-05-25 12:02:50.827409 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119785e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119794580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119794550>]}
2020-05-25 12:02:50.827962 (MainThread): Checking target/*
2020-05-25 12:02:50.829845 (MainThread):  Cleaned target/*
2020-05-25 12:02:50.829992 (MainThread): Checking dbt_modules/*
2020-05-25 12:02:50.830408 (MainThread):  Cleaned dbt_modules/*
2020-05-25 12:02:50.830510 (MainThread): Finished cleaning all paths.
2020-05-25 12:02:50.830757 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119785e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119794520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1197944f0>]}
2020-05-25 12:02:50.830966 (MainThread): Flushing usage events
2020-05-25 12:22:15.314863 (MainThread): Running with dbt=0.16.1
2020-05-25 12:22:15.676883 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-25 12:22:15.678486 (MainThread): Tracking: tracking
2020-05-25 12:22:15.683947 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1247d27f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1247e2790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1247e2760>]}
2020-05-25 12:22:15.705014 (MainThread): Partial parsing not enabled
2020-05-25 12:22:15.707753 (MainThread): Parsing macros/core.sql
2020-05-25 12:22:15.712683 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:22:15.720806 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:22:15.723210 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:22:15.740264 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:22:15.774497 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:22:15.794693 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:22:15.797143 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:22:15.803531 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:22:15.815753 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:22:15.822448 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:22:15.828532 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:22:15.833336 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:22:15.834426 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:22:15.835883 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:22:15.838083 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:22:15.840737 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:22:15.850089 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:22:15.852339 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:22:15.853902 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:22:15.894592 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:22:15.896005 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:22:15.897197 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:22:15.898816 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:22:15.901738 (MainThread): Parsing macros/etc.sql
2020-05-25 12:22:15.903124 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:22:15.911190 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:22:15.932282 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:22:15.934904 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:22:15.936794 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:22:15.946416 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:22:15.958479 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:22:15.977368 (MainThread): Partial parsing not enabled
2020-05-25 12:22:16.007793 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:22:16.007924 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:22:16.023305 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:22:16.023432 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:22:16.030754 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:22:16.030886 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:22:16.036769 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:22:16.036912 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:22:16.109393 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-25 12:22:16.270480 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:22:16.273345 (MainThread): 
2020-05-25 12:22:16.273496 (MainThread): 22:22:16 | Concurrency: 1 threads (target='dev')
2020-05-25 12:22:16.273602 (MainThread): 22:22:16 | 
2020-05-25 12:22:16.278374 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:22:16.278740 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:22:16.278840 (Thread-1): Opening a new connection, currently in state init
2020-05-25 12:22:16.278933 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:22:16.293288 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:22:16.293845 (Thread-1): finished collecting timing info
2020-05-25 12:22:16.294093 (Thread-1): finished collecting timing info
2020-05-25 12:22:16.294450 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:22:16.294575 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:22:16.294797 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:22:16.294884 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:22:16.294967 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:22:16.301184 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:22:16.301505 (Thread-1): finished collecting timing info
2020-05-25 12:22:16.301723 (Thread-1): finished collecting timing info
2020-05-25 12:22:16.302059 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:22:16.302181 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:22:16.302399 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:22:16.302486 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:22:16.302568 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:22:16.310449 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:22:16.310852 (Thread-1): finished collecting timing info
2020-05-25 12:22:16.311080 (Thread-1): finished collecting timing info
2020-05-25 12:22:16.311437 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:22:16.311559 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:22:16.311786 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:22:16.311872 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:22:16.311954 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:22:16.318828 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:22:16.319111 (Thread-1): finished collecting timing info
2020-05-25 12:22:16.319303 (Thread-1): finished collecting timing info
2020-05-25 12:22:16.319600 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:22:16.320443 (MainThread): Connection 'model.dbt_servian_demo.Weekly_national_trends' was properly closed.
2020-05-25 12:22:16.320532 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-05-25 12:22:16.329286 (MainThread): 22:22:16 | Done.
2020-05-25 12:22:16.329471 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124827220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124964b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124964b80>]}
2020-05-25 12:22:16.329647 (MainThread): Flushing usage events
2020-05-25 12:22:18.314453 (MainThread): Running with dbt=0.16.1
2020-05-25 12:22:18.675127 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-25 12:22:18.675951 (MainThread): Tracking: tracking
2020-05-25 12:22:18.681669 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11689bfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1168ab6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1168ab6a0>]}
2020-05-25 12:22:18.703125 (MainThread): Partial parsing not enabled
2020-05-25 12:22:18.704935 (MainThread): Parsing macros/core.sql
2020-05-25 12:22:18.709304 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:22:18.716835 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:22:18.718607 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:22:18.734851 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:22:18.768599 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:22:18.788885 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:22:18.790708 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:22:18.796544 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:22:18.808889 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:22:18.815397 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:22:18.821372 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:22:18.826090 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:22:18.826985 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:22:18.827983 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:22:18.829508 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:22:18.831440 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:22:18.840021 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:22:18.841882 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:22:18.842933 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:22:18.883456 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:22:18.884570 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:22:18.885427 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:22:18.886555 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:22:18.888727 (MainThread): Parsing macros/etc.sql
2020-05-25 12:22:18.889358 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:22:18.896642 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:22:18.917393 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:22:18.919254 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:22:18.920626 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:22:18.929819 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:22:18.941528 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:22:18.959681 (MainThread): Partial parsing not enabled
2020-05-25 12:22:18.989160 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:22:18.989282 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:22:19.003581 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:22:19.003681 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:22:19.010068 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:22:19.010163 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:22:19.015063 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:22:19.015231 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:22:19.084278 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-25 12:22:19.241614 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:22:19.244425 (MainThread): 
2020-05-25 12:22:19.244703 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 12:22:19.244788 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:22:19.252599 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-25 12:22:19.252832 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-25 12:22:19.253763 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:22:20.607780 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:22:21.957502 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 12:22:21.957958 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-25 12:22:21.958269 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:22:22.364837 (MainThread): 22:22:22 | Concurrency: 1 threads (target='dev')
2020-05-25 12:22:22.365063 (MainThread): 22:22:22 | 
2020-05-25 12:22:22.368555 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:22:22.368741 (Thread-1): 22:22:22 | 1 of 4 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-05-25 12:22:22.369033 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:22:22.369130 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 12:22:22.369248 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:22:22.386752 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:22:22.387200 (Thread-1): finished collecting timing info
2020-05-25 12:22:22.423926 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:22:23.180476 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:22:23.181096 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:22:26.019979 (Thread-1): finished collecting timing info
2020-05-25 12:22:26.020910 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e21b882c-a54c-42ce-a2b6-c5df6706af8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116b3f9d0>]}
2020-05-25 12:22:26.021310 (Thread-1): 22:22:26 | 1 of 4 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 3.65s]
2020-05-25 12:22:26.021495 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:22:26.021679 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:22:26.021857 (Thread-1): 22:22:26 | 2 of 4 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-05-25 12:22:26.022357 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:22:26.022501 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-05-25 12:22:26.022645 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:22:26.031007 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:22:26.031469 (Thread-1): finished collecting timing info
2020-05-25 12:22:26.035464 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:22:26.604629 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:22:26.605291 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:22:29.437898 (Thread-1): finished collecting timing info
2020-05-25 12:22:29.438780 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e21b882c-a54c-42ce-a2b6-c5df6706af8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116b46a60>]}
2020-05-25 12:22:29.439102 (Thread-1): 22:22:29 | 2 of 4 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.42s]
2020-05-25 12:22:29.439279 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:22:29.439460 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:22:29.439639 (Thread-1): 22:22:29 | 3 of 4 START view model covid_19_italy_insights.Weekly_national_trends [RUN]
2020-05-25 12:22:29.440229 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:22:29.440377 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-05-25 12:22:29.440510 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:22:29.451266 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:22:29.451749 (Thread-1): finished collecting timing info
2020-05-25 12:22:29.469901 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:22:29.470365 (Thread-1): On model.dbt_servian_demo.Weekly_national_trends: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trends"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trends`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,

	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	
FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 12:22:31.361579 (Thread-1): finished collecting timing info
2020-05-25 12:22:31.362466 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e21b882c-a54c-42ce-a2b6-c5df6706af8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1168c0fd0>]}
2020-05-25 12:22:31.362797 (Thread-1): 22:22:31 | 3 of 4 OK created view model covid_19_italy_insights.Weekly_national_trends [CREATE VIEW in 1.92s]
2020-05-25 12:22:31.362976 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:22:31.363158 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:22:31.363352 (Thread-1): 22:22:31 | 4 of 4 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-05-25 12:22:31.363739 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:22:31.363868 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trends).
2020-05-25 12:22:31.363975 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:22:31.372871 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:22:31.373326 (Thread-1): finished collecting timing info
2020-05-25 12:22:31.377335 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:22:31.826250 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:22:31.826978 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-05-25 12:22:35.092761 (Thread-1): finished collecting timing info
2020-05-25 12:22:35.093652 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e21b882c-a54c-42ce-a2b6-c5df6706af8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116b46a60>]}
2020-05-25 12:22:35.093994 (Thread-1): 22:22:35 | 4 of 4 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.73s]
2020-05-25 12:22:35.094174 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:22:35.095689 (MainThread): 22:22:35 | 
2020-05-25 12:22:35.095846 (MainThread): 22:22:35 | Finished running 3 table models, 1 view model in 15.85s.
2020-05-25 12:22:35.095973 (MainThread): Connection 'master' was left open.
2020-05-25 12:22:35.096071 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-05-25 12:22:35.106855 (MainThread): 
2020-05-25 12:22:35.107008 (MainThread): Completed successfully
2020-05-25 12:22:35.107138 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2020-05-25 12:22:35.107355 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116978070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116a36040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116a36940>]}
2020-05-25 12:22:35.107559 (MainThread): Flushing usage events
2020-05-25 12:22:37.594532 (MainThread): Running with dbt=0.16.1
2020-05-25 12:22:37.956736 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-05-25 12:22:37.957674 (MainThread): Tracking: tracking
2020-05-25 12:22:37.963910 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12265cf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12266b6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12266b6a0>]}
2020-05-25 12:22:37.964492 (MainThread): Checking target/*
2020-05-25 12:22:37.966238 (MainThread):  Cleaned target/*
2020-05-25 12:22:37.966363 (MainThread): Checking dbt_modules/*
2020-05-25 12:22:37.966819 (MainThread):  Cleaned dbt_modules/*
2020-05-25 12:22:37.966917 (MainThread): Finished cleaning all paths.
2020-05-25 12:22:37.967094 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12265cf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12266b670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12266b640>]}
2020-05-25 12:22:37.967254 (MainThread): Flushing usage events
2020-05-25 12:31:51.883728 (MainThread): Running with dbt=0.16.1
2020-05-25 12:31:52.243421 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-25 12:31:52.245014 (MainThread): Tracking: tracking
2020-05-25 12:31:52.251668 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117a60670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117a70730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117a70700>]}
2020-05-25 12:31:52.272333 (MainThread): Partial parsing not enabled
2020-05-25 12:31:52.274501 (MainThread): Parsing macros/core.sql
2020-05-25 12:31:52.279314 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:31:52.287071 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:31:52.289348 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:31:52.306414 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:31:52.339614 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:31:52.359941 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:31:52.362729 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:31:52.369738 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:31:52.382407 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:31:52.389154 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:31:52.395274 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:31:52.400229 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:31:52.401337 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:31:52.402629 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:31:52.404425 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:31:52.406668 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:31:52.415628 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:31:52.417920 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:31:52.419480 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:31:52.460143 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:31:52.461483 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:31:52.462607 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:31:52.464252 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:31:52.466943 (MainThread): Parsing macros/etc.sql
2020-05-25 12:31:52.467976 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:31:52.475772 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:31:52.497072 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:31:52.499781 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:31:52.501859 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:31:52.511446 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:31:52.523759 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:31:52.547737 (MainThread): Partial parsing not enabled
2020-05-25 12:31:52.548660 (MainThread): Parsing macros/project_macros.sql
2020-05-25 12:31:52.580302 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:31:52.580435 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:31:52.596855 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:31:52.597071 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:31:52.607950 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:31:52.608091 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:31:52.618986 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:31:52.619133 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:31:52.624975 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:31:52.625073 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:31:52.698068 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-25 12:31:52.860967 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:31:52.863780 (MainThread): 
2020-05-25 12:31:52.863912 (MainThread): 22:31:52 | Concurrency: 1 threads (target='dev')
2020-05-25 12:31:52.864005 (MainThread): 22:31:52 | 
2020-05-25 12:31:52.868703 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:31:52.869076 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:31:52.869168 (Thread-1): Opening a new connection, currently in state init
2020-05-25 12:31:52.869258 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:31:52.883496 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:31:52.884019 (Thread-1): finished collecting timing info
2020-05-25 12:31:52.884248 (Thread-1): finished collecting timing info
2020-05-25 12:31:52.884605 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:31:52.884720 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:31:52.884930 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:31:52.885012 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:31:52.885089 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:31:52.890629 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:31:52.890968 (Thread-1): finished collecting timing info
2020-05-25 12:31:52.891176 (Thread-1): finished collecting timing info
2020-05-25 12:31:52.891491 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:31:52.891600 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:31:52.891801 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:31:52.891879 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:31:52.891952 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:31:52.899229 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:31:52.899630 (Thread-1): finished collecting timing info
2020-05-25 12:31:52.899847 (Thread-1): finished collecting timing info
2020-05-25 12:31:52.900190 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:31:52.900302 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:31:52.900506 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:31:52.900584 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:31:52.900658 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:31:52.907732 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:31:52.908036 (Thread-1): finished collecting timing info
2020-05-25 12:31:52.908230 (Thread-1): finished collecting timing info
2020-05-25 12:31:52.908541 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:31:52.908649 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:31:52.908853 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:31:52.908981 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:31:52.909081 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:31:52.915655 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:31:52.915987 (Thread-1): finished collecting timing info
2020-05-25 12:31:52.916191 (Thread-1): finished collecting timing info
2020-05-25 12:31:52.916512 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:31:52.917232 (MainThread): Connection 'model.dbt_servian_demo.Weekly_national_trends' was properly closed.
2020-05-25 12:31:52.917320 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-05-25 12:31:52.926920 (MainThread): 22:31:52 | Done.
2020-05-25 12:31:52.927090 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117a85e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117c21940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117c21c70>]}
2020-05-25 12:31:52.927321 (MainThread): Flushing usage events
2020-05-25 12:31:54.962623 (MainThread): Running with dbt=0.16.1
2020-05-25 12:31:55.323014 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-25 12:31:55.323949 (MainThread): Tracking: tracking
2020-05-25 12:31:55.329552 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a8f3af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a902700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a9026d0>]}
2020-05-25 12:31:55.349551 (MainThread): Partial parsing not enabled
2020-05-25 12:31:55.351338 (MainThread): Parsing macros/core.sql
2020-05-25 12:31:55.355755 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:31:55.363555 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:31:55.365340 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:31:55.381693 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:31:55.415631 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:31:55.436102 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:31:55.438002 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:31:55.443979 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:31:55.456436 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:31:55.462944 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:31:55.468947 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:31:55.473648 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:31:55.474571 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:31:55.475589 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:31:55.477147 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:31:55.479121 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:31:55.487738 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:31:55.489641 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:31:55.490666 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:31:55.531318 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:31:55.532431 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:31:55.533311 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:31:55.534485 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:31:55.536736 (MainThread): Parsing macros/etc.sql
2020-05-25 12:31:55.537367 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:31:55.544676 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:31:55.565504 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:31:55.567373 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:31:55.568741 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:31:55.577868 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:31:55.589560 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:31:55.607316 (MainThread): Partial parsing not enabled
2020-05-25 12:31:55.607641 (MainThread): Parsing macros/project_macros.sql
2020-05-25 12:31:55.638505 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:31:55.638640 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:31:55.653455 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:31:55.653548 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:31:55.659303 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:31:55.659390 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:31:55.668035 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:31:55.668127 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:31:55.673047 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:31:55.673131 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:31:55.742971 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-25 12:31:55.904732 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:31:55.907520 (MainThread): 
2020-05-25 12:31:55.907777 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 12:31:55.907855 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:31:55.916588 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-25 12:31:55.916818 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-25 12:31:55.917727 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:31:57.252550 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:31:58.614121 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 12:31:58.614591 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-25 12:31:58.614917 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:31:59.047109 (MainThread): 22:31:59 | Concurrency: 1 threads (target='dev')
2020-05-25 12:31:59.047348 (MainThread): 22:31:59 | 
2020-05-25 12:31:59.051298 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:31:59.051528 (Thread-1): 22:31:59 | 1 of 5 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-05-25 12:31:59.051844 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:31:59.051946 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 12:31:59.052068 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:31:59.070126 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:31:59.070599 (Thread-1): finished collecting timing info
2020-05-25 12:31:59.109496 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:31:59.944424 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:31:59.945031 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:32:02.703494 (Thread-1): finished collecting timing info
2020-05-25 12:32:02.704429 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '81e59465-061a-4be4-8e2c-ed69fd7cc6d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ab72400>]}
2020-05-25 12:32:02.704820 (Thread-1): 22:32:02 | 1 of 5 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 3.65s]
2020-05-25 12:32:02.705002 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:32:02.705186 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:32:02.705369 (Thread-1): 22:32:02 | 2 of 5 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-05-25 12:32:02.705871 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:32:02.706016 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-05-25 12:32:02.706160 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:32:02.714228 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:32:02.714661 (Thread-1): finished collecting timing info
2020-05-25 12:32:02.718606 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:32:03.141695 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:32:03.142328 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:32:06.013878 (Thread-1): finished collecting timing info
2020-05-25 12:32:06.014768 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '81e59465-061a-4be4-8e2c-ed69fd7cc6d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa58eb0>]}
2020-05-25 12:32:06.015098 (Thread-1): 22:32:06 | 2 of 5 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.31s]
2020-05-25 12:32:06.015270 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:32:06.015445 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:32:06.015618 (Thread-1): 22:32:06 | 3 of 5 START view model covid_19_italy_insights.Weekly_national_trend_macro [RUN]
2020-05-25 12:32:06.016229 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:32:06.016380 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-05-25 12:32:06.016505 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:32:06.026019 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:32:06.026447 (Thread-1): finished collecting timing info
2020-05-25 12:32:06.044434 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:32:06.044868 (Thread-1): On model.dbt_servian_demo.Weekly_national_trend_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trend_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trend_macro`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,
	
	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	

FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 12:32:07.766400 (Thread-1): finished collecting timing info
2020-05-25 12:32:07.767131 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '81e59465-061a-4be4-8e2c-ed69fd7cc6d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa6f8e0>]}
2020-05-25 12:32:07.767403 (Thread-1): 22:32:07 | 3 of 5 OK created view model covid_19_italy_insights.Weekly_national_trend_macro [CREATE VIEW in 1.75s]
2020-05-25 12:32:07.767550 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:32:07.767754 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:32:07.768163 (Thread-1): 22:32:07 | 4 of 5 START view model covid_19_italy_insights.Weekly_national_trends [RUN]
2020-05-25 12:32:07.768688 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:32:07.768804 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trend_macro).
2020-05-25 12:32:07.768910 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:32:07.778522 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:32:07.778995 (Thread-1): finished collecting timing info
2020-05-25 12:32:07.784465 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:32:07.784885 (Thread-1): On model.dbt_servian_demo.Weekly_national_trends: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trends"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trends`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,

	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	
FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 12:32:09.889048 (Thread-1): finished collecting timing info
2020-05-25 12:32:09.890004 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '81e59465-061a-4be4-8e2c-ed69fd7cc6d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11abad250>]}
2020-05-25 12:32:09.890343 (Thread-1): 22:32:09 | 4 of 5 OK created view model covid_19_italy_insights.Weekly_national_trends [CREATE VIEW in 2.12s]
2020-05-25 12:32:09.890525 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:32:09.890708 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:32:09.890896 (Thread-1): 22:32:09 | 5 of 5 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-05-25 12:32:09.891296 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:32:09.891418 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trends).
2020-05-25 12:32:09.891529 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:32:09.900186 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:32:09.900646 (Thread-1): finished collecting timing info
2020-05-25 12:32:09.904468 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:32:10.501752 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:32:10.502423 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-05-25 12:32:13.368950 (Thread-1): finished collecting timing info
2020-05-25 12:32:13.369853 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '81e59465-061a-4be4-8e2c-ed69fd7cc6d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa3dee0>]}
2020-05-25 12:32:13.370183 (Thread-1): 22:32:13 | 5 of 5 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.48s]
2020-05-25 12:32:13.370330 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:32:13.371632 (MainThread): 22:32:13 | 
2020-05-25 12:32:13.371796 (MainThread): 22:32:13 | Finished running 3 table models, 2 view models in 17.46s.
2020-05-25 12:32:13.371924 (MainThread): Connection 'master' was left open.
2020-05-25 12:32:13.372022 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-05-25 12:32:13.385273 (MainThread): 
2020-05-25 12:32:13.385454 (MainThread): Completed successfully
2020-05-25 12:32:13.385588 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2020-05-25 12:32:13.385810 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a917b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aaaba30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aaabee0>]}
2020-05-25 12:32:13.386022 (MainThread): Flushing usage events
2020-05-25 12:32:15.578326 (MainThread): Running with dbt=0.16.1
2020-05-25 12:32:15.936906 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-05-25 12:32:15.937736 (MainThread): Tracking: tracking
2020-05-25 12:32:15.943408 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dc6ce80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dc7d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dc7d5b0>]}
2020-05-25 12:32:15.943969 (MainThread): Checking target/*
2020-05-25 12:32:15.945878 (MainThread):  Cleaned target/*
2020-05-25 12:32:15.945988 (MainThread): Checking dbt_modules/*
2020-05-25 12:32:15.946535 (MainThread):  Cleaned dbt_modules/*
2020-05-25 12:32:15.946633 (MainThread): Finished cleaning all paths.
2020-05-25 12:32:15.946807 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dc6ce80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dc7d580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dc7d550>]}
2020-05-25 12:32:15.946981 (MainThread): Flushing usage events
2020-05-25 12:40:48.664904 (MainThread): Running with dbt=0.16.1
2020-05-25 12:40:49.022423 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-25 12:40:49.023113 (MainThread): Tracking: tracking
2020-05-25 12:40:49.029262 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121e09fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121e196a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121e19670>]}
2020-05-25 12:40:49.049679 (MainThread): Partial parsing not enabled
2020-05-25 12:40:49.052259 (MainThread): Parsing macros/core.sql
2020-05-25 12:40:49.056508 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:40:49.064114 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:40:49.065822 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:40:49.081686 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:40:49.115462 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:40:49.135087 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:40:49.136826 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:40:49.142648 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:40:49.154680 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:40:49.161022 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:40:49.166939 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:40:49.171460 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:40:49.172344 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:40:49.173327 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:40:49.174825 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:40:49.176718 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:40:49.185055 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:40:49.186976 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:40:49.187966 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:40:49.228314 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:40:49.229441 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:40:49.230305 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:40:49.231336 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:40:49.233738 (MainThread): Parsing macros/etc.sql
2020-05-25 12:40:49.234470 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:40:49.241770 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:40:49.262235 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:40:49.264099 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:40:49.265466 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:40:49.274770 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:40:49.286541 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:40:49.304753 (MainThread): Partial parsing not enabled
2020-05-25 12:40:49.305101 (MainThread): Parsing macros/project_macros.sql
2020-05-25 12:40:49.335843 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:40:49.335958 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:40:49.350178 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:40:49.350267 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:40:49.356568 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:40:49.356656 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:40:49.365284 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:40:49.365402 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:40:49.371552 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:40:49.371638 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:40:49.376713 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:40:49.376803 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:40:49.447466 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-25 12:40:49.614040 (MainThread): Found 6 models, 0 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:40:49.617055 (MainThread): 
2020-05-25 12:40:49.617180 (MainThread): 22:40:49 | Concurrency: 1 threads (target='dev')
2020-05-25 12:40:49.617270 (MainThread): 22:40:49 | 
2020-05-25 12:40:49.619710 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:40:49.620001 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:40:49.620086 (Thread-1): Opening a new connection, currently in state init
2020-05-25 12:40:49.620165 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:40:49.632877 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:40:49.633430 (Thread-1): finished collecting timing info
2020-05-25 12:40:49.633650 (Thread-1): finished collecting timing info
2020-05-25 12:40:49.633976 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:40:49.634086 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:40:49.634282 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:40:49.634359 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:40:49.634433 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:40:49.640014 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:40:49.640285 (Thread-1): finished collecting timing info
2020-05-25 12:40:49.640497 (Thread-1): finished collecting timing info
2020-05-25 12:40:49.640803 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:40:49.640911 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:40:49.641108 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:40:49.641186 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:40:49.641260 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:40:49.647647 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 12:40:49.647973 (Thread-1): finished collecting timing info
2020-05-25 12:40:49.648183 (Thread-1): finished collecting timing info
2020-05-25 12:40:49.648509 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:40:49.648623 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:40:49.648833 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:40:49.648913 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:40:49.648991 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:40:49.656180 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:40:49.656542 (Thread-1): finished collecting timing info
2020-05-25 12:40:49.656744 (Thread-1): finished collecting timing info
2020-05-25 12:40:49.657057 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:40:49.657166 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:40:49.657365 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:40:49.657442 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:40:49.657515 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:40:49.664810 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:40:49.665171 (Thread-1): finished collecting timing info
2020-05-25 12:40:49.665386 (Thread-1): finished collecting timing info
2020-05-25 12:40:49.665714 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:40:49.665826 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:40:49.666030 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:40:49.666109 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:40:49.666186 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:40:49.672815 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:40:49.673128 (Thread-1): finished collecting timing info
2020-05-25 12:40:49.673325 (Thread-1): finished collecting timing info
2020-05-25 12:40:49.673631 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:40:49.674298 (MainThread): Connection 'model.dbt_servian_demo.Weekly_national_trends' was properly closed.
2020-05-25 12:40:49.674387 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-05-25 12:40:49.686371 (MainThread): 22:40:49 | Done.
2020-05-25 12:40:49.686551 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121e766d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121e40fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f017370>]}
2020-05-25 12:40:49.686727 (MainThread): Flushing usage events
2020-05-25 12:40:51.710512 (MainThread): Running with dbt=0.16.1
2020-05-25 12:40:52.081928 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-25 12:40:52.082756 (MainThread): Tracking: tracking
2020-05-25 12:40:52.088593 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122964670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122973730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122973700>]}
2020-05-25 12:40:52.109873 (MainThread): Partial parsing not enabled
2020-05-25 12:40:52.111626 (MainThread): Parsing macros/core.sql
2020-05-25 12:40:52.116105 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:40:52.123557 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:40:52.125254 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:40:52.141315 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:40:52.174709 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:40:52.194821 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:40:52.196629 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:40:52.202451 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:40:52.214698 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:40:52.221146 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:40:52.227095 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:40:52.231750 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:40:52.232659 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:40:52.233678 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:40:52.235272 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:40:52.237189 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:40:52.245640 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:40:52.247483 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:40:52.248471 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:40:52.288547 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:40:52.289632 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:40:52.290486 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:40:52.291513 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:40:52.293678 (MainThread): Parsing macros/etc.sql
2020-05-25 12:40:52.294300 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:40:52.301646 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:40:52.322070 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:40:52.323911 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:40:52.325262 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:40:52.334437 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:40:52.346248 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:40:52.364133 (MainThread): Partial parsing not enabled
2020-05-25 12:40:52.364463 (MainThread): Parsing macros/project_macros.sql
2020-05-25 12:40:52.394875 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:40:52.395081 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:40:52.410431 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:40:52.410534 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:40:52.416915 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:40:52.417005 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:40:52.424957 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:40:52.425049 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:40:52.431941 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:40:52.432052 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:40:52.437050 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:40:52.437139 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:40:52.507219 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-25 12:40:52.673309 (MainThread): Found 6 models, 0 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:40:52.676683 (MainThread): 
2020-05-25 12:40:52.676981 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 12:40:52.677066 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:40:52.687311 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-25 12:40:52.687437 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-25 12:40:52.688283 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:40:54.089417 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:40:55.485135 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 12:40:55.485529 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-25 12:40:55.485784 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:40:55.888881 (MainThread): 22:40:55 | Concurrency: 1 threads (target='dev')
2020-05-25 12:40:55.889109 (MainThread): 22:40:55 | 
2020-05-25 12:40:55.892852 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:40:55.893064 (Thread-1): 22:40:55 | 1 of 6 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-05-25 12:40:55.893391 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:40:55.893492 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 12:40:55.893622 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:40:55.911293 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:40:55.911753 (Thread-1): finished collecting timing info
2020-05-25 12:40:55.950607 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:40:56.737350 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:40:56.737953 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:40:59.924752 (Thread-1): finished collecting timing info
2020-05-25 12:40:59.925710 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '198fbdcc-53ce-4408-9765-659025470e8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122b005b0>]}
2020-05-25 12:40:59.926102 (Thread-1): 22:40:59 | 1 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 4.03s]
2020-05-25 12:40:59.926289 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:40:59.926474 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:40:59.926660 (Thread-1): 22:40:59 | 2 of 6 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-05-25 12:40:59.927000 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:40:59.927127 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-05-25 12:40:59.927253 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:40:59.935725 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:40:59.936183 (Thread-1): finished collecting timing info
2020-05-25 12:40:59.940222 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:41:00.422568 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:41:00.423257 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:41:03.355649 (Thread-1): finished collecting timing info
2020-05-25 12:41:03.356537 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '198fbdcc-53ce-4408-9765-659025470e8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1229c74c0>]}
2020-05-25 12:41:03.356872 (Thread-1): 22:41:03 | 2 of 6 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.43s]
2020-05-25 12:41:03.357050 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:41:03.357235 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:41:03.357412 (Thread-1): 22:41:03 | 3 of 6 START view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [RUN]
2020-05-25 12:41:03.357825 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:41:03.358260 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-05-25 12:41:03.358427 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:41:03.367494 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 12:41:03.367988 (Thread-1): finished collecting timing info
2020-05-25 12:41:03.386524 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 12:41:03.387001 (Thread-1): On model.dbt_servian_demo.Weekly_Total_Confirmed_Cases: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_Total_Confirmed_Cases`
  OPTIONS()
  as (
     

SELECT
  TIMESTAMP_TRUNC(date,WEEK),
  country,
  region_name,
  province_name,
  province_abbreviation,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM 
	`bigquery-public-data`.`covid19_italy`.`data_by_province`

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
      , 
   
     4
      , 
   
     5
     
   

  );

2020-05-25 12:41:04.524501 (Thread-1): finished collecting timing info
2020-05-25 12:41:04.525083 (Thread-1): Database Error in model Weekly_Total_Confirmed_Cases (models/covid_19_italy_insights/Weekly_Total_Confirmed_Cases.sql)
  CREATE VIEW columns must be named, but column 1 has no name at [6:6]
  compiled SQL at target/run/dbt_servian_demo/covid_19_italy_insights/Weekly_Total_Confirmed_Cases.sql
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3079, in done
    self._query_results = self._client._get_query_results(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1286, in _get_query_results
    resource = self._call_api(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/graham-hamza-bq-dbt-webinar/queries/0b50b16c-7f6a-46c7-94ad-6de87eb8170c?maxResults=0&location=US: CREATE VIEW columns must be named, but column 1 has no name at [6:6]

(job ID: 0b50b16c-7f6a-46c7-94ad-6de87eb8170c)

                                                                       -----Query Job SQL Follows-----                                                                        

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"} */
   2:
   3:
   4:  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_Total_Confirmed_Cases`
   5:  OPTIONS()
   6:  as (
   7:     
   8:
   9:SELECT
  10:  TIMESTAMP_TRUNC(date,WEEK),
  11:  country,
  12:  region_name,
  13:  province_name,
  14:  province_abbreviation,
  15:  SUM(confirmed_cases) as Total_Confirmed_Cases
  16:FROM 
  17:	`bigquery-public-data`.`covid19_italy`.`data_by_province`
  18:
  19:  GROUP BY
  20:   
  21:     1
  22:      , 
  23:   
  24:     2
  25:      , 
  26:   
  27:     3
  28:      , 
  29:   
  30:     4
  31:      , 
  32:   
  33:     5
  34:     
  35:   
  36:
  37:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 217, in execute
    return self.connections.execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model Weekly_Total_Confirmed_Cases (models/covid_19_italy_insights/Weekly_Total_Confirmed_Cases.sql)
  CREATE VIEW columns must be named, but column 1 has no name at [6:6]
  compiled SQL at target/run/dbt_servian_demo/covid_19_italy_insights/Weekly_Total_Confirmed_Cases.sql
2020-05-25 12:41:04.538523 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '198fbdcc-53ce-4408-9765-659025470e8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122b2cbe0>]}
2020-05-25 12:41:04.538794 (Thread-1): 22:41:04 | 3 of 6 ERROR creating view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [ERROR in 1.18s]
2020-05-25 12:41:04.538936 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:41:04.539087 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:41:04.539228 (Thread-1): 22:41:04 | 4 of 6 START view model covid_19_italy_insights.Weekly_national_trend_macro [RUN]
2020-05-25 12:41:04.539524 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:41:04.539778 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_Total_Confirmed_Cases).
2020-05-25 12:41:04.539900 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:41:04.550039 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:41:04.550572 (Thread-1): finished collecting timing info
2020-05-25 12:41:04.555400 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:41:04.555851 (Thread-1): On model.dbt_servian_demo.Weekly_national_trend_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trend_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trend_macro`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,
	
	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	

FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 12:41:06.445427 (Thread-1): finished collecting timing info
2020-05-25 12:41:06.446307 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '198fbdcc-53ce-4408-9765-659025470e8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122c6f730>]}
2020-05-25 12:41:06.446634 (Thread-1): 22:41:06 | 4 of 6 OK created view model covid_19_italy_insights.Weekly_national_trend_macro [CREATE VIEW in 1.91s]
2020-05-25 12:41:06.446809 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:41:06.446992 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:41:06.447177 (Thread-1): 22:41:06 | 5 of 6 START view model covid_19_italy_insights.Weekly_national_trends [RUN]
2020-05-25 12:41:06.447605 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:41:06.447731 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trend_macro).
2020-05-25 12:41:06.447846 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:41:06.457643 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:41:06.458069 (Thread-1): finished collecting timing info
2020-05-25 12:41:06.462700 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:41:06.463110 (Thread-1): On model.dbt_servian_demo.Weekly_national_trends: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trends"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trends`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,

	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	
FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 12:41:08.329448 (Thread-1): finished collecting timing info
2020-05-25 12:41:08.330345 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '198fbdcc-53ce-4408-9765-659025470e8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122b5de80>]}
2020-05-25 12:41:08.330680 (Thread-1): 22:41:08 | 5 of 6 OK created view model covid_19_italy_insights.Weekly_national_trends [CREATE VIEW in 1.88s]
2020-05-25 12:41:08.330860 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:41:08.331064 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:41:08.331230 (Thread-1): 22:41:08 | 6 of 6 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-05-25 12:41:08.331673 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:41:08.331815 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trends).
2020-05-25 12:41:08.331929 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:41:08.341028 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:41:08.341462 (Thread-1): finished collecting timing info
2020-05-25 12:41:08.345277 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:41:08.734294 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:41:08.734962 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-05-25 12:41:11.745484 (Thread-1): finished collecting timing info
2020-05-25 12:41:11.746376 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '198fbdcc-53ce-4408-9765-659025470e8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122b2cbe0>]}
2020-05-25 12:41:11.746706 (Thread-1): 22:41:11 | 6 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.41s]
2020-05-25 12:41:11.746883 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:41:11.748415 (MainThread): 22:41:11 | 
2020-05-25 12:41:11.748602 (MainThread): 22:41:11 | Finished running 3 table models, 3 view models in 19.07s.
2020-05-25 12:41:11.748755 (MainThread): Connection 'master' was left open.
2020-05-25 12:41:11.748871 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-05-25 12:41:11.763974 (MainThread): 
2020-05-25 12:41:11.764120 (MainThread): Completed with 1 error and 0 warnings:
2020-05-25 12:41:11.764238 (MainThread): 
2020-05-25 12:41:11.764351 (MainThread): Database Error in model Weekly_Total_Confirmed_Cases (models/covid_19_italy_insights/Weekly_Total_Confirmed_Cases.sql)
2020-05-25 12:41:11.764454 (MainThread):   CREATE VIEW columns must be named, but column 1 has no name at [6:6]
2020-05-25 12:41:11.764548 (MainThread):   compiled SQL at target/run/dbt_servian_demo/covid_19_italy_insights/Weekly_Total_Confirmed_Cases.sql
2020-05-25 12:41:11.764655 (MainThread): 
Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
2020-05-25 12:41:11.764853 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122bee7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122beee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122bee970>]}
2020-05-25 12:41:11.765050 (MainThread): Flushing usage events
2020-05-25 12:41:14.173929 (MainThread): Running with dbt=0.16.1
2020-05-25 12:41:14.528935 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-05-25 12:41:14.529684 (MainThread): Tracking: tracking
2020-05-25 12:41:14.535829 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a6d5e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a6e4580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a6e4550>]}
2020-05-25 12:41:14.536454 (MainThread): Checking target/*
2020-05-25 12:41:14.538658 (MainThread):  Cleaned target/*
2020-05-25 12:41:14.538810 (MainThread): Checking dbt_modules/*
2020-05-25 12:41:14.539221 (MainThread):  Cleaned dbt_modules/*
2020-05-25 12:41:14.539325 (MainThread): Finished cleaning all paths.
2020-05-25 12:41:14.539519 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a6d5e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a6e4520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a6e44f0>]}
2020-05-25 12:41:14.539708 (MainThread): Flushing usage events
2020-05-25 12:42:34.132422 (MainThread): Running with dbt=0.16.1
2020-05-25 12:42:34.492697 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-25 12:42:34.493710 (MainThread): Tracking: tracking
2020-05-25 12:42:34.499608 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121bb0670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121bc0730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121bc0700>]}
2020-05-25 12:42:34.520578 (MainThread): Partial parsing not enabled
2020-05-25 12:42:34.522264 (MainThread): Parsing macros/core.sql
2020-05-25 12:42:34.526532 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:42:34.534758 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:42:34.536512 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:42:34.552536 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:42:34.585857 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:42:34.605941 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:42:34.607731 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:42:34.613518 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:42:34.625715 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:42:34.632113 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:42:34.638123 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:42:34.642634 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:42:34.643518 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:42:34.645005 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:42:34.646560 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:42:34.648468 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:42:34.656800 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:42:34.658630 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:42:34.659615 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:42:34.699673 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:42:34.700748 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:42:34.701591 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:42:34.702602 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:42:34.704787 (MainThread): Parsing macros/etc.sql
2020-05-25 12:42:34.705402 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:42:34.712812 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:42:34.733220 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:42:34.735050 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:42:34.736396 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:42:34.745593 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:42:34.757588 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:42:34.776308 (MainThread): Partial parsing not enabled
2020-05-25 12:42:34.776667 (MainThread): Parsing macros/project_macros.sql
2020-05-25 12:42:34.807777 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:42:34.807892 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:42:34.822048 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:42:34.822134 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:42:34.828708 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:42:34.828797 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:42:34.837804 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:42:34.837907 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:42:34.844239 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:42:34.844324 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:42:34.849379 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:42:34.849464 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:42:34.920568 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-25 12:42:35.087501 (MainThread): Found 6 models, 0 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:42:35.090634 (MainThread): 
2020-05-25 12:42:35.090764 (MainThread): 22:42:35 | Concurrency: 1 threads (target='dev')
2020-05-25 12:42:35.090893 (MainThread): 22:42:35 | 
2020-05-25 12:42:35.093181 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:42:35.093460 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:42:35.093543 (Thread-1): Opening a new connection, currently in state init
2020-05-25 12:42:35.093620 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:42:35.107086 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:42:35.107589 (Thread-1): finished collecting timing info
2020-05-25 12:42:35.107807 (Thread-1): finished collecting timing info
2020-05-25 12:42:35.108128 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:42:35.108234 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:42:35.108424 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:42:35.108497 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:42:35.108567 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:42:35.114135 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:42:35.114486 (Thread-1): finished collecting timing info
2020-05-25 12:42:35.114751 (Thread-1): finished collecting timing info
2020-05-25 12:42:35.115161 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:42:35.115264 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:42:35.115458 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:42:35.115529 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:42:35.115598 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:42:35.121842 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 12:42:35.122231 (Thread-1): finished collecting timing info
2020-05-25 12:42:35.122461 (Thread-1): finished collecting timing info
2020-05-25 12:42:35.122841 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:42:35.122943 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:42:35.123203 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:42:35.123285 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:42:35.123357 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:42:35.130082 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:42:35.130428 (Thread-1): finished collecting timing info
2020-05-25 12:42:35.130677 (Thread-1): finished collecting timing info
2020-05-25 12:42:35.131122 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:42:35.131230 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:42:35.131432 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:42:35.131505 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:42:35.131578 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:42:35.139183 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:42:35.139522 (Thread-1): finished collecting timing info
2020-05-25 12:42:35.139725 (Thread-1): finished collecting timing info
2020-05-25 12:42:35.140048 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:42:35.140155 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:42:35.140350 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:42:35.140424 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:42:35.140494 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:42:35.147043 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:42:35.147391 (Thread-1): finished collecting timing info
2020-05-25 12:42:35.147606 (Thread-1): finished collecting timing info
2020-05-25 12:42:35.147926 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:42:35.148620 (MainThread): Connection 'model.dbt_servian_demo.Weekly_national_trends' was properly closed.
2020-05-25 12:42:35.148706 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-05-25 12:42:35.160218 (MainThread): 22:42:35 | Done.
2020-05-25 12:42:35.160378 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121e37730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121b982b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d3997c0>]}
2020-05-25 12:42:35.160545 (MainThread): Flushing usage events
2020-05-25 12:42:37.064495 (MainThread): Running with dbt=0.16.1
2020-05-25 12:42:37.424671 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-25 12:42:37.425333 (MainThread): Tracking: tracking
2020-05-25 12:42:37.431902 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a276790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a286730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a286700>]}
2020-05-25 12:42:37.452674 (MainThread): Partial parsing not enabled
2020-05-25 12:42:37.454422 (MainThread): Parsing macros/core.sql
2020-05-25 12:42:37.458772 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:42:37.466361 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:42:37.468077 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:42:37.484061 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:42:37.517330 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:42:37.537327 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:42:37.539079 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:42:37.544740 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:42:37.556683 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:42:37.562935 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:42:37.568850 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:42:37.573381 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:42:37.574263 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:42:37.575243 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:42:37.576744 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:42:37.578793 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:42:37.587244 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:42:37.589116 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:42:37.590197 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:42:37.629998 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:42:37.631088 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:42:37.631936 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:42:37.632950 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:42:37.635103 (MainThread): Parsing macros/etc.sql
2020-05-25 12:42:37.635765 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:42:37.642976 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:42:37.663300 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:42:37.665125 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:42:37.666467 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:42:37.675689 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:42:37.687358 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:42:37.705257 (MainThread): Partial parsing not enabled
2020-05-25 12:42:37.705589 (MainThread): Parsing macros/project_macros.sql
2020-05-25 12:42:37.735966 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:42:37.736094 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:42:37.751749 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:42:37.751870 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:42:37.757729 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:42:37.757815 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:42:37.766394 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:42:37.766494 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:42:37.772717 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:42:37.772808 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:42:37.777788 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:42:37.777872 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:42:37.848563 (MainThread): WARNING: Found documentation for resource "total_reigons" which was not found or is disabled
2020-05-25 12:42:38.014298 (MainThread): Found 6 models, 0 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:42:38.017399 (MainThread): 
2020-05-25 12:42:38.017661 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 12:42:38.017740 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:42:38.027405 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-25 12:42:38.027508 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-25 12:42:38.028333 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:42:39.466524 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:42:40.830030 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 12:42:40.830516 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-25 12:42:40.830756 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:42:41.266793 (MainThread): 22:42:41 | Concurrency: 1 threads (target='dev')
2020-05-25 12:42:41.267013 (MainThread): 22:42:41 | 
2020-05-25 12:42:41.270747 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:42:41.270951 (Thread-1): 22:42:41 | 1 of 6 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-05-25 12:42:41.271255 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:42:41.271358 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 12:42:41.271482 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:42:41.289090 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:42:41.289506 (Thread-1): finished collecting timing info
2020-05-25 12:42:41.328378 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:42:42.010544 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:42:42.011222 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:42:44.790493 (Thread-1): finished collecting timing info
2020-05-25 12:42:44.791429 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c628e489-4917-4174-9c69-05184a21f2b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a544e20>]}
2020-05-25 12:42:44.791812 (Thread-1): 22:42:44 | 1 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 3.52s]
2020-05-25 12:42:44.791992 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:42:44.792174 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:42:44.792355 (Thread-1): 22:42:44 | 2 of 6 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-05-25 12:42:44.792845 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:42:44.793007 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-05-25 12:42:44.793138 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:42:44.801301 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:42:44.801763 (Thread-1): finished collecting timing info
2020-05-25 12:42:44.805778 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:42:45.286604 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:42:45.287259 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:42:48.185384 (Thread-1): finished collecting timing info
2020-05-25 12:42:48.186281 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c628e489-4917-4174-9c69-05184a21f2b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a420580>]}
2020-05-25 12:42:48.186617 (Thread-1): 22:42:48 | 2 of 6 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.39s]
2020-05-25 12:42:48.186795 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:42:48.186979 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:42:48.187158 (Thread-1): 22:42:48 | 3 of 6 START view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [RUN]
2020-05-25 12:42:48.187659 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:42:48.187809 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-05-25 12:42:48.187944 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:42:48.196599 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 12:42:48.197045 (Thread-1): finished collecting timing info
2020-05-25 12:42:48.215321 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 12:42:48.215795 (Thread-1): On model.dbt_servian_demo.Weekly_Total_Confirmed_Cases: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_Total_Confirmed_Cases`
  OPTIONS()
  as (
     

SELECT
  TIMESTAMP_TRUNC(date,WEEK) as date,
  country,
  region_name,
  province_name,
  province_abbreviation,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM 
	`bigquery-public-data`.`covid19_italy`.`data_by_province`

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
      , 
   
     4
      , 
   
     5
     
   

  );

2020-05-25 12:42:49.980363 (Thread-1): finished collecting timing info
2020-05-25 12:42:49.981087 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c628e489-4917-4174-9c69-05184a21f2b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a426d60>]}
2020-05-25 12:42:49.981362 (Thread-1): 22:42:49 | 3 of 6 OK created view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [CREATE VIEW in 1.79s]
2020-05-25 12:42:49.981507 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:42:49.981654 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:42:49.981908 (Thread-1): 22:42:49 | 4 of 6 START view model covid_19_italy_insights.Weekly_national_trend_macro [RUN]
2020-05-25 12:42:49.982208 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:42:49.982313 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_Total_Confirmed_Cases).
2020-05-25 12:42:49.982413 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:42:49.992156 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:42:49.992589 (Thread-1): finished collecting timing info
2020-05-25 12:42:49.997043 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:42:49.997444 (Thread-1): On model.dbt_servian_demo.Weekly_national_trend_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trend_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trend_macro`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,
	
	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	

FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 12:42:51.800443 (Thread-1): finished collecting timing info
2020-05-25 12:42:51.801324 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c628e489-4917-4174-9c69-05184a21f2b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a544e20>]}
2020-05-25 12:42:51.801654 (Thread-1): 22:42:51 | 4 of 6 OK created view model covid_19_italy_insights.Weekly_national_trend_macro [CREATE VIEW in 1.82s]
2020-05-25 12:42:51.801829 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:42:51.802014 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:42:51.802208 (Thread-1): 22:42:51 | 5 of 6 START view model covid_19_italy_insights.Weekly_national_trends [RUN]
2020-05-25 12:42:51.802629 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:42:51.802761 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trend_macro).
2020-05-25 12:42:51.802878 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:42:51.812778 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:42:51.813205 (Thread-1): finished collecting timing info
2020-05-25 12:42:51.817925 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:42:51.818307 (Thread-1): On model.dbt_servian_demo.Weekly_national_trends: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trends"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trends`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,

	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	
FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 12:42:53.531514 (Thread-1): finished collecting timing info
2020-05-25 12:42:53.532384 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c628e489-4917-4174-9c69-05184a21f2b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a4260d0>]}
2020-05-25 12:42:53.532662 (Thread-1): 22:42:53 | 5 of 6 OK created view model covid_19_italy_insights.Weekly_national_trends [CREATE VIEW in 1.73s]
2020-05-25 12:42:53.532809 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:42:53.532959 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:42:53.533106 (Thread-1): 22:42:53 | 6 of 6 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-05-25 12:42:53.533488 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:42:53.533606 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trends).
2020-05-25 12:42:53.533710 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:42:53.542139 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:42:53.542553 (Thread-1): finished collecting timing info
2020-05-25 12:42:53.546226 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:42:53.999035 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:42:53.999695 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-05-25 12:42:56.870116 (Thread-1): finished collecting timing info
2020-05-25 12:42:56.871000 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c628e489-4917-4174-9c69-05184a21f2b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a4cc4c0>]}
2020-05-25 12:42:56.871330 (Thread-1): 22:42:56 | 6 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.34s]
2020-05-25 12:42:56.871506 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:42:56.873024 (MainThread): 22:42:56 | 
2020-05-25 12:42:56.873189 (MainThread): 22:42:56 | Finished running 3 table models, 3 view models in 18.86s.
2020-05-25 12:42:56.873325 (MainThread): Connection 'master' was left open.
2020-05-25 12:42:56.873427 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-05-25 12:42:56.889115 (MainThread): 
2020-05-25 12:42:56.889263 (MainThread): Completed successfully
2020-05-25 12:42:56.889398 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2020-05-25 12:42:56.889607 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a534bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a534880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a5348b0>]}
2020-05-25 12:42:56.889807 (MainThread): Flushing usage events
2020-05-25 12:42:59.257366 (MainThread): Running with dbt=0.16.1
2020-05-25 12:42:59.622805 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-05-25 12:42:59.623518 (MainThread): Tracking: tracking
2020-05-25 12:42:59.629333 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1176cfe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1176e05e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1176e05b0>]}
2020-05-25 12:42:59.629948 (MainThread): Checking target/*
2020-05-25 12:42:59.632201 (MainThread):  Cleaned target/*
2020-05-25 12:42:59.632336 (MainThread): Checking dbt_modules/*
2020-05-25 12:42:59.632748 (MainThread):  Cleaned dbt_modules/*
2020-05-25 12:42:59.632851 (MainThread): Finished cleaning all paths.
2020-05-25 12:42:59.633036 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1176cfe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1176e0580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1176e0550>]}
2020-05-25 12:42:59.633223 (MainThread): Flushing usage events
2020-05-25 12:56:53.763420 (MainThread): Running with dbt=0.16.1
2020-05-25 12:56:54.241510 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-25 12:56:54.242333 (MainThread): Tracking: tracking
2020-05-25 12:56:54.249930 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124817b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124826700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1248266d0>]}
2020-05-25 12:56:54.271107 (MainThread): Partial parsing not enabled
2020-05-25 12:56:54.272835 (MainThread): Parsing macros/core.sql
2020-05-25 12:56:54.277215 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:56:54.284779 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:56:54.286474 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:56:54.302463 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:56:54.335480 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:56:54.355177 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:56:54.356930 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:56:54.362752 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:56:54.374722 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:56:54.381210 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:56:54.387096 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:56:54.392916 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:56:54.393992 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:56:54.395012 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:56:54.396603 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:56:54.398882 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:56:54.407303 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:56:54.409147 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:56:54.410136 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:56:54.450619 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:56:54.451711 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:56:54.452569 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:56:54.453594 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:56:54.455778 (MainThread): Parsing macros/etc.sql
2020-05-25 12:56:54.456398 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:56:54.463635 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:56:54.484505 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:56:54.486417 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:56:54.487813 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:56:54.497196 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:56:54.509118 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:56:54.527282 (MainThread): Partial parsing not enabled
2020-05-25 12:56:54.528654 (MainThread): Parsing macros/project_macros.sql
2020-05-25 12:56:54.560986 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:56:54.561103 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:56:54.576131 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:56:54.576234 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:56:54.582043 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:56:54.582191 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:56:54.590203 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:56:54.590300 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:56:54.596342 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:56:54.596428 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:56:54.601539 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:56:54.601634 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:56:54.629875 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 12:56:54.629990 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:56:54.866325 (MainThread): Found 6 models, 1 test, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:56:54.870320 (MainThread): 
2020-05-25 12:56:54.870475 (MainThread): 22:56:54 | Concurrency: 1 threads (target='dev')
2020-05-25 12:56:54.870581 (MainThread): 22:56:54 | 
2020-05-25 12:56:54.873311 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:56:54.873643 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:56:54.873737 (Thread-1): Opening a new connection, currently in state init
2020-05-25 12:56:54.873825 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:56:54.889519 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:56:54.890046 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.890271 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.890605 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:56:54.890715 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:56:54.891048 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:56:54.891144 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:56:54.891357 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:56:54.897133 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:56:54.897456 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.897658 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.897969 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:56:54.898079 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:56:54.898346 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:56:54.898424 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:56:54.898562 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:56:54.904984 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 12:56:54.905349 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.905564 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.905902 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:56:54.906017 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:56:54.906223 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:56:54.906303 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:56:54.906379 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:56:54.913592 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:56:54.913982 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.914208 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.914561 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:56:54.914683 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:56:54.915015 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:56:54.915115 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:56:54.915202 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:56:54.923615 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:56:54.924011 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.924250 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.924616 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:56:54.924741 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 12:56:54.925033 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 12:56:54.925119 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:56:54.925201 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 12:56:54.938252 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 12:56:54.938838 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.939089 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.939481 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 12:56:54.939614 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:56:54.939852 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:56:54.940087 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:56:54.940230 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:56:54.947459 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:56:54.947811 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.948040 (Thread-1): finished collecting timing info
2020-05-25 12:56:54.948391 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:56:54.949185 (MainThread): Connection 'test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code' was properly closed.
2020-05-25 12:56:54.949285 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-05-25 12:56:54.963206 (MainThread): 22:56:54 | Done.
2020-05-25 12:56:54.963371 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111837550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1198e5d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1249cdb50>]}
2020-05-25 12:56:54.963544 (MainThread): Flushing usage events
2020-05-25 12:56:57.016003 (MainThread): Running with dbt=0.16.1
2020-05-25 12:56:57.496133 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-25 12:56:57.496860 (MainThread): Tracking: tracking
2020-05-25 12:56:57.502630 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1237a3760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1237b3820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1237b37f0>]}
2020-05-25 12:56:57.524103 (MainThread): Partial parsing not enabled
2020-05-25 12:56:57.526873 (MainThread): Parsing macros/core.sql
2020-05-25 12:56:57.532151 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:56:57.540481 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:56:57.542523 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:56:57.559701 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:56:57.593537 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:56:57.613912 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:56:57.615749 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:56:57.621722 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:56:57.634013 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:56:57.640637 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:56:57.646903 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:56:57.652120 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:56:57.653101 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:56:57.654117 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:56:57.655667 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:56:57.657638 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:56:57.666954 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:56:57.668939 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:56:57.669962 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:56:57.711632 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:56:57.712767 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:56:57.713643 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:56:57.714682 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:56:57.716987 (MainThread): Parsing macros/etc.sql
2020-05-25 12:56:57.717630 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:56:57.725156 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:56:57.746702 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:56:57.748778 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:56:57.750186 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:56:57.759602 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:56:57.771626 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:56:57.790443 (MainThread): Partial parsing not enabled
2020-05-25 12:56:57.790809 (MainThread): Parsing macros/project_macros.sql
2020-05-25 12:56:57.824540 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:56:57.824799 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:56:57.843074 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:56:57.843215 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:56:57.850455 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:56:57.850592 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:56:57.860639 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:56:57.860782 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:56:57.869114 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:56:57.869325 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:56:57.875958 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:56:57.876114 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:56:57.911924 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 12:56:57.912066 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:56:58.177895 (MainThread): Found 6 models, 1 test, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:56:58.181505 (MainThread): 
2020-05-25 12:56:58.181795 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 12:56:58.181878 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:56:58.191508 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-25 12:56:58.191624 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-25 12:56:58.192449 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:57:00.851806 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:57:03.103706 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 12:57:03.105089 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-25 12:57:03.105336 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:57:03.620286 (MainThread): 22:57:03 | Concurrency: 1 threads (target='dev')
2020-05-25 12:57:03.620504 (MainThread): 22:57:03 | 
2020-05-25 12:57:03.624187 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:57:03.624401 (Thread-1): 22:57:03 | 1 of 6 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-05-25 12:57:03.624720 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:57:03.624821 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 12:57:03.624938 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:57:03.645364 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:57:03.645873 (Thread-1): finished collecting timing info
2020-05-25 12:57:03.685063 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:57:04.348776 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:57:04.349535 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:57:07.205680 (Thread-1): finished collecting timing info
2020-05-25 12:57:07.206515 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9cf16f2d-7874-42cf-b909-78e7192049f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123972670>]}
2020-05-25 12:57:07.206848 (Thread-1): 22:57:07 | 1 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 3.58s]
2020-05-25 12:57:07.207005 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:57:07.207164 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:57:07.207315 (Thread-1): 22:57:07 | 2 of 6 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-05-25 12:57:07.207762 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:57:07.207881 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-05-25 12:57:07.207988 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:57:07.215827 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:57:07.216278 (Thread-1): finished collecting timing info
2020-05-25 12:57:07.220657 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:57:07.661766 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:57:07.662419 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:57:11.035897 (Thread-1): finished collecting timing info
2020-05-25 12:57:11.036856 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9cf16f2d-7874-42cf-b909-78e7192049f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123a87b80>]}
2020-05-25 12:57:11.037183 (Thread-1): 22:57:11 | 2 of 6 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.83s]
2020-05-25 12:57:11.037360 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:57:11.037542 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:57:11.037730 (Thread-1): 22:57:11 | 3 of 6 START view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [RUN]
2020-05-25 12:57:11.038222 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:57:11.038377 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-05-25 12:57:11.038513 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:57:11.047375 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 12:57:11.047855 (Thread-1): finished collecting timing info
2020-05-25 12:57:11.066345 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 12:57:11.066790 (Thread-1): On model.dbt_servian_demo.Weekly_Total_Confirmed_Cases: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_Total_Confirmed_Cases`
  OPTIONS()
  as (
     

SELECT
  TIMESTAMP_TRUNC(date,WEEK) as date,
  country,
  region_name,
  province_name,
  province_abbreviation,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM 
	`bigquery-public-data`.`covid19_italy`.`data_by_province`

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
      , 
   
     4
      , 
   
     5
     
   

  );

2020-05-25 12:57:12.791588 (Thread-1): finished collecting timing info
2020-05-25 12:57:12.792458 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9cf16f2d-7874-42cf-b909-78e7192049f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1239ce3d0>]}
2020-05-25 12:57:12.792781 (Thread-1): 22:57:12 | 3 of 6 OK created view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [CREATE VIEW in 1.75s]
2020-05-25 12:57:12.792958 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:57:12.793140 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:57:12.793433 (Thread-1): 22:57:12 | 4 of 6 START view model covid_19_italy_insights.Weekly_national_trend_macro [RUN]
2020-05-25 12:57:12.793750 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:57:12.793861 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_Total_Confirmed_Cases).
2020-05-25 12:57:12.793967 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:57:12.803275 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:57:12.803714 (Thread-1): finished collecting timing info
2020-05-25 12:57:12.808510 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:57:12.808961 (Thread-1): On model.dbt_servian_demo.Weekly_national_trend_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trend_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trend_macro`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,
	
	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	

FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 12:57:14.698248 (Thread-1): finished collecting timing info
2020-05-25 12:57:14.699140 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9cf16f2d-7874-42cf-b909-78e7192049f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123a74a00>]}
2020-05-25 12:57:14.699472 (Thread-1): 22:57:14 | 4 of 6 OK created view model covid_19_italy_insights.Weekly_national_trend_macro [CREATE VIEW in 1.91s]
2020-05-25 12:57:14.699658 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:57:14.699832 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:57:14.699985 (Thread-1): 22:57:14 | 5 of 6 START view model covid_19_italy_insights.Weekly_national_trends [RUN]
2020-05-25 12:57:14.700455 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:57:14.700616 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trend_macro).
2020-05-25 12:57:14.700776 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:57:14.710485 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:57:14.710938 (Thread-1): finished collecting timing info
2020-05-25 12:57:14.715708 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:57:14.716107 (Thread-1): On model.dbt_servian_demo.Weekly_national_trends: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trends"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trends`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,

	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	
FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 12:57:16.437429 (Thread-1): finished collecting timing info
2020-05-25 12:57:16.438423 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9cf16f2d-7874-42cf-b909-78e7192049f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123a50400>]}
2020-05-25 12:57:16.438760 (Thread-1): 22:57:16 | 5 of 6 OK created view model covid_19_italy_insights.Weekly_national_trends [CREATE VIEW in 1.74s]
2020-05-25 12:57:16.438937 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:57:16.439130 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:57:16.439370 (Thread-1): 22:57:16 | 6 of 6 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-05-25 12:57:16.439669 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:57:16.439770 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trends).
2020-05-25 12:57:16.439867 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:57:16.448909 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:57:16.449474 (Thread-1): finished collecting timing info
2020-05-25 12:57:16.453391 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:57:16.923937 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:57:16.924607 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-05-25 12:57:19.687855 (Thread-1): finished collecting timing info
2020-05-25 12:57:19.688539 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9cf16f2d-7874-42cf-b909-78e7192049f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123a49820>]}
2020-05-25 12:57:19.688779 (Thread-1): 22:57:19 | 6 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.25s]
2020-05-25 12:57:19.688904 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:57:19.690006 (MainThread): 22:57:19 | 
2020-05-25 12:57:19.690140 (MainThread): 22:57:19 | Finished running 3 table models, 3 view models in 21.51s.
2020-05-25 12:57:19.690245 (MainThread): Connection 'master' was left open.
2020-05-25 12:57:19.690320 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-05-25 12:57:19.704864 (MainThread): 
2020-05-25 12:57:19.705050 (MainThread): Completed successfully
2020-05-25 12:57:19.705241 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2020-05-25 12:57:19.705506 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12393b3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12393bee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12393b4f0>]}
2020-05-25 12:57:19.705715 (MainThread): Flushing usage events
2020-05-25 12:57:22.112865 (MainThread): Running with dbt=0.16.1
2020-05-25 12:57:22.739695 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-05-25 12:57:22.740598 (MainThread): Tracking: tracking
2020-05-25 12:57:22.748020 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11691afd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11692a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11692a6a0>]}
2020-05-25 12:57:22.770550 (MainThread): Partial parsing not enabled
2020-05-25 12:57:22.772786 (MainThread): Parsing macros/core.sql
2020-05-25 12:57:22.778581 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:57:22.787999 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:57:22.790426 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:57:22.808881 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:57:22.844775 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:57:22.865697 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:57:22.868103 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:57:22.874516 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:57:22.887050 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:57:22.893835 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:57:22.900846 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:57:22.905938 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:57:22.907208 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:57:22.908759 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:57:22.911033 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:57:22.913755 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:57:22.923197 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:57:22.925533 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:57:22.927048 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:57:22.968757 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:57:22.970207 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:57:22.971292 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:57:22.972622 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:57:22.975055 (MainThread): Parsing macros/etc.sql
2020-05-25 12:57:22.976254 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:57:22.984565 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:57:23.005949 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:57:23.008091 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:57:23.010089 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:57:23.019909 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:57:23.032254 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:57:23.050692 (MainThread): Partial parsing not enabled
2020-05-25 12:57:23.051998 (MainThread): Parsing macros/project_macros.sql
2020-05-25 12:57:23.086113 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:57:23.086255 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:57:23.103626 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:57:23.103793 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:57:23.111191 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:57:23.111327 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:57:23.122005 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:57:23.122148 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:57:23.130012 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:57:23.130153 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:57:23.136720 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:57:23.136834 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:57:23.168181 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 12:57:23.168304 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:57:23.410613 (MainThread): Found 6 models, 1 test, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:57:23.414104 (MainThread): 
2020-05-25 12:57:23.414395 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 12:57:23.414473 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:57:23.428976 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:57:25.274073 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 12:57:25.274507 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-05-25 12:57:25.275070 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:57:25.767016 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:57:27.425879 (MainThread): 22:57:27 | Concurrency: 1 threads (target='dev')
2020-05-25 12:57:27.426108 (MainThread): 22:57:27 | 
2020-05-25 12:57:27.431060 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 12:57:27.431282 (Thread-1): 22:57:27 | 1 of 1 START test not_null_Confirmed_Case_Per_Reigons_region_code.... [RUN]
2020-05-25 12:57:27.431631 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 12:57:27.431736 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 12:57:27.431858 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 12:57:27.452122 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 12:57:27.452594 (Thread-1): finished collecting timing info
2020-05-25 12:57:27.452888 (Thread-1): On test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
where region_code is null


2020-05-25 12:57:29.601503 (Thread-1): finished collecting timing info
2020-05-25 12:57:29.602386 (Thread-1): 22:57:29 | 1 of 1 PASS not_null_Confirmed_Case_Per_Reigons_region_code.......... [PASS in 2.17s]
2020-05-25 12:57:29.602642 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 12:57:29.604209 (MainThread): 22:57:29 | 
2020-05-25 12:57:29.604401 (MainThread): 22:57:29 | Finished running 1 test in 6.19s.
2020-05-25 12:57:29.604592 (MainThread): Connection 'master' was left open.
2020-05-25 12:57:29.604756 (MainThread): Connection 'test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code' was left open.
2020-05-25 12:57:29.608869 (MainThread): 
2020-05-25 12:57:29.609044 (MainThread): Completed successfully
2020-05-25 12:57:29.609182 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-05-25 12:57:29.609447 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116acec40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116acec70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116ace040>]}
2020-05-25 12:57:29.609716 (MainThread): Flushing usage events
2020-05-25 12:57:31.654629 (MainThread): Running with dbt=0.16.1
2020-05-25 12:57:32.058318 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-05-25 12:57:32.059183 (MainThread): Tracking: tracking
2020-05-25 12:57:32.065422 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124c75ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124c84640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124c84610>]}
2020-05-25 12:57:32.066160 (MainThread): Checking target/*
2020-05-25 12:57:32.069582 (MainThread):  Cleaned target/*
2020-05-25 12:57:32.069760 (MainThread): Checking dbt_modules/*
2020-05-25 12:57:32.070164 (MainThread):  Cleaned dbt_modules/*
2020-05-25 12:57:32.070294 (MainThread): Finished cleaning all paths.
2020-05-25 12:57:32.070524 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124c75ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124c845e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124c845b0>]}
2020-05-25 12:57:32.070725 (MainThread): Flushing usage events
2020-05-25 12:58:48.012574 (MainThread): Running with dbt=0.16.1
2020-05-25 12:58:48.381448 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-25 12:58:48.382869 (MainThread): Tracking: tracking
2020-05-25 12:58:48.388256 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1194adfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1194bd6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1194bd6a0>]}
2020-05-25 12:58:48.409608 (MainThread): Partial parsing not enabled
2020-05-25 12:58:48.411731 (MainThread): Parsing macros/core.sql
2020-05-25 12:58:48.416701 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:58:48.424653 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:58:48.426799 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:58:48.443500 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:58:48.477717 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:58:48.498427 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:58:48.501221 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:58:48.508215 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:58:48.521103 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:58:48.527639 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:58:48.533715 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:58:48.538664 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:58:48.539755 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:58:48.541199 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:58:48.543444 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:58:48.546111 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:58:48.555486 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:58:48.557749 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:58:48.559315 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:58:48.600261 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:58:48.601633 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:58:48.602707 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:58:48.604280 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:58:48.607225 (MainThread): Parsing macros/etc.sql
2020-05-25 12:58:48.608699 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:58:48.616904 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:58:48.644356 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:58:48.647299 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:58:48.649439 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:58:48.659646 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:58:48.672184 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:58:48.690813 (MainThread): Partial parsing not enabled
2020-05-25 12:58:48.691681 (MainThread): Parsing macros/project_macros.sql
2020-05-25 12:58:48.731245 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:58:48.731390 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:58:48.747808 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:58:48.747936 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:58:48.755004 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:58:48.755132 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:58:48.764670 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:58:48.764807 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:58:48.772393 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:58:48.772535 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:58:48.779104 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:58:48.779247 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:58:48.810543 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 12:58:48.810668 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:58:49.044756 (MainThread): Found 6 models, 1 test, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:58:49.048447 (MainThread): 
2020-05-25 12:58:49.048581 (MainThread): 22:58:49 | Concurrency: 1 threads (target='dev')
2020-05-25 12:58:49.048676 (MainThread): 22:58:49 | 
2020-05-25 12:58:49.053206 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:58:49.053569 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:58:49.053663 (Thread-1): Opening a new connection, currently in state init
2020-05-25 12:58:49.053751 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:58:49.069927 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:58:49.070460 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.070684 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.071030 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:58:49.071140 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:58:49.071343 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:58:49.071423 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:58:49.071498 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:58:49.076897 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:58:49.077310 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.077514 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.077813 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:58:49.077918 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:58:49.078113 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:58:49.078188 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:58:49.078262 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:58:49.084632 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 12:58:49.084980 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.085182 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.085493 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:58:49.085600 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:58:49.085795 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:58:49.085870 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:58:49.085945 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:58:49.093565 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:58:49.093905 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.094105 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.094419 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:58:49.094524 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:58:49.094721 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:58:49.094796 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:58:49.094868 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:58:49.102178 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:58:49.102482 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.102674 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.102970 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:58:49.103073 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 12:58:49.103267 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 12:58:49.103341 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:58:49.103412 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 12:58:49.115254 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 12:58:49.115677 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.115876 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.116186 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 12:58:49.116292 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:58:49.116489 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:58:49.116565 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 12:58:49.116668 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:58:49.123186 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:58:49.123545 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.123944 (Thread-1): finished collecting timing info
2020-05-25 12:58:49.124348 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:58:49.125045 (MainThread): Connection 'test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code' was properly closed.
2020-05-25 12:58:49.125131 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-05-25 12:58:49.138249 (MainThread): 22:58:49 | Done.
2020-05-25 12:58:49.138449 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11969b340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119699ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11967aeb0>]}
2020-05-25 12:58:49.138729 (MainThread): Flushing usage events
2020-05-25 12:58:51.203642 (MainThread): Running with dbt=0.16.1
2020-05-25 12:58:51.562500 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-05-25 12:58:51.563346 (MainThread): Tracking: tracking
2020-05-25 12:58:51.568848 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1220eda00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1220fd700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1220fd6d0>]}
2020-05-25 12:58:51.590406 (MainThread): Partial parsing not enabled
2020-05-25 12:58:51.592323 (MainThread): Parsing macros/core.sql
2020-05-25 12:58:51.597007 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:58:51.604474 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:58:51.606153 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:58:51.622014 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:58:51.655790 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:58:51.675869 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:58:51.677692 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:58:51.683711 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:58:51.695930 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:58:51.702371 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:58:51.708297 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:58:51.712956 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:58:51.713860 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:58:51.714866 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:58:51.716408 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:58:51.718355 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:58:51.726951 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:58:51.728835 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:58:51.729854 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:58:51.770444 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:58:51.771562 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:58:51.772448 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:58:51.773463 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:58:51.775860 (MainThread): Parsing macros/etc.sql
2020-05-25 12:58:51.776484 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:58:51.783798 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:58:51.804043 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:58:51.805867 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:58:51.807212 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:58:51.816350 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:58:51.827965 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:58:51.846600 (MainThread): Partial parsing not enabled
2020-05-25 12:58:51.846956 (MainThread): Parsing macros/project_macros.sql
2020-05-25 12:58:51.877703 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:58:51.877821 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:58:51.892727 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:58:51.892827 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:58:51.898661 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:58:51.898746 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:58:51.906670 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:58:51.906756 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:58:51.913050 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:58:51.913140 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:58:51.918044 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:58:51.918126 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:58:51.946418 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 12:58:51.946527 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:58:52.175916 (MainThread): Found 6 models, 1 test, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:58:52.179288 (MainThread): 
2020-05-25 12:58:52.179542 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 12:58:52.179617 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:58:52.192301 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:58:53.541650 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 12:58:53.542137 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-05-25 12:58:53.542797 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:58:54.022809 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:58:54.929574 (MainThread): 22:58:54 | Concurrency: 1 threads (target='dev')
2020-05-25 12:58:54.929803 (MainThread): 22:58:54 | 
2020-05-25 12:58:54.933346 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 12:58:54.933532 (Thread-1): 22:58:54 | 1 of 1 START test not_null_Confirmed_Case_Per_Reigons_region_code.... [RUN]
2020-05-25 12:58:54.933835 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 12:58:54.933938 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 12:58:54.934058 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 12:58:54.953885 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 12:58:54.954331 (Thread-1): finished collecting timing info
2020-05-25 12:58:54.954618 (Thread-1): On test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
where region_code is null


2020-05-25 12:58:57.404242 (Thread-1): finished collecting timing info
2020-05-25 12:58:57.404959 (Thread-1): 22:58:57 | 1 of 1 PASS not_null_Confirmed_Case_Per_Reigons_region_code.......... [PASS in 2.47s]
2020-05-25 12:58:57.405158 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 12:58:57.406638 (MainThread): 22:58:57 | 
2020-05-25 12:58:57.406828 (MainThread): 22:58:57 | Finished running 1 test in 5.23s.
2020-05-25 12:58:57.406979 (MainThread): Connection 'master' was left open.
2020-05-25 12:58:57.407093 (MainThread): Connection 'test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code' was left open.
2020-05-25 12:58:57.410735 (MainThread): 
2020-05-25 12:58:57.410886 (MainThread): Completed successfully
2020-05-25 12:58:57.411016 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-05-25 12:58:57.411251 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1222da250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12226cf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12226cfd0>]}
2020-05-25 12:58:57.411510 (MainThread): Flushing usage events
2020-05-25 12:58:59.412521 (MainThread): Running with dbt=0.16.1
2020-05-25 12:58:59.789428 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-25 12:58:59.790332 (MainThread): Tracking: tracking
2020-05-25 12:58:59.795900 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f2726a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f282760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f282730>]}
2020-05-25 12:58:59.817341 (MainThread): Partial parsing not enabled
2020-05-25 12:58:59.819309 (MainThread): Parsing macros/core.sql
2020-05-25 12:58:59.824322 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 12:58:59.832305 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 12:58:59.834166 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 12:58:59.851053 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 12:58:59.885661 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 12:58:59.906634 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 12:58:59.908527 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 12:58:59.914511 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 12:58:59.927100 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 12:58:59.933725 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 12:58:59.939845 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 12:58:59.944627 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 12:58:59.945564 (MainThread): Parsing macros/etc/query.sql
2020-05-25 12:58:59.946604 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 12:58:59.948188 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 12:58:59.950363 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 12:58:59.959326 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 12:58:59.961302 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 12:58:59.962357 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 12:59:00.004372 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 12:59:00.005567 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 12:59:00.006470 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 12:59:00.007556 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 12:59:00.009896 (MainThread): Parsing macros/etc.sql
2020-05-25 12:59:00.010558 (MainThread): Parsing macros/catalog.sql
2020-05-25 12:59:00.018281 (MainThread): Parsing macros/adapters.sql
2020-05-25 12:59:00.039676 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 12:59:00.041679 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 12:59:00.043136 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 12:59:00.052998 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 12:59:00.065160 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 12:59:00.083513 (MainThread): Partial parsing not enabled
2020-05-25 12:59:00.083865 (MainThread): Parsing macros/project_macros.sql
2020-05-25 12:59:00.114959 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:59:00.115078 (MainThread): Opening a new connection, currently in state init
2020-05-25 12:59:00.130152 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:59:00.130268 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:59:00.136884 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:59:00.136976 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:59:00.145289 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:59:00.145383 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:59:00.151679 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:59:00.151764 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:59:00.156820 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:59:00.156904 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:59:00.186111 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 12:59:00.186237 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:59:00.416084 (MainThread): Found 6 models, 1 test, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 12:59:00.419535 (MainThread): 
2020-05-25 12:59:00.419791 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 12:59:00.419867 (MainThread): Opening a new connection, currently in state closed
2020-05-25 12:59:00.429266 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-25 12:59:00.429363 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-25 12:59:00.430173 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:59:01.768707 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 12:59:03.152510 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 12:59:03.152992 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-25 12:59:03.153295 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:59:03.568103 (MainThread): 22:59:03 | Concurrency: 1 threads (target='dev')
2020-05-25 12:59:03.568340 (MainThread): 22:59:03 | 
2020-05-25 12:59:03.572028 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:59:03.572224 (Thread-1): 22:59:03 | 1 of 6 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-05-25 12:59:03.572530 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 12:59:03.572631 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 12:59:03.572750 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:59:03.593024 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:59:03.593473 (Thread-1): finished collecting timing info
2020-05-25 12:59:03.632700 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:59:04.360624 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 12:59:04.361226 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:59:07.412390 (Thread-1): finished collecting timing info
2020-05-25 12:59:07.413350 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f12cd4b-0456-4488-ba50-bfee3528bca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f4587f0>]}
2020-05-25 12:59:07.413738 (Thread-1): 22:59:07 | 1 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 3.84s]
2020-05-25 12:59:07.413925 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 12:59:07.414109 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:59:07.414294 (Thread-1): 22:59:07 | 2 of 6 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-05-25 12:59:07.414802 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 12:59:07.414935 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-05-25 12:59:07.415068 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:59:07.423198 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:59:07.423646 (Thread-1): finished collecting timing info
2020-05-25 12:59:07.427690 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:59:07.850248 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 12:59:07.850878 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 12:59:10.789862 (Thread-1): finished collecting timing info
2020-05-25 12:59:10.790793 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f12cd4b-0456-4488-ba50-bfee3528bca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f55b160>]}
2020-05-25 12:59:10.791136 (Thread-1): 22:59:10 | 2 of 6 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.38s]
2020-05-25 12:59:10.791317 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 12:59:10.791500 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:59:10.791681 (Thread-1): 22:59:10 | 3 of 6 START view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [RUN]
2020-05-25 12:59:10.792298 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 12:59:10.792447 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-05-25 12:59:10.792587 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:59:10.801374 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 12:59:10.801824 (Thread-1): finished collecting timing info
2020-05-25 12:59:10.820762 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 12:59:10.821227 (Thread-1): On model.dbt_servian_demo.Weekly_Total_Confirmed_Cases: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_Total_Confirmed_Cases`
  OPTIONS()
  as (
     

SELECT
  TIMESTAMP_TRUNC(date,WEEK) as date,
  country,
  region_name,
  province_name,
  province_abbreviation,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM 
	`bigquery-public-data`.`covid19_italy`.`data_by_province`

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
      , 
   
     4
      , 
   
     5
     
   

  );

2020-05-25 12:59:12.507763 (Thread-1): finished collecting timing info
2020-05-25 12:59:12.508655 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f12cd4b-0456-4488-ba50-bfee3528bca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f439fa0>]}
2020-05-25 12:59:12.508989 (Thread-1): 22:59:12 | 3 of 6 OK created view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [CREATE VIEW in 1.72s]
2020-05-25 12:59:12.509169 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 12:59:12.509360 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:59:12.509507 (Thread-1): 22:59:12 | 4 of 6 START view model covid_19_italy_insights.Weekly_national_trend_macro [RUN]
2020-05-25 12:59:12.509837 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 12:59:12.509956 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_Total_Confirmed_Cases).
2020-05-25 12:59:12.510066 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:59:12.519869 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:59:12.520338 (Thread-1): finished collecting timing info
2020-05-25 12:59:12.525009 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 12:59:12.525422 (Thread-1): On model.dbt_servian_demo.Weekly_national_trend_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trend_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trend_macro`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,
	
	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	

FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 12:59:14.300989 (Thread-1): finished collecting timing info
2020-05-25 12:59:14.301869 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f12cd4b-0456-4488-ba50-bfee3528bca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f4c2ee0>]}
2020-05-25 12:59:14.302196 (Thread-1): 22:59:14 | 4 of 6 OK created view model covid_19_italy_insights.Weekly_national_trend_macro [CREATE VIEW in 1.79s]
2020-05-25 12:59:14.302369 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 12:59:14.302552 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:59:14.302843 (Thread-1): 22:59:14 | 5 of 6 START view model covid_19_italy_insights.Weekly_national_trends [RUN]
2020-05-25 12:59:14.303231 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 12:59:14.303349 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trend_macro).
2020-05-25 12:59:14.303463 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:59:14.313671 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:59:14.314105 (Thread-1): finished collecting timing info
2020-05-25 12:59:14.318929 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 12:59:14.319334 (Thread-1): On model.dbt_servian_demo.Weekly_national_trends: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trends"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trends`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,

	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	
FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 12:59:16.377183 (Thread-1): finished collecting timing info
2020-05-25 12:59:16.378051 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f12cd4b-0456-4488-ba50-bfee3528bca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f2fc490>]}
2020-05-25 12:59:16.378372 (Thread-1): 22:59:16 | 5 of 6 OK created view model covid_19_italy_insights.Weekly_national_trends [CREATE VIEW in 2.07s]
2020-05-25 12:59:16.378515 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 12:59:16.378661 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:59:16.378891 (Thread-1): 22:59:16 | 6 of 6 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-05-25 12:59:16.379196 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 12:59:16.379302 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trends).
2020-05-25 12:59:16.379406 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:59:16.388174 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:59:16.388611 (Thread-1): finished collecting timing info
2020-05-25 12:59:16.392519 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 12:59:16.811111 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 12:59:16.811789 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-05-25 12:59:19.836412 (Thread-1): finished collecting timing info
2020-05-25 12:59:19.837294 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f12cd4b-0456-4488-ba50-bfee3528bca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f433100>]}
2020-05-25 12:59:19.837618 (Thread-1): 22:59:19 | 6 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.46s]
2020-05-25 12:59:19.837793 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 12:59:19.839234 (MainThread): 22:59:19 | 
2020-05-25 12:59:19.839395 (MainThread): 22:59:19 | Finished running 3 table models, 3 view models in 19.42s.
2020-05-25 12:59:19.839525 (MainThread): Connection 'master' was left open.
2020-05-25 12:59:19.839624 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-05-25 12:59:19.855371 (MainThread): 
2020-05-25 12:59:19.855528 (MainThread): Completed successfully
2020-05-25 12:59:19.855655 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2020-05-25 12:59:19.855866 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f433ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f433370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f433340>]}
2020-05-25 12:59:19.856069 (MainThread): Flushing usage events
2020-05-25 12:59:22.367904 (MainThread): Running with dbt=0.16.1
2020-05-25 12:59:22.753375 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-05-25 12:59:22.754071 (MainThread): Tracking: tracking
2020-05-25 12:59:22.759787 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11626cdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11627c550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11627c520>]}
2020-05-25 12:59:22.760322 (MainThread): Checking target/*
2020-05-25 12:59:22.762448 (MainThread):  Cleaned target/*
2020-05-25 12:59:22.762598 (MainThread): Checking dbt_modules/*
2020-05-25 12:59:22.762959 (MainThread):  Cleaned dbt_modules/*
2020-05-25 12:59:22.763057 (MainThread): Finished cleaning all paths.
2020-05-25 12:59:22.763237 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11626cdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11627c4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11627c4c0>]}
2020-05-25 12:59:22.763406 (MainThread): Flushing usage events
2020-05-25 13:01:58.106205 (MainThread): Running with dbt=0.16.1
2020-05-25 13:01:58.609804 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-05-25 13:01:58.611083 (MainThread): Tracking: tracking
2020-05-25 13:01:58.618766 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b201670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b211730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b211700>]}
2020-05-25 13:01:58.640063 (MainThread): Partial parsing not enabled
2020-05-25 13:01:58.641838 (MainThread): Parsing macros/core.sql
2020-05-25 13:01:58.646397 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:01:58.654071 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:01:58.655772 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:01:58.671605 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:01:58.705434 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:01:58.726340 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:01:58.728278 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:01:58.734428 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:01:58.746896 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:01:58.753405 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:01:58.759380 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:01:58.764050 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:01:58.764964 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:01:58.765981 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:01:58.767552 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:01:58.769512 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:01:58.778166 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:01:58.780056 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:01:58.781068 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:01:58.822078 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:01:58.823209 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:01:58.824098 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:01:58.825160 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:01:58.827445 (MainThread): Parsing macros/etc.sql
2020-05-25 13:01:58.828092 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:01:58.835518 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:01:58.856458 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:01:58.858383 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:01:58.859857 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:01:58.869299 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:01:58.881136 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:01:58.899067 (MainThread): Partial parsing not enabled
2020-05-25 13:01:58.901310 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:01:58.938104 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:01:58.938215 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:01:58.953560 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:01:58.953675 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:01:58.960214 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:01:58.960311 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:01:58.968803 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:01:58.968894 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:01:58.975140 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:01:58.975228 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:01:58.980200 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:01:58.980287 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:01:59.010438 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:01:59.010562 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:01:59.018715 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name".
2020-05-25 13:01:59.018808 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:01:59.023772 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b2a8fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b3d83d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b3d8d90>]}
2020-05-25 13:01:59.023963 (MainThread): Flushing usage events
2020-05-25 13:02:00.201497 (MainThread): Connection 'test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name' was properly closed.
2020-05-25 13:02:00.201750 (MainThread): Encountered an error:
2020-05-25 13:02:00.201924 (MainThread): Compilation Error
  Invalid test config given in models/covid_19_italy_insights/schema.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', ['Piemonte', 'Lombardia'])] instead (2 keys)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)
2020-05-25 13:02:00.213613 (MainThread): Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/schemas.py", line 265, in parse_test
    self.parse_node(block)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/schemas.py", line 189, in parse_node
    builder = TestBuilder[Target](
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/typing.py", line 726, in __call__
    result = self.__origin__(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/schema_test_builders.py", line 234, in __init__
    test_name, test_args = self.extract_test_args(test, column_name)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/schema_test_builders.py", line 277, in extract_test_args
    raise_compiler_error(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', ['Piemonte', 'Lombardia'])] instead (2 keys)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 336, in load_all
    loader.load(internal_manifest=internal_manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 208, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 182, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 138, in parse_with_cache
    parser.parse_file(block)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/schemas.py", line 303, in parse_file
    self.parse_tests(test_block)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/schemas.py", line 277, in parse_tests
    self.parse_column_tests(block, column)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/schemas.py", line 179, in parse_column_tests
    self.parse_test(block, test, column)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/schemas.py", line 273, in parse_test
    raise CompilationException(msg) from exc
dbt.exceptions.CompilationException: Compilation Error
  Invalid test config given in models/covid_19_italy_insights/schema.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', ['Piemonte', 'Lombardia'])] instead (2 keys)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)

2020-05-25 13:03:30.808484 (MainThread): Running with dbt=0.16.1
2020-05-25 13:03:31.490359 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-05-25 13:03:31.491256 (MainThread): Tracking: tracking
2020-05-25 13:03:31.498429 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116e70820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116e847c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116e84790>]}
2020-05-25 13:03:31.520426 (MainThread): Partial parsing not enabled
2020-05-25 13:03:31.523284 (MainThread): Parsing macros/core.sql
2020-05-25 13:03:31.528832 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:03:31.538398 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:03:31.541708 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:03:31.560883 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:03:31.596972 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:03:31.618420 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:03:31.621053 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:03:31.628866 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:03:31.642812 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:03:31.650042 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:03:31.656395 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:03:31.661511 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:03:31.662652 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:03:31.664220 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:03:31.666562 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:03:31.669240 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:03:31.678816 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:03:31.681148 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:03:31.682722 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:03:31.724330 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:03:31.725717 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:03:31.726809 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:03:31.728395 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:03:31.731018 (MainThread): Parsing macros/etc.sql
2020-05-25 13:03:31.732159 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:03:31.740619 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:03:31.761809 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:03:31.763901 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:03:31.765933 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:03:31.776252 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:03:31.788670 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:03:31.807218 (MainThread): Partial parsing not enabled
2020-05-25 13:03:31.807972 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:03:31.843193 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:03:31.843333 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:03:31.859137 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:03:31.859266 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:03:31.866373 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:03:31.866504 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:03:31.875395 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:03:31.875514 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:03:31.882539 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:03:31.882667 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:03:31.888416 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:03:31.888526 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:03:31.918946 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:03:31.919056 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:03:31.927431 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name".
2020-05-25 13:03:31.927522 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:03:31.934068 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Lombardia".
2020-05-25 13:03:31.934158 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:03:32.183338 (MainThread): Found 6 models, 3 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:03:32.187595 (MainThread): 
2020-05-25 13:03:32.187868 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 13:03:32.187946 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:03:32.205428 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:03:34.202179 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 13:03:34.202627 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-05-25 13:03:34.203161 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:03:34.682116 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:03:36.349072 (MainThread): 23:03:36 | Concurrency: 1 threads (target='dev')
2020-05-25 13:03:36.349293 (MainThread): 23:03:36 | 
2020-05-25 13:03:36.355579 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Lombardia
2020-05-25 13:03:36.355833 (Thread-1): 23:03:36 | 1 of 3 START test accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Lombardia [RUN]
2020-05-25 13:03:36.356179 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Lombardia".
2020-05-25 13:03:36.356282 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 13:03:36.356404 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Lombardia
2020-05-25 13:03:36.377088 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Lombardia"
2020-05-25 13:03:36.377760 (Thread-1): finished collecting timing info
2020-05-25 13:03:36.378057 (Thread-1): On test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Lombardia: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Lombardia"} */





with all_values as (

    select distinct
        region_name as value_field

    from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        'Piemonte','Lombardia'
    )
)

select count(*)
from validation_errors


2020-05-25 13:03:38.795222 (Thread-1): finished collecting timing info
2020-05-25 13:03:38.796191 (Thread-1): 23:03:38 | 1 of 3 FAIL 19 accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Lombardia [FAIL 19 in 2.44s]
2020-05-25 13:03:38.796702 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Lombardia
2020-05-25 13:03:38.796981 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:03:38.797394 (Thread-1): 23:03:38 | 2 of 3 START test not_null_Confirmed_Case_Per_Reigons_region_code.... [RUN]
2020-05-25 13:03:38.797864 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:03:38.797991 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Lombardia).
2020-05-25 13:03:38.798114 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:03:38.808189 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 13:03:38.808623 (Thread-1): finished collecting timing info
2020-05-25 13:03:38.808901 (Thread-1): On test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
where region_code is null


2020-05-25 13:03:42.186951 (Thread-1): finished collecting timing info
2020-05-25 13:03:42.187813 (Thread-1): 23:03:42 | 2 of 3 PASS not_null_Confirmed_Case_Per_Reigons_region_code.......... [PASS in 3.39s]
2020-05-25 13:03:42.188055 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:03:42.188289 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name
2020-05-25 13:03:42.188732 (Thread-1): 23:03:42 | 3 of 3 START test not_null_Confirmed_Case_Per_Reigons_region_name.... [RUN]
2020-05-25 13:03:42.189210 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name".
2020-05-25 13:03:42.189375 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code).
2020-05-25 13:03:42.189532 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name
2020-05-25 13:03:42.200052 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name"
2020-05-25 13:03:42.200473 (Thread-1): finished collecting timing info
2020-05-25 13:03:42.200743 (Thread-1): On test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
where region_name is null


2020-05-25 13:03:45.519785 (Thread-1): finished collecting timing info
2020-05-25 13:03:45.520628 (Thread-1): 23:03:45 | 3 of 3 PASS not_null_Confirmed_Case_Per_Reigons_region_name.......... [PASS in 3.33s]
2020-05-25 13:03:45.520871 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name
2020-05-25 13:03:45.522516 (MainThread): 23:03:45 | 
2020-05-25 13:03:45.522697 (MainThread): 23:03:45 | Finished running 3 tests in 13.33s.
2020-05-25 13:03:45.522846 (MainThread): Connection 'master' was left open.
2020-05-25 13:03:45.522960 (MainThread): Connection 'test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name' was left open.
2020-05-25 13:03:45.532267 (MainThread): 
2020-05-25 13:03:45.532417 (MainThread): Completed with 1 error and 0 warnings:
2020-05-25 13:03:45.532539 (MainThread): 
2020-05-25 13:03:45.532658 (MainThread): Failure in test accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Lombardia (models/covid_19_italy_insights/schema.yml)
2020-05-25 13:03:45.532874 (MainThread):   Got 19 results, expected 0.
2020-05-25 13:03:45.532982 (MainThread): 
2020-05-25 13:03:45.533091 (MainThread):   compiled SQL at target/compiled/dbt_servian_demo/schema_test/accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Lombardia.sql
2020-05-25 13:03:45.533204 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2020-05-25 13:03:45.533431 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117088370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1170490a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117090dc0>]}
2020-05-25 13:03:45.533674 (MainThread): Flushing usage events
2020-05-25 13:06:01.543673 (MainThread): Running with dbt=0.16.1
2020-05-25 13:06:01.910833 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-05-25 13:06:01.911511 (MainThread): Tracking: tracking
2020-05-25 13:06:01.917322 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ce9ff70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cead640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cead610>]}
2020-05-25 13:06:01.937827 (MainThread): Partial parsing not enabled
2020-05-25 13:06:01.939568 (MainThread): Parsing macros/core.sql
2020-05-25 13:06:01.943913 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:06:01.951674 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:06:01.953543 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:06:01.970142 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:06:02.003635 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:06:02.025060 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:06:02.026975 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:06:02.033216 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:06:02.045548 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:06:02.051974 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:06:02.057905 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:06:02.062521 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:06:02.063419 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:06:02.064417 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:06:02.066033 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:06:02.067981 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:06:02.076648 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:06:02.078517 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:06:02.079522 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:06:02.121022 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:06:02.122175 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:06:02.123074 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:06:02.124146 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:06:02.126417 (MainThread): Parsing macros/etc.sql
2020-05-25 13:06:02.127065 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:06:02.134533 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:06:02.155472 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:06:02.157388 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:06:02.158795 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:06:02.168268 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:06:02.180372 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:06:02.198406 (MainThread): Partial parsing not enabled
2020-05-25 13:06:02.198732 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:06:02.229255 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:06:02.229369 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:06:02.244361 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:06:02.244463 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:06:02.250224 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:06:02.250306 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:06:02.258259 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:06:02.258346 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:06:02.264471 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:06:02.264558 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:06:02.269457 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:06:02.269538 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:06:02.299368 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:06:02.299474 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:06:02.307419 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name".
2020-05-25 13:06:02.307510 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:06:02.313951 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria".
2020-05-25 13:06:02.314037 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:06:02.557318 (MainThread): Found 6 models, 3 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:06:02.561590 (MainThread): 
2020-05-25 13:06:02.561973 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 13:06:02.562110 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:06:02.576382 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:06:03.912155 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 13:06:03.912547 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-05-25 13:06:03.913126 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:06:04.394153 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:06:05.274451 (MainThread): 23:06:05 | Concurrency: 1 threads (target='dev')
2020-05-25 13:06:05.274680 (MainThread): 23:06:05 | 
2020-05-25 13:06:05.278369 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria
2020-05-25 13:06:05.278570 (Thread-1): 23:06:05 | 1 of 3 START test accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria [RUN]
2020-05-25 13:06:05.278899 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria".
2020-05-25 13:06:05.279005 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 13:06:05.279129 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria
2020-05-25 13:06:05.300621 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria"
2020-05-25 13:06:05.301134 (Thread-1): finished collecting timing info
2020-05-25 13:06:05.301427 (Thread-1): On test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria"} */





with all_values as (

    select distinct
        region_name as value_field

    from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        'Piemonte','Valle d'Aosta','Lombardia','Veneto','Friuli Venezia Giulia','Liguria','Emilia-Romagna','Toscana','Umbria'
    )
)

select count(*)
from validation_errors


2020-05-25 13:06:06.227532 (Thread-1): finished collecting timing info
2020-05-25 13:06:06.228241 (Thread-1): Database Error in test accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria (models/covid_19_italy_insights/schema.yml)
  Syntax error: Expected ")" or "," but got identifier "Aosta" at [23:29]
  compiled SQL at target/compiled/dbt_servian_demo/schema_test/accepted_values_Confirmed_Case_Per_Reigons_69201058a1c95d2519ef8c811c00bd8d.sql
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Syntax error: Expected ")" or "," but got identifier "Aosta" at [23:29]

(job ID: f5a84fe6-fe85-472c-b661-250f1eacdcde)

                                                                                                                                          -----Query Job SQL Follows-----                                                                                                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria"} */
   2:
   3:
   4:
   5:
   6:
   7:with all_values as (
   8:
   9:    select distinct
  10:        region_name as value_field
  11:
  12:    from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  13:
  14:),
  15:
  16:validation_errors as (
  17:
  18:    select
  19:        value_field
  20:
  21:    from all_values
  22:    where value_field not in (
  23:        'Piemonte','Valle d'Aosta','Lombardia','Veneto','Friuli Venezia Giulia','Liguria','Emilia-Romagna','Toscana','Umbria'
  24:    )
  25:)
  26:
  27:select count(*)
  28:from validation_errors
  29:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 577, in execute
    failed_rows = self.execute_test(test)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 558, in execute_test
    res, table = self.adapter.execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 217, in execute
    return self.connections.execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria (models/covid_19_italy_insights/schema.yml)
  Syntax error: Expected ")" or "," but got identifier "Aosta" at [23:29]
  compiled SQL at target/compiled/dbt_servian_demo/schema_test/accepted_values_Confirmed_Case_Per_Reigons_69201058a1c95d2519ef8c811c00bd8d.sql
2020-05-25 13:06:06.241962 (Thread-1): 23:06:06 | 1 of 3 ERROR accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria [ERROR in 0.96s]
2020-05-25 13:06:06.242196 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria
2020-05-25 13:06:06.242410 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:06:06.242604 (Thread-1): 23:06:06 | 2 of 3 START test not_null_Confirmed_Case_Per_Reigons_region_code.... [RUN]
2020-05-25 13:06:06.243252 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:06:06.243397 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria).
2020-05-25 13:06:06.243529 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:06:06.253248 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 13:06:06.253684 (Thread-1): finished collecting timing info
2020-05-25 13:06:06.253965 (Thread-1): On test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
where region_code is null


2020-05-25 13:06:09.606656 (Thread-1): finished collecting timing info
2020-05-25 13:06:09.607576 (Thread-1): 23:06:09 | 2 of 3 PASS not_null_Confirmed_Case_Per_Reigons_region_code.......... [PASS in 3.36s]
2020-05-25 13:06:09.608308 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:06:09.608641 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name
2020-05-25 13:06:09.608911 (Thread-1): 23:06:09 | 3 of 3 START test not_null_Confirmed_Case_Per_Reigons_region_name.... [RUN]
2020-05-25 13:06:09.609497 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name".
2020-05-25 13:06:09.609641 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code).
2020-05-25 13:06:09.609771 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name
2020-05-25 13:06:09.619778 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name"
2020-05-25 13:06:09.620237 (Thread-1): finished collecting timing info
2020-05-25 13:06:09.620516 (Thread-1): On test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
where region_name is null


2020-05-25 13:06:11.798441 (Thread-1): finished collecting timing info
2020-05-25 13:06:11.799297 (Thread-1): 23:06:11 | 3 of 3 PASS not_null_Confirmed_Case_Per_Reigons_region_name.......... [PASS in 2.19s]
2020-05-25 13:06:11.799542 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name
2020-05-25 13:06:11.801082 (MainThread): 23:06:11 | 
2020-05-25 13:06:11.801269 (MainThread): 23:06:11 | Finished running 3 tests in 9.24s.
2020-05-25 13:06:11.801424 (MainThread): Connection 'master' was left open.
2020-05-25 13:06:11.801538 (MainThread): Connection 'test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_name' was left open.
2020-05-25 13:06:11.811684 (MainThread): 
2020-05-25 13:06:11.811846 (MainThread): Completed with 1 error and 0 warnings:
2020-05-25 13:06:11.811986 (MainThread): 
2020-05-25 13:06:11.812104 (MainThread): Database Error in test accepted_values_Confirmed_Case_Per_Reigons_region_name__Piemonte__Valle_d_Aosta__Lombardia__Veneto__Friuli_Venezia_Giulia__Liguria__Emilia_Romagna__Toscana__Umbria (models/covid_19_italy_insights/schema.yml)
2020-05-25 13:06:11.812213 (MainThread):   Syntax error: Expected ")" or "," but got identifier "Aosta" at [23:29]
2020-05-25 13:06:11.812312 (MainThread):   compiled SQL at target/compiled/dbt_servian_demo/schema_test/accepted_values_Confirmed_Case_Per_Reigons_69201058a1c95d2519ef8c811c00bd8d.sql
2020-05-25 13:06:11.812421 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2020-05-25 13:06:11.812651 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d0d99d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d0d9cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d03a2b0>]}
2020-05-25 13:06:11.812904 (MainThread): Flushing usage events
2020-05-25 13:08:16.662477 (MainThread): Running with dbt=0.16.1
2020-05-25 13:08:17.023486 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-05-25 13:08:17.024258 (MainThread): Tracking: tracking
2020-05-25 13:08:17.030510 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11edcf7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11eddf760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11eddf730>]}
2020-05-25 13:08:17.051238 (MainThread): Partial parsing not enabled
2020-05-25 13:08:17.053014 (MainThread): Parsing macros/core.sql
2020-05-25 13:08:17.057961 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:08:17.066166 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:08:17.067963 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:08:17.084310 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:08:17.118020 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:08:17.138917 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:08:17.140871 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:08:17.147029 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:08:17.159443 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:08:17.165879 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:08:17.171767 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:08:17.176364 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:08:17.177268 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:08:17.178271 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:08:17.179817 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:08:17.181757 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:08:17.190315 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:08:17.192189 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:08:17.193296 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:08:17.234220 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:08:17.235357 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:08:17.236240 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:08:17.237291 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:08:17.239542 (MainThread): Parsing macros/etc.sql
2020-05-25 13:08:17.240184 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:08:17.247644 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:08:17.268516 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:08:17.270446 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:08:17.271842 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:08:17.281268 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:08:17.293366 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:08:17.311669 (MainThread): Partial parsing not enabled
2020-05-25 13:08:17.312000 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:08:17.343856 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:08:17.343977 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:08:17.358176 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:08:17.358280 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:08:17.364597 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:08:17.364683 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:08:17.372920 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:08:17.373015 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:08:17.379105 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:08:17.379195 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:08:17.384089 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:08:17.384175 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:08:17.413461 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:08:17.413580 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:08:17.421802 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5".
2020-05-25 13:08:17.421895 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:08:17.657523 (MainThread): Found 6 models, 2 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:08:17.662260 (MainThread): 
2020-05-25 13:08:17.662605 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 13:08:17.662691 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:08:17.676243 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:08:19.079567 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 13:08:19.079977 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-05-25 13:08:19.080682 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:08:19.598051 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:08:20.493007 (MainThread): 23:08:20 | Concurrency: 1 threads (target='dev')
2020-05-25 13:08:20.493228 (MainThread): 23:08:20 | 
2020-05-25 13:08:20.496965 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5
2020-05-25 13:08:20.497175 (Thread-1): 23:08:20 | 1 of 2 START test accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5 [RUN]
2020-05-25 13:08:20.497499 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5".
2020-05-25 13:08:20.497608 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 13:08:20.497733 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5
2020-05-25 13:08:20.518832 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5"
2020-05-25 13:08:20.519296 (Thread-1): finished collecting timing info
2020-05-25 13:08:20.519601 (Thread-1): On test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5"} */





with all_values as (

    select distinct
        region_code as value_field

    from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        1,2,3,4,5
    )
)

select count(*)
from validation_errors


2020-05-25 13:08:23.386300 (Thread-1): finished collecting timing info
2020-05-25 13:08:23.387034 (Thread-1): 23:08:23 | 1 of 2 FAIL 17 accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5 [FAIL 17 in 2.89s]
2020-05-25 13:08:23.387239 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5
2020-05-25 13:08:23.387421 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:08:23.387596 (Thread-1): 23:08:23 | 2 of 2 START test not_null_Confirmed_Case_Per_Reigons_region_code.... [RUN]
2020-05-25 13:08:23.388095 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:08:23.388238 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5).
2020-05-25 13:08:23.388368 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:08:23.397751 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 13:08:23.398158 (Thread-1): finished collecting timing info
2020-05-25 13:08:23.398424 (Thread-1): On test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
where region_code is null


2020-05-25 13:08:27.277954 (Thread-1): finished collecting timing info
2020-05-25 13:08:27.278812 (Thread-1): 23:08:27 | 2 of 2 PASS not_null_Confirmed_Case_Per_Reigons_region_code.......... [PASS in 3.89s]
2020-05-25 13:08:27.279049 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:08:27.280670 (MainThread): 23:08:27 | 
2020-05-25 13:08:27.280853 (MainThread): 23:08:27 | Finished running 2 tests in 9.62s.
2020-05-25 13:08:27.281005 (MainThread): Connection 'master' was left open.
2020-05-25 13:08:27.281120 (MainThread): Connection 'test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code' was left open.
2020-05-25 13:08:27.287980 (MainThread): 
2020-05-25 13:08:27.288128 (MainThread): Completed with 1 error and 0 warnings:
2020-05-25 13:08:27.288251 (MainThread): 
2020-05-25 13:08:27.288371 (MainThread): Failure in test accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5 (models/covid_19_italy_insights/schema.yml)
2020-05-25 13:08:27.288512 (MainThread):   Got 17 results, expected 0.
2020-05-25 13:08:27.288623 (MainThread): 
2020-05-25 13:08:27.288733 (MainThread):   compiled SQL at target/compiled/dbt_servian_demo/schema_test/accepted_values_Confirmed_Case_Per_Reigons_b72fa6221eab6570c2cc951e1e6e403e.sql
2020-05-25 13:08:27.288847 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
2020-05-25 13:08:27.289081 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ee3c940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11efd3760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11efd3dc0>]}
2020-05-25 13:08:27.289336 (MainThread): Flushing usage events
2020-05-25 13:09:19.487911 (MainThread): Running with dbt=0.16.1
2020-05-25 13:09:19.913969 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-05-25 13:09:19.914729 (MainThread): Tracking: tracking
2020-05-25 13:09:19.921433 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c925fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c934670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c934640>]}
2020-05-25 13:09:19.939978 (MainThread): Partial parsing not enabled
2020-05-25 13:09:19.941683 (MainThread): Parsing macros/core.sql
2020-05-25 13:09:19.945920 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:09:19.953614 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:09:19.955302 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:09:19.971177 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:09:20.004610 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:09:20.024974 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:09:20.026892 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:09:20.032924 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:09:20.045820 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:09:20.052347 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:09:20.058310 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:09:20.062984 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:09:20.063906 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:09:20.064927 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:09:20.066483 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:09:20.068450 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:09:20.077182 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:09:20.079085 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:09:20.080109 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:09:20.121239 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:09:20.122352 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:09:20.123216 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:09:20.124253 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:09:20.126469 (MainThread): Parsing macros/etc.sql
2020-05-25 13:09:20.127100 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:09:20.134488 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:09:20.155261 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:09:20.157144 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:09:20.158546 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:09:20.167896 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:09:20.179809 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:09:20.197757 (MainThread): Partial parsing not enabled
2020-05-25 13:09:20.198076 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:09:20.228566 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:09:20.228673 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:09:20.243553 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:09:20.243714 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:09:20.250178 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:09:20.250265 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:09:20.258183 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:09:20.258265 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:09:20.264258 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:09:20.264340 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:09:20.269191 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:09:20.269269 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:09:20.299491 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:09:20.299612 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:09:20.307789 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:09:20.307875 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:09:20.543228 (MainThread): Found 6 models, 2 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:09:20.547063 (MainThread): 
2020-05-25 13:09:20.547325 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 13:09:20.547398 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:09:20.560219 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:09:21.953777 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 13:09:21.954242 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-05-25 13:09:21.954788 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:09:22.432907 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:09:23.355776 (MainThread): 23:09:23 | Concurrency: 1 threads (target='dev')
2020-05-25 13:09:23.355999 (MainThread): 23:09:23 | 
2020-05-25 13:09:23.359606 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:09:23.359803 (Thread-1): 23:09:23 | 1 of 2 START test accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22 [RUN]
2020-05-25 13:09:23.360119 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:09:23.360221 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 13:09:23.360341 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:09:23.382564 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"
2020-05-25 13:09:23.383020 (Thread-1): finished collecting timing info
2020-05-25 13:09:23.383326 (Thread-1): On test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"} */





with all_values as (

    select distinct
        region_code as value_field

    from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22
    )
)

select count(*)
from validation_errors


2020-05-25 13:09:27.258185 (Thread-1): finished collecting timing info
2020-05-25 13:09:27.259076 (Thread-1): 23:09:27 | 1 of 2 PASS accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22 [PASS in 3.90s]
2020-05-25 13:09:27.259316 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:09:27.259547 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:09:27.259780 (Thread-1): 23:09:27 | 2 of 2 START test not_null_Confirmed_Case_Per_Reigons_region_code.... [RUN]
2020-05-25 13:09:27.260284 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:09:27.260424 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22).
2020-05-25 13:09:27.260555 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:09:27.270562 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 13:09:27.270993 (Thread-1): finished collecting timing info
2020-05-25 13:09:27.271268 (Thread-1): On test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
where region_code is null


2020-05-25 13:09:29.460391 (Thread-1): finished collecting timing info
2020-05-25 13:09:29.461251 (Thread-1): 23:09:29 | 2 of 2 PASS not_null_Confirmed_Case_Per_Reigons_region_code.......... [PASS in 2.20s]
2020-05-25 13:09:29.461494 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:09:29.463039 (MainThread): 23:09:29 | 
2020-05-25 13:09:29.463214 (MainThread): 23:09:29 | Finished running 2 tests in 8.92s.
2020-05-25 13:09:29.463357 (MainThread): Connection 'master' was left open.
2020-05-25 13:09:29.463465 (MainThread): Connection 'test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code' was left open.
2020-05-25 13:09:29.470414 (MainThread): 
2020-05-25 13:09:29.470571 (MainThread): Completed successfully
2020-05-25 13:09:29.470695 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-05-25 13:09:29.470942 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cb1c6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cafceb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cafc460>]}
2020-05-25 13:09:29.471186 (MainThread): Flushing usage events
2020-05-25 13:10:17.669724 (MainThread): Running with dbt=0.16.1
2020-05-25 13:10:18.042711 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-05-25 13:10:18.043585 (MainThread): Tracking: tracking
2020-05-25 13:10:18.049008 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121108f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121117640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121117610>]}
2020-05-25 13:10:18.068904 (MainThread): Partial parsing not enabled
2020-05-25 13:10:18.070568 (MainThread): Parsing macros/core.sql
2020-05-25 13:10:18.074890 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:10:18.082468 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:10:18.084150 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:10:18.100040 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:10:18.132768 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:10:18.153547 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:10:18.155455 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:10:18.161906 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:10:18.174518 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:10:18.182145 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:10:18.188478 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:10:18.193124 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:10:18.194046 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:10:18.195080 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:10:18.196654 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:10:18.198637 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:10:18.207286 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:10:18.209655 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:10:18.210726 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:10:18.251856 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:10:18.253002 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:10:18.253886 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:10:18.254950 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:10:18.257201 (MainThread): Parsing macros/etc.sql
2020-05-25 13:10:18.257854 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:10:18.265315 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:10:18.286365 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:10:18.288276 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:10:18.289666 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:10:18.298970 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:10:18.310648 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:10:18.328742 (MainThread): Partial parsing not enabled
2020-05-25 13:10:18.329072 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:10:18.359694 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:10:18.359813 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:10:18.374478 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:10:18.374574 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:10:18.380579 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:10:18.380669 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:10:18.388655 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:10:18.388742 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:10:18.394692 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:10:18.394775 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:10:18.399619 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:10:18.399702 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:10:18.428536 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:10:18.428649 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:10:18.437227 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10".
2020-05-25 13:10:18.437326 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:10:18.675371 (MainThread): Found 6 models, 2 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:10:18.679260 (MainThread): 
2020-05-25 13:10:18.679530 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 13:10:18.679609 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:10:18.692621 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:10:20.163776 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 13:10:20.164142 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-05-25 13:10:20.164607 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:10:20.651615 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:10:21.505263 (MainThread): 23:10:21 | Concurrency: 1 threads (target='dev')
2020-05-25 13:10:21.505488 (MainThread): 23:10:21 | 
2020-05-25 13:10:21.509187 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10
2020-05-25 13:10:21.509384 (Thread-1): 23:10:21 | 1 of 2 START test accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10 [RUN]
2020-05-25 13:10:21.509693 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10".
2020-05-25 13:10:21.509792 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 13:10:21.509908 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10
2020-05-25 13:10:21.530619 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10"
2020-05-25 13:10:21.531050 (Thread-1): finished collecting timing info
2020-05-25 13:10:21.531331 (Thread-1): On test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10"} */





with all_values as (

    select distinct
        region_code as value_field

    from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        1,2,3,4,5,6,7,8,9,10
    )
)

select count(*)
from validation_errors


2020-05-25 13:10:25.271519 (Thread-1): finished collecting timing info
2020-05-25 13:10:25.272448 (Thread-1): 23:10:25 | 1 of 2 FAIL 12 accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10 [FAIL 12 in 3.76s]
2020-05-25 13:10:25.272695 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10
2020-05-25 13:10:25.272929 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:10:25.273144 (Thread-1): 23:10:25 | 2 of 2 START test not_null_Confirmed_Case_Per_Reigons_region_code.... [RUN]
2020-05-25 13:10:25.273657 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:10:25.273807 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10).
2020-05-25 13:10:25.273939 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:10:25.284094 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 13:10:25.284517 (Thread-1): finished collecting timing info
2020-05-25 13:10:25.284800 (Thread-1): On test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
where region_code is null


2020-05-25 13:10:28.558124 (Thread-1): finished collecting timing info
2020-05-25 13:10:28.558836 (Thread-1): 23:10:28 | 2 of 2 PASS not_null_Confirmed_Case_Per_Reigons_region_code.......... [PASS in 3.29s]
2020-05-25 13:10:28.558993 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:10:28.560246 (MainThread): 23:10:28 | 
2020-05-25 13:10:28.560418 (MainThread): 23:10:28 | Finished running 2 tests in 9.88s.
2020-05-25 13:10:28.560547 (MainThread): Connection 'master' was left open.
2020-05-25 13:10:28.560642 (MainThread): Connection 'test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code' was left open.
2020-05-25 13:10:28.566932 (MainThread): 
2020-05-25 13:10:28.567086 (MainThread): Completed with 1 error and 0 warnings:
2020-05-25 13:10:28.567207 (MainThread): 
2020-05-25 13:10:28.567326 (MainThread): Failure in test accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10 (models/covid_19_italy_insights/schema.yml)
2020-05-25 13:10:28.567465 (MainThread):   Got 12 results, expected 0.
2020-05-25 13:10:28.567571 (MainThread): 
2020-05-25 13:10:28.567677 (MainThread):   compiled SQL at target/compiled/dbt_servian_demo/schema_test/accepted_values_Confirmed_Case_Per_Reigons_0336debe28e002ff0df14fa9d4196f8e.sql
2020-05-25 13:10:28.567787 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
2020-05-25 13:10:28.568014 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121289490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1212d80d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1212d8fa0>]}
2020-05-25 13:10:28.568265 (MainThread): Flushing usage events
2020-05-25 13:11:26.088242 (MainThread): Running with dbt=0.16.1
2020-05-25 13:11:26.456548 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-25 13:11:26.457124 (MainThread): Tracking: tracking
2020-05-25 13:11:26.463046 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116bd2a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116be1700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116be16d0>]}
2020-05-25 13:11:26.483063 (MainThread): Partial parsing not enabled
2020-05-25 13:11:26.484871 (MainThread): Parsing macros/core.sql
2020-05-25 13:11:26.489151 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:11:26.496911 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:11:26.498616 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:11:26.514739 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:11:26.548039 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:11:26.569223 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:11:26.571003 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:11:26.576836 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:11:26.588857 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:11:26.595313 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:11:26.601458 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:11:26.606192 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:11:26.607119 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:11:26.608154 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:11:26.609730 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:11:26.611721 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:11:26.620382 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:11:26.622282 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:11:26.623335 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:11:26.664275 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:11:26.665404 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:11:26.666288 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:11:26.667339 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:11:26.669572 (MainThread): Parsing macros/etc.sql
2020-05-25 13:11:26.670215 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:11:26.677657 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:11:26.698602 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:11:26.700460 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:11:26.701822 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:11:26.711062 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:11:26.722633 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:11:26.741223 (MainThread): Partial parsing not enabled
2020-05-25 13:11:26.741565 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:11:26.772171 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:11:26.772289 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:11:26.787945 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:11:26.788061 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:26.794040 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:11:26.794139 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:26.802304 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:11:26.802396 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:26.808542 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:11:26.808625 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:26.813617 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:11:26.813701 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:26.843411 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:11:26.843518 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:26.851680 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:11:26.851779 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:27.086154 (MainThread): Found 6 models, 2 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:11:27.089954 (MainThread): 
2020-05-25 13:11:27.090084 (MainThread): 23:11:27 | Concurrency: 1 threads (target='dev')
2020-05-25 13:11:27.090173 (MainThread): 23:11:27 | 
2020-05-25 13:11:27.092850 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:11:27.093147 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:11:27.093232 (Thread-1): Opening a new connection, currently in state init
2020-05-25 13:11:27.093312 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:11:27.108296 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 13:11:27.108705 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.108921 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.109241 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:11:27.109351 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:11:27.109552 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:11:27.109630 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:11:27.109704 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:11:27.115136 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 13:11:27.115550 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.115758 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.116061 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:11:27.116174 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:11:27.116376 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:11:27.116454 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:11:27.116529 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:11:27.123047 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 13:11:27.123453 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.123667 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.123990 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:11:27.124110 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:11:27.124315 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:11:27.124394 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:11:27.124478 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:11:27.131741 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 13:11:27.132069 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.132268 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.132574 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:11:27.132683 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:11:27.132882 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:11:27.132962 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:11:27.133038 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:11:27.139859 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 13:11:27.140138 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.140340 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.140639 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:11:27.140753 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:11:27.140954 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:11:27.141033 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:11:27.141113 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:11:27.153926 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"
2020-05-25 13:11:27.154254 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.154457 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.154765 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:11:27.154876 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:11:27.155074 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:11:27.155151 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:11:27.155226 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:11:27.161800 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 13:11:27.162076 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.162273 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.162572 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:11:27.162680 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:11:27.162877 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:11:27.162953 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:11:27.163026 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:11:27.169222 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 13:11:27.169574 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.169784 (Thread-1): finished collecting timing info
2020-05-25 13:11:27.170092 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:11:27.170752 (MainThread): Connection 'test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22' was properly closed.
2020-05-25 13:11:27.170842 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-05-25 13:11:27.186304 (MainThread): 23:11:27 | Done.
2020-05-25 13:11:27.186470 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116c9f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116ca6040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116ca65e0>]}
2020-05-25 13:11:27.186645 (MainThread): Flushing usage events
2020-05-25 13:11:29.298158 (MainThread): Running with dbt=0.16.1
2020-05-25 13:11:29.670902 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-05-25 13:11:29.671608 (MainThread): Tracking: tracking
2020-05-25 13:11:29.677159 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fc2f670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fc3e730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fc3e700>]}
2020-05-25 13:11:29.696631 (MainThread): Partial parsing not enabled
2020-05-25 13:11:29.698409 (MainThread): Parsing macros/core.sql
2020-05-25 13:11:29.702760 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:11:29.710401 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:11:29.712226 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:11:29.728607 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:11:29.762227 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:11:29.782227 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:11:29.784149 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:11:29.789976 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:11:29.802314 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:11:29.808741 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:11:29.814671 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:11:29.819320 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:11:29.820244 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:11:29.821258 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:11:29.822796 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:11:29.824751 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:11:29.833279 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:11:29.835266 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:11:29.836287 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:11:29.876802 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:11:29.877942 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:11:29.878810 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:11:29.879850 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:11:29.882052 (MainThread): Parsing macros/etc.sql
2020-05-25 13:11:29.882687 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:11:29.890119 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:11:29.910789 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:11:29.912619 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:11:29.913957 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:11:29.922953 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:11:29.935002 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:11:29.953222 (MainThread): Partial parsing not enabled
2020-05-25 13:11:29.953566 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:11:29.984134 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:11:29.984253 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:11:29.999278 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:11:29.999387 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:30.005318 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:11:30.005409 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:30.013424 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:11:30.013513 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:30.019536 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:11:30.019623 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:30.024587 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:11:30.024673 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:30.054678 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:11:30.054790 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:30.062928 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:11:30.063031 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:30.299572 (MainThread): Found 6 models, 2 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:11:30.303492 (MainThread): 
2020-05-25 13:11:30.303810 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 13:11:30.303894 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:30.317114 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:11:31.648690 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 13:11:31.649074 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-05-25 13:11:31.649615 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:11:32.122102 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:11:33.020042 (MainThread): 23:11:33 | Concurrency: 1 threads (target='dev')
2020-05-25 13:11:33.020269 (MainThread): 23:11:33 | 
2020-05-25 13:11:33.023902 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:11:33.024118 (Thread-1): 23:11:33 | 1 of 2 START test accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22 [RUN]
2020-05-25 13:11:33.024436 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:11:33.024549 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 13:11:33.024677 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:11:33.046846 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"
2020-05-25 13:11:33.047294 (Thread-1): finished collecting timing info
2020-05-25 13:11:33.047590 (Thread-1): On test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"} */





with all_values as (

    select distinct
        region_code as value_field

    from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22
    )
)

select count(*)
from validation_errors


2020-05-25 13:11:35.495798 (Thread-1): finished collecting timing info
2020-05-25 13:11:35.496696 (Thread-1): 23:11:35 | 1 of 2 PASS accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22 [PASS in 2.47s]
2020-05-25 13:11:35.496949 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:11:35.497186 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:11:35.497414 (Thread-1): 23:11:35 | 2 of 2 START test not_null_Confirmed_Case_Per_Reigons_region_code.... [RUN]
2020-05-25 13:11:35.497936 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:11:35.498083 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22).
2020-05-25 13:11:35.498217 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:11:35.508152 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 13:11:35.508571 (Thread-1): finished collecting timing info
2020-05-25 13:11:35.508854 (Thread-1): On test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
where region_code is null


2020-05-25 13:11:38.874557 (Thread-1): finished collecting timing info
2020-05-25 13:11:38.875432 (Thread-1): 23:11:38 | 2 of 2 PASS not_null_Confirmed_Case_Per_Reigons_region_code.......... [PASS in 3.38s]
2020-05-25 13:11:38.876434 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:11:38.878294 (MainThread): 23:11:38 | 
2020-05-25 13:11:38.878501 (MainThread): 23:11:38 | Finished running 2 tests in 8.57s.
2020-05-25 13:11:38.878653 (MainThread): Connection 'master' was left open.
2020-05-25 13:11:38.878767 (MainThread): Connection 'test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code' was left open.
2020-05-25 13:11:38.885670 (MainThread): 
2020-05-25 13:11:38.885824 (MainThread): Completed successfully
2020-05-25 13:11:38.885953 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-05-25 13:11:38.886192 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fdac7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fdd9f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fdd94c0>]}
2020-05-25 13:11:38.886441 (MainThread): Flushing usage events
2020-05-25 13:11:40.788436 (MainThread): Running with dbt=0.16.1
2020-05-25 13:11:41.160214 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-25 13:11:41.160949 (MainThread): Tracking: tracking
2020-05-25 13:11:41.167082 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f4cc790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f4dc730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f4dc700>]}
2020-05-25 13:11:41.189514 (MainThread): Partial parsing not enabled
2020-05-25 13:11:41.191464 (MainThread): Parsing macros/core.sql
2020-05-25 13:11:41.196320 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:11:41.204325 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:11:41.206061 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:11:41.222402 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:11:41.256141 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:11:41.276443 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:11:41.278287 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:11:41.284260 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:11:41.296521 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:11:41.303129 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:11:41.309072 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:11:41.313879 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:11:41.314808 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:11:41.315804 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:11:41.317411 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:11:41.319356 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:11:41.327886 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:11:41.329767 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:11:41.330778 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:11:41.371714 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:11:41.372841 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:11:41.373713 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:11:41.374747 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:11:41.376968 (MainThread): Parsing macros/etc.sql
2020-05-25 13:11:41.377608 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:11:41.385028 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:11:41.405850 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:11:41.407748 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:11:41.409128 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:11:41.418448 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:11:41.430725 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:11:41.449338 (MainThread): Partial parsing not enabled
2020-05-25 13:11:41.449698 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:11:41.480830 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:11:41.480954 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:11:41.496404 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:11:41.496527 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:41.502586 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:11:41.502674 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:41.511367 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:11:41.511491 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:41.517868 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:11:41.517959 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:41.523298 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:11:41.523398 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:41.553898 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:11:41.554017 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:41.562509 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:11:41.562626 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:41.798876 (MainThread): Found 6 models, 2 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:11:41.802708 (MainThread): 
2020-05-25 13:11:41.802962 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 13:11:41.803039 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:11:41.812683 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-25 13:11:41.812793 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-25 13:11:41.813605 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:11:43.182779 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:11:45.222156 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 13:11:45.222467 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-25 13:11:45.222638 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:11:45.888873 (MainThread): 23:11:45 | Concurrency: 1 threads (target='dev')
2020-05-25 13:11:45.889091 (MainThread): 23:11:45 | 
2020-05-25 13:11:45.892839 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:11:45.893047 (Thread-1): 23:11:45 | 1 of 6 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-05-25 13:11:45.893367 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:11:45.893471 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 13:11:45.893598 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:11:45.914342 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 13:11:45.914825 (Thread-1): finished collecting timing info
2020-05-25 13:11:45.952728 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:11:46.551860 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 13:11:46.552493 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 13:11:49.305526 (Thread-1): finished collecting timing info
2020-05-25 13:11:49.306469 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b13b535-d901-40d1-9303-58c64ee25e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f626730>]}
2020-05-25 13:11:49.306860 (Thread-1): 23:11:49 | 1 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 3.41s]
2020-05-25 13:11:49.307045 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:11:49.307230 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:11:49.307414 (Thread-1): 23:11:49 | 2 of 6 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-05-25 13:11:49.307915 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:11:49.308058 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-05-25 13:11:49.308204 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:11:49.315954 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 13:11:49.316374 (Thread-1): finished collecting timing info
2020-05-25 13:11:49.320330 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:11:49.752310 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 13:11:49.752981 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 13:11:52.902744 (Thread-1): finished collecting timing info
2020-05-25 13:11:52.903639 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b13b535-d901-40d1-9303-58c64ee25e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f601b80>]}
2020-05-25 13:11:52.903978 (Thread-1): 23:11:52 | 2 of 6 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.60s]
2020-05-25 13:11:52.904156 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:11:52.904346 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:11:52.904529 (Thread-1): 23:11:52 | 3 of 6 START view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [RUN]
2020-05-25 13:11:52.904913 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:11:52.905061 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-05-25 13:11:52.905195 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:11:52.914459 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 13:11:52.915001 (Thread-1): finished collecting timing info
2020-05-25 13:11:52.933059 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 13:11:52.933531 (Thread-1): On model.dbt_servian_demo.Weekly_Total_Confirmed_Cases: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_Total_Confirmed_Cases`
  OPTIONS()
  as (
     

SELECT
  TIMESTAMP_TRUNC(date,WEEK) as date,
  country,
  region_name,
  province_name,
  province_abbreviation,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM 
	`bigquery-public-data`.`covid19_italy`.`data_by_province`

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
      , 
   
     4
      , 
   
     5
     
   

  );

2020-05-25 13:11:54.627014 (Thread-1): finished collecting timing info
2020-05-25 13:11:54.627900 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b13b535-d901-40d1-9303-58c64ee25e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f624a00>]}
2020-05-25 13:11:54.628235 (Thread-1): 23:11:54 | 3 of 6 OK created view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [CREATE VIEW in 1.72s]
2020-05-25 13:11:54.628414 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:11:54.628598 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:11:54.628886 (Thread-1): 23:11:54 | 4 of 6 START view model covid_19_italy_insights.Weekly_national_trend_macro [RUN]
2020-05-25 13:11:54.629198 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:11:54.629298 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_Total_Confirmed_Cases).
2020-05-25 13:11:54.629395 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:11:54.638634 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 13:11:54.639064 (Thread-1): finished collecting timing info
2020-05-25 13:11:54.643701 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 13:11:54.644099 (Thread-1): On model.dbt_servian_demo.Weekly_national_trend_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trend_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trend_macro`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,
	
	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	

FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 13:11:56.595291 (Thread-1): finished collecting timing info
2020-05-25 13:11:56.596174 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b13b535-d901-40d1-9303-58c64ee25e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f5fe4c0>]}
2020-05-25 13:11:56.596502 (Thread-1): 23:11:56 | 4 of 6 OK created view model covid_19_italy_insights.Weekly_national_trend_macro [CREATE VIEW in 1.97s]
2020-05-25 13:11:56.596675 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:11:56.596852 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:11:56.597036 (Thread-1): 23:11:56 | 5 of 6 START view model covid_19_italy_insights.Weekly_national_trends [RUN]
2020-05-25 13:11:56.597459 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:11:56.597593 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trend_macro).
2020-05-25 13:11:56.597706 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:11:56.607724 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 13:11:56.608158 (Thread-1): finished collecting timing info
2020-05-25 13:11:56.612878 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 13:11:56.613287 (Thread-1): On model.dbt_servian_demo.Weekly_national_trends: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trends"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trends`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,

	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	
FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 13:11:58.445201 (Thread-1): finished collecting timing info
2020-05-25 13:11:58.446086 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b13b535-d901-40d1-9303-58c64ee25e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f624a00>]}
2020-05-25 13:11:58.446414 (Thread-1): 23:11:58 | 5 of 6 OK created view model covid_19_italy_insights.Weekly_national_trends [CREATE VIEW in 1.85s]
2020-05-25 13:11:58.446588 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:11:58.446782 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:11:58.446935 (Thread-1): 23:11:58 | 6 of 6 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-05-25 13:11:58.447222 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:11:58.447327 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trends).
2020-05-25 13:11:58.447434 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:11:58.457142 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 13:11:58.457620 (Thread-1): finished collecting timing info
2020-05-25 13:11:58.461533 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:11:58.914148 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 13:11:58.914807 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-05-25 13:12:01.816395 (Thread-1): finished collecting timing info
2020-05-25 13:12:01.817293 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b13b535-d901-40d1-9303-58c64ee25e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f601b80>]}
2020-05-25 13:12:01.817613 (Thread-1): 23:12:01 | 6 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.37s]
2020-05-25 13:12:01.817785 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:12:01.819291 (MainThread): 23:12:01 | 
2020-05-25 13:12:01.819464 (MainThread): 23:12:01 | Finished running 3 table models, 3 view models in 20.02s.
2020-05-25 13:12:01.819580 (MainThread): Connection 'master' was left open.
2020-05-25 13:12:01.819667 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-05-25 13:12:01.835276 (MainThread): 
2020-05-25 13:12:01.835416 (MainThread): Completed successfully
2020-05-25 13:12:01.835536 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2020-05-25 13:12:01.835743 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f69e250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f6c4430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f6c4340>]}
2020-05-25 13:12:01.835936 (MainThread): Flushing usage events
2020-05-25 13:12:04.159078 (MainThread): Running with dbt=0.16.1
2020-05-25 13:12:04.524629 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-05-25 13:12:04.525658 (MainThread): Tracking: tracking
2020-05-25 13:12:04.531550 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121a69eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121a79610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121a795e0>]}
2020-05-25 13:12:04.532198 (MainThread): Checking target/*
2020-05-25 13:12:04.535305 (MainThread):  Cleaned target/*
2020-05-25 13:12:04.535452 (MainThread): Checking dbt_modules/*
2020-05-25 13:12:04.535810 (MainThread):  Cleaned dbt_modules/*
2020-05-25 13:12:04.535908 (MainThread): Finished cleaning all paths.
2020-05-25 13:12:04.536113 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121a69eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121a795b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121a79580>]}
2020-05-25 13:12:04.536300 (MainThread): Flushing usage events
2020-05-25 13:13:34.230715 (MainThread): Running with dbt=0.16.1
2020-05-25 13:13:34.588230 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-25 13:13:34.589592 (MainThread): Tracking: tracking
2020-05-25 13:13:34.595171 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ccd8820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ccfe7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ccfe790>]}
2020-05-25 13:13:34.617145 (MainThread): Partial parsing not enabled
2020-05-25 13:13:34.619919 (MainThread): Parsing macros/core.sql
2020-05-25 13:13:34.625601 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:13:34.634895 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:13:34.636921 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:13:34.653600 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:13:34.686962 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:13:34.707312 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:13:34.709806 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:13:34.716112 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:13:34.728553 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:13:34.735251 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:13:34.741419 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:13:34.746295 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:13:34.747443 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:13:34.748971 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:13:34.751267 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:13:34.753929 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:13:34.763290 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:13:34.765590 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:13:34.767181 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:13:34.808245 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:13:34.810025 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:13:34.811532 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:13:34.813531 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:13:34.816966 (MainThread): Parsing macros/etc.sql
2020-05-25 13:13:34.818429 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:13:34.827607 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:13:34.849151 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:13:34.851772 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:13:34.853831 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:13:34.863564 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:13:34.875659 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:13:34.893739 (MainThread): Partial parsing not enabled
2020-05-25 13:13:34.895238 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:13:34.930002 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:13:34.930146 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:13:34.947298 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:13:34.947426 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:34.954383 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:13:34.954509 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:34.964072 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:13:34.964205 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:34.971773 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:13:34.971910 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:34.978745 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:13:34.978883 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:35.012010 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:13:35.012133 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:35.020253 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:13:35.020348 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:35.256023 (MainThread): Found 6 models, 2 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:13:35.260299 (MainThread): 
2020-05-25 13:13:35.260437 (MainThread): 23:13:35 | Concurrency: 1 threads (target='dev')
2020-05-25 13:13:35.260529 (MainThread): 23:13:35 | 
2020-05-25 13:13:35.265075 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:13:35.265405 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:13:35.265492 (Thread-1): Opening a new connection, currently in state init
2020-05-25 13:13:35.265574 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:13:35.281577 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 13:13:35.282105 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.282325 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.282646 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:13:35.282754 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:13:35.282950 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:13:35.283027 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:13:35.283170 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:13:35.289393 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 13:13:35.289788 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.290038 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.290488 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:13:35.290672 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:13:35.291105 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:13:35.291349 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:13:35.291581 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:13:35.298495 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 13:13:35.298911 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.299177 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.299540 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:13:35.299726 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:13:35.300034 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:13:35.300196 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:13:35.300301 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:13:35.308260 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 13:13:35.308616 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.308838 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.309183 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:13:35.309305 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:13:35.309523 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:13:35.309609 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:13:35.309691 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:13:35.317787 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 13:13:35.318178 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.318413 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.318769 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:13:35.318895 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:13:35.319136 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:13:35.319232 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:13:35.319319 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:13:35.333527 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"
2020-05-25 13:13:35.334031 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.334254 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.334581 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:13:35.334713 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:13:35.334918 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:13:35.334997 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:13:35.335073 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:13:35.342060 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 13:13:35.342356 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.342553 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.342858 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:13:35.342967 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:13:35.343169 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:13:35.343247 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:13:35.343321 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:13:35.349761 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 13:13:35.350118 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.350331 (Thread-1): finished collecting timing info
2020-05-25 13:13:35.350702 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:13:35.351389 (MainThread): Connection 'test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22' was properly closed.
2020-05-25 13:13:35.351478 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-05-25 13:13:35.366760 (MainThread): 23:13:35 | Done.
2020-05-25 13:13:35.366959 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cf126d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ceaa160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ceaa520>]}
2020-05-25 13:13:35.367142 (MainThread): Flushing usage events
2020-05-25 13:13:37.384831 (MainThread): Running with dbt=0.16.1
2020-05-25 13:13:37.744271 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-05-25 13:13:37.745028 (MainThread): Tracking: tracking
2020-05-25 13:13:37.750360 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1221a6af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1221ce700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1221ce6d0>]}
2020-05-25 13:13:37.770891 (MainThread): Partial parsing not enabled
2020-05-25 13:13:37.772617 (MainThread): Parsing macros/core.sql
2020-05-25 13:13:37.776945 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:13:37.784603 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:13:37.786343 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:13:37.802590 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:13:37.836140 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:13:37.856468 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:13:37.858298 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:13:37.864172 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:13:37.876495 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:13:37.883049 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:13:37.889263 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:13:37.893982 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:13:37.894897 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:13:37.895908 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:13:37.897454 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:13:37.899405 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:13:37.907822 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:13:37.909668 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:13:37.910658 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:13:37.950828 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:13:37.951923 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:13:37.952778 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:13:37.953834 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:13:37.955993 (MainThread): Parsing macros/etc.sql
2020-05-25 13:13:37.956613 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:13:37.963881 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:13:37.984323 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:13:37.986159 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:13:37.987585 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:13:37.996701 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:13:38.008308 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:13:38.026170 (MainThread): Partial parsing not enabled
2020-05-25 13:13:38.026492 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:13:38.056597 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:13:38.056710 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:13:38.071449 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:13:38.071546 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:38.077350 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:13:38.077438 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:38.085565 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:13:38.085659 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:38.091653 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:13:38.091735 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:38.096595 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:13:38.096676 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:38.126271 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:13:38.126376 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:38.134355 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:13:38.134442 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:38.369645 (MainThread): Found 6 models, 2 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:13:38.373514 (MainThread): 
2020-05-25 13:13:38.373782 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 13:13:38.373860 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:38.387925 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:13:39.750573 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 13:13:39.750981 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-05-25 13:13:39.751545 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:13:40.229495 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:13:41.093476 (MainThread): 23:13:41 | Concurrency: 1 threads (target='dev')
2020-05-25 13:13:41.093698 (MainThread): 23:13:41 | 
2020-05-25 13:13:41.097382 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:13:41.097576 (Thread-1): 23:13:41 | 1 of 2 START test accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22 [RUN]
2020-05-25 13:13:41.097888 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:13:41.097992 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 13:13:41.098113 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:13:41.120306 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"
2020-05-25 13:13:41.120766 (Thread-1): finished collecting timing info
2020-05-25 13:13:41.121059 (Thread-1): On test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"} */





with all_values as (

    select distinct
        region_code as value_field

    from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22
    )
)

select count(*)
from validation_errors


2020-05-25 13:13:43.431436 (Thread-1): finished collecting timing info
2020-05-25 13:13:43.432315 (Thread-1): 23:13:43 | 1 of 2 PASS accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22 [PASS in 2.33s]
2020-05-25 13:13:43.432564 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:13:43.432800 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:13:43.433235 (Thread-1): 23:13:43 | 2 of 2 START test not_null_Confirmed_Case_Per_Reigons_region_code.... [RUN]
2020-05-25 13:13:43.433627 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:13:43.433760 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22).
2020-05-25 13:13:43.433888 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:13:43.444052 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 13:13:43.444525 (Thread-1): finished collecting timing info
2020-05-25 13:13:43.444809 (Thread-1): On test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
where region_code is null


2020-05-25 13:13:47.168414 (Thread-1): finished collecting timing info
2020-05-25 13:13:47.169245 (Thread-1): 23:13:47 | 2 of 2 PASS not_null_Confirmed_Case_Per_Reigons_region_code.......... [PASS in 3.74s]
2020-05-25 13:13:47.169487 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:13:47.171069 (MainThread): 23:13:47 | 
2020-05-25 13:13:47.171250 (MainThread): 23:13:47 | Finished running 2 tests in 8.80s.
2020-05-25 13:13:47.171399 (MainThread): Connection 'master' was left open.
2020-05-25 13:13:47.171514 (MainThread): Connection 'test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code' was left open.
2020-05-25 13:13:47.178273 (MainThread): 
2020-05-25 13:13:47.178419 (MainThread): Completed successfully
2020-05-25 13:13:47.178545 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-05-25 13:13:47.178773 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122368130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1223680a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122368850>]}
2020-05-25 13:13:47.179028 (MainThread): Flushing usage events
2020-05-25 13:13:49.232017 (MainThread): Running with dbt=0.16.1
2020-05-25 13:13:49.594144 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-25 13:13:49.594983 (MainThread): Tracking: tracking
2020-05-25 13:13:49.600634 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1165eb670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1165fb730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1165fb700>]}
2020-05-25 13:13:49.619904 (MainThread): Partial parsing not enabled
2020-05-25 13:13:49.621659 (MainThread): Parsing macros/core.sql
2020-05-25 13:13:49.625965 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:13:49.633507 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:13:49.635185 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:13:49.650882 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:13:49.684331 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:13:49.704272 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:13:49.706046 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:13:49.711686 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:13:49.723733 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:13:49.729969 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:13:49.735720 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:13:49.740225 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:13:49.741111 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:13:49.742095 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:13:49.743604 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:13:49.745498 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:13:49.753929 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:13:49.756050 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:13:49.757034 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:13:49.797483 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:13:49.798570 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:13:49.799420 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:13:49.800501 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:13:49.802658 (MainThread): Parsing macros/etc.sql
2020-05-25 13:13:49.803269 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:13:49.810654 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:13:49.830921 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:13:49.832763 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:13:49.834125 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:13:49.843484 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:13:49.855684 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:13:49.874194 (MainThread): Partial parsing not enabled
2020-05-25 13:13:49.874534 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:13:49.904817 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:13:49.904937 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:13:49.920035 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:13:49.920140 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:49.926016 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:13:49.926103 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:49.934164 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:13:49.934250 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:49.940357 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:13:49.940444 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:49.945445 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:13:49.945531 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:49.975403 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:13:49.975514 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:49.983661 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:13:49.983757 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:50.218465 (MainThread): Found 6 models, 2 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:13:50.222244 (MainThread): 
2020-05-25 13:13:50.222497 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 13:13:50.222573 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:13:50.231926 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-25 13:13:50.232025 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-25 13:13:50.232847 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:13:51.554824 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:13:52.888189 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 13:13:52.888607 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-25 13:13:52.888859 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:13:53.319459 (MainThread): 23:13:53 | Concurrency: 1 threads (target='dev')
2020-05-25 13:13:53.319679 (MainThread): 23:13:53 | 
2020-05-25 13:13:53.323332 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:13:53.323527 (Thread-1): 23:13:53 | 1 of 6 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-05-25 13:13:53.323831 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:13:53.323933 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 13:13:53.324058 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:13:53.344242 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 13:13:53.344689 (Thread-1): finished collecting timing info
2020-05-25 13:13:53.381230 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:13:54.071880 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 13:13:54.072511 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 13:13:56.917323 (Thread-1): finished collecting timing info
2020-05-25 13:13:56.918304 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2a9e540-27db-4da7-b670-43cbd6e1e8e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116730730>]}
2020-05-25 13:13:56.918695 (Thread-1): 23:13:56 | 1 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 3.59s]
2020-05-25 13:13:56.918888 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:13:56.919075 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:13:56.919263 (Thread-1): 23:13:56 | 2 of 6 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-05-25 13:13:56.919613 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:13:56.919748 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-05-25 13:13:56.919859 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:13:56.927895 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 13:13:56.928338 (Thread-1): finished collecting timing info
2020-05-25 13:13:56.932376 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:13:57.427344 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 13:13:57.427995 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 13:14:00.394262 (Thread-1): finished collecting timing info
2020-05-25 13:14:00.395141 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2a9e540-27db-4da7-b670-43cbd6e1e8e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116756a60>]}
2020-05-25 13:14:00.395464 (Thread-1): 23:14:00 | 2 of 6 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.48s]
2020-05-25 13:14:00.395642 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:14:00.395825 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:14:00.396002 (Thread-1): 23:14:00 | 3 of 6 START view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [RUN]
2020-05-25 13:14:00.396607 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:14:00.396795 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-05-25 13:14:00.396959 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:14:00.405569 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 13:14:00.405979 (Thread-1): finished collecting timing info
2020-05-25 13:14:00.420612 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 13:14:00.421007 (Thread-1): On model.dbt_servian_demo.Weekly_Total_Confirmed_Cases: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_Total_Confirmed_Cases`
  OPTIONS()
  as (
     

SELECT
  TIMESTAMP_TRUNC(date,WEEK) as date,
  country,
  region_name,
  province_name,
  province_abbreviation,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM 
	`bigquery-public-data`.`covid19_italy`.`data_by_province`

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
      , 
   
     4
      , 
   
     5
     
   

  );

2020-05-25 13:14:02.345021 (Thread-1): finished collecting timing info
2020-05-25 13:14:02.345901 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2a9e540-27db-4da7-b670-43cbd6e1e8e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1167be6a0>]}
2020-05-25 13:14:02.346228 (Thread-1): 23:14:02 | 3 of 6 OK created view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [CREATE VIEW in 1.95s]
2020-05-25 13:14:02.346406 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:14:02.346588 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:14:02.346873 (Thread-1): 23:14:02 | 4 of 6 START view model covid_19_italy_insights.Weekly_national_trend_macro [RUN]
2020-05-25 13:14:02.347199 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:14:02.347313 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_Total_Confirmed_Cases).
2020-05-25 13:14:02.347423 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:14:02.356827 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 13:14:02.357268 (Thread-1): finished collecting timing info
2020-05-25 13:14:02.361967 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 13:14:02.362374 (Thread-1): On model.dbt_servian_demo.Weekly_national_trend_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trend_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trend_macro`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,
	
	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	

FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 13:14:04.188520 (Thread-1): finished collecting timing info
2020-05-25 13:14:04.189396 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2a9e540-27db-4da7-b670-43cbd6e1e8e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1167224f0>]}
2020-05-25 13:14:04.189723 (Thread-1): 23:14:04 | 4 of 6 OK created view model covid_19_italy_insights.Weekly_national_trend_macro [CREATE VIEW in 1.84s]
2020-05-25 13:14:04.189902 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:14:04.190085 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:14:04.190276 (Thread-1): 23:14:04 | 5 of 6 START view model covid_19_italy_insights.Weekly_national_trends [RUN]
2020-05-25 13:14:04.190676 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:14:04.190801 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trend_macro).
2020-05-25 13:14:04.190925 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:14:04.200601 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 13:14:04.201031 (Thread-1): finished collecting timing info
2020-05-25 13:14:04.205785 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 13:14:04.206193 (Thread-1): On model.dbt_servian_demo.Weekly_national_trends: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trends"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trends`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,

	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	
FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 13:14:06.133426 (Thread-1): finished collecting timing info
2020-05-25 13:14:06.134303 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2a9e540-27db-4da7-b670-43cbd6e1e8e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1167be6a0>]}
2020-05-25 13:14:06.134632 (Thread-1): 23:14:06 | 5 of 6 OK created view model covid_19_italy_insights.Weekly_national_trends [CREATE VIEW in 1.94s]
2020-05-25 13:14:06.134809 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:14:06.134990 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:14:06.135183 (Thread-1): 23:14:06 | 6 of 6 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-05-25 13:14:06.135608 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:14:06.135738 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trends).
2020-05-25 13:14:06.135856 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:14:06.144771 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 13:14:06.145205 (Thread-1): finished collecting timing info
2020-05-25 13:14:06.149090 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:14:06.650474 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 13:14:06.651120 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-05-25 13:14:09.426293 (Thread-1): finished collecting timing info
2020-05-25 13:14:09.427195 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2a9e540-27db-4da7-b670-43cbd6e1e8e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1167c6700>]}
2020-05-25 13:14:09.427539 (Thread-1): 23:14:09 | 6 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.29s]
2020-05-25 13:14:09.427721 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:14:09.429128 (MainThread): 23:14:09 | 
2020-05-25 13:14:09.429289 (MainThread): 23:14:09 | Finished running 3 table models, 3 view models in 19.21s.
2020-05-25 13:14:09.429417 (MainThread): Connection 'master' was left open.
2020-05-25 13:14:09.429526 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-05-25 13:14:09.445052 (MainThread): 
2020-05-25 13:14:09.445202 (MainThread): Completed successfully
2020-05-25 13:14:09.445326 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2020-05-25 13:14:09.445537 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11677a940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11677aee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11677a670>]}
2020-05-25 13:14:09.445742 (MainThread): Flushing usage events
2020-05-25 13:14:11.927388 (MainThread): Running with dbt=0.16.1
2020-05-25 13:14:12.292116 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-05-25 13:14:12.292790 (MainThread): Tracking: tracking
2020-05-25 13:14:12.298521 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b6ede80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b6fe5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b6fe5b0>]}
2020-05-25 13:14:12.299069 (MainThread): Checking target/*
2020-05-25 13:14:12.301342 (MainThread):  Cleaned target/*
2020-05-25 13:14:12.301465 (MainThread): Checking dbt_modules/*
2020-05-25 13:14:12.301815 (MainThread):  Cleaned dbt_modules/*
2020-05-25 13:14:12.301910 (MainThread): Finished cleaning all paths.
2020-05-25 13:14:12.302091 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b6ede80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b6fe580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b6fe550>]}
2020-05-25 13:14:12.302273 (MainThread): Flushing usage events
2020-05-25 13:14:14.358657 (MainThread): Running with dbt=0.16.1
2020-05-25 13:14:14.719654 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2020-05-25 13:14:14.720379 (MainThread): Tracking: tracking
2020-05-25 13:14:14.726084 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12309ab50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1230a6700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1230a66d0>]}
2020-05-25 13:14:14.746689 (MainThread): Partial parsing not enabled
2020-05-25 13:14:14.748444 (MainThread): Parsing macros/core.sql
2020-05-25 13:14:14.752742 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:14:14.760322 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:14:14.762076 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:14:14.778062 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:14:14.810924 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:14:14.830674 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:14:14.832420 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:14:14.838449 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:14:14.850533 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:14:14.856909 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:14:14.862728 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:14:14.867283 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:14:14.868212 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:14:14.869196 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:14:14.870697 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:14:14.872612 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:14:14.881094 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:14:14.882941 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:14:14.883926 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:14:14.923853 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:14:14.924930 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:14:14.925784 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:14:14.926811 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:14:14.928977 (MainThread): Parsing macros/etc.sql
2020-05-25 13:14:14.929630 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:14:14.937260 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:14:14.957628 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:14:14.959695 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:14:14.961471 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:14:14.971404 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:14:14.983108 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:14:15.000910 (MainThread): Partial parsing not enabled
2020-05-25 13:14:15.001239 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:14:15.031840 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:14:15.031953 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:14:15.047684 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:14:15.047796 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:15.053669 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:14:15.053752 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:15.061752 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:14:15.061835 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:15.067843 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:14:15.067924 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:15.072792 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:14:15.072870 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:15.102500 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:14:15.102618 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:15.110654 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:14:15.110747 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:15.305522 (MainThread): Acquiring new bigquery connection "generate_catalog".
2020-05-25 13:14:15.305706 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:15.305824 (MainThread): 23:14:15 | Building catalog
2020-05-25 13:14:15.324752 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:14:18.678962 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "graham-hamza-bq-dbt-webinar.information_schema".
2020-05-25 13:14:18.679367 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-25 13:14:18.756337 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:14:19.210465 (ThreadPoolExecutor-0_0): On graham-hamza-bq-dbt-webinar.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "graham-hamza-bq-dbt-webinar.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `graham-hamza-bq-dbt-webinar`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('covid_19_italy_insights'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-05-25 13:14:23.125995 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "bigquery-public-data.information_schema".
2020-05-25 13:14:23.126211 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly graham-hamza-bq-dbt-webinar.information_schema).
2020-05-25 13:14:23.128964 (ThreadPoolExecutor-0_0): On bigquery-public-data.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "bigquery-public-data.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `bigquery-public-data`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('covid19_italy'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bigquery-public-data`.`covid19_italy`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `bigquery-public-data`.`covid19_italy`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `bigquery-public-data`.`covid19_italy`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-05-25 13:14:23.950871 (ThreadPoolExecutor-0_0): Unhandled error while running:
macro get_catalog
2020-05-25 13:14:23.951100 (ThreadPoolExecutor-0_0): Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-05-25 13:14:23.951648 (MainThread): Encountered an error while generating catalog: Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-05-25 13:14:23.998246 (MainThread): dbt encountered 1 failure while writing the catalog
2020-05-25 13:14:23.998501 (MainThread): 23:14:23 | Catalog written to /Users/hamzakhan/Desktop/Work/Servian/dbt-demo/dbt-demo-servian/target/catalog.json
2020-05-25 13:14:23.998770 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12309ab50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1232535b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1232404f0>]}
2020-05-25 13:14:23.999006 (MainThread): Flushing usage events
2020-05-25 13:14:25.075550 (MainThread): Connection 'generate_catalog' was left open.
2020-05-25 13:14:25.075716 (MainThread): Connection 'bigquery-public-data.information_schema' was left open.
2020-05-25 13:14:26.072137 (MainThread): Running with dbt=0.16.1
2020-05-25 13:14:26.489828 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, port=8001, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='serve', write_json=True)
2020-05-25 13:14:26.490502 (MainThread): Tracking: tracking
2020-05-25 13:14:26.497708 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c8fceb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c90c610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c90c5e0>]}
2020-05-25 13:14:26.499769 (MainThread): Serving docs at 0.0.0.0:8001
2020-05-25 13:14:26.499932 (MainThread): To access from your browser, navigate to:  http://localhost:8001
2020-05-25 13:14:26.500025 (MainThread): Press Ctrl+C to exit.


2020-05-25 13:14:40.596110 (MainThread): Flushing usage events
2020-05-25 13:14:41.769576 (MainThread): ctrl-c
2020-05-25 13:14:58.465694 (MainThread): Running with dbt=0.16.1
2020-05-25 13:14:58.837599 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-05-25 13:14:58.838361 (MainThread): Tracking: tracking
2020-05-25 13:14:58.843939 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ab297c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ab39760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ab39730>]}
2020-05-25 13:14:58.866263 (MainThread): Partial parsing not enabled
2020-05-25 13:14:58.868893 (MainThread): Parsing macros/core.sql
2020-05-25 13:14:58.874175 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:14:58.882285 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:14:58.884614 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:14:58.901572 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:14:58.935686 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:14:58.956501 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:14:58.958977 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:14:58.965413 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:14:58.978019 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:14:58.985583 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:14:58.991943 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:14:58.996893 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:14:58.998132 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:14:58.999845 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:14:59.002477 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:14:59.005557 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:14:59.016120 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:14:59.018509 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:14:59.020167 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:14:59.062008 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:14:59.063282 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:14:59.064383 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:14:59.066042 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:14:59.068976 (MainThread): Parsing macros/etc.sql
2020-05-25 13:14:59.070225 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:14:59.078849 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:14:59.100406 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:14:59.102980 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:14:59.104989 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:14:59.114701 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:14:59.126955 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:14:59.145883 (MainThread): Partial parsing not enabled
2020-05-25 13:14:59.147740 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:14:59.183408 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:14:59.183537 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:14:59.199781 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:14:59.199928 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:59.208014 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:14:59.208152 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:59.218694 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:14:59.218840 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:59.226731 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:14:59.226878 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:59.233860 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:14:59.234000 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:59.268256 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:14:59.268382 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:59.276716 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:14:59.276820 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:14:59.515780 (MainThread): Found 6 models, 2 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:14:59.519626 (MainThread): 
2020-05-25 13:14:59.519761 (MainThread): 23:14:59 | Concurrency: 1 threads (target='dev')
2020-05-25 13:14:59.519852 (MainThread): 23:14:59 | 
2020-05-25 13:14:59.524433 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:14:59.524790 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:14:59.524882 (Thread-1): Opening a new connection, currently in state init
2020-05-25 13:14:59.524967 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:14:59.540696 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 13:14:59.541198 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.541453 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.541767 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:14:59.541873 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:14:59.542070 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:14:59.542145 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:14:59.542215 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:14:59.547769 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 13:14:59.548225 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.548428 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.548740 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:14:59.548847 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:14:59.549043 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:14:59.549119 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:14:59.549190 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:14:59.556074 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 13:14:59.556707 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.556952 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.557415 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:14:59.557571 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:14:59.557864 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:14:59.557983 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:14:59.558092 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:14:59.565743 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 13:14:59.566097 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.566306 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.566623 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:14:59.566731 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:14:59.566926 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:14:59.567001 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:14:59.567073 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:14:59.574494 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 13:14:59.574903 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.575123 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.575477 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:14:59.575593 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:14:59.575809 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:14:59.575889 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:14:59.575967 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:14:59.589728 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"
2020-05-25 13:14:59.590220 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.590438 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.590983 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:14:59.591108 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:14:59.591361 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:14:59.591494 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:14:59.591578 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:14:59.598985 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 13:14:59.599338 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.599561 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.599905 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:14:59.600026 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:14:59.600316 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:14:59.600413 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:14:59.600496 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:14:59.607310 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 13:14:59.607696 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.607909 (Thread-1): finished collecting timing info
2020-05-25 13:14:59.608246 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:14:59.608968 (MainThread): Connection 'test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22' was properly closed.
2020-05-25 13:14:59.609064 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-05-25 13:14:59.625459 (MainThread): 23:14:59 | Done.
2020-05-25 13:14:59.625642 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11acf5430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11acde610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11acde370>]}
2020-05-25 13:14:59.625813 (MainThread): Flushing usage events
2020-05-25 13:15:01.655460 (MainThread): Running with dbt=0.16.1
2020-05-25 13:15:02.029447 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-05-25 13:15:02.030121 (MainThread): Tracking: tracking
2020-05-25 13:15:02.035763 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a9f9670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa09730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa09700>]}
2020-05-25 13:15:02.056799 (MainThread): Partial parsing not enabled
2020-05-25 13:15:02.058616 (MainThread): Parsing macros/core.sql
2020-05-25 13:15:02.063112 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:15:02.070580 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:15:02.072266 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:15:02.088766 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:15:02.122022 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:15:02.142395 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:15:02.144200 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:15:02.149924 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:15:02.162158 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:15:02.168557 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:15:02.174410 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:15:02.178965 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:15:02.179856 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:15:02.180845 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:15:02.182401 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:15:02.184315 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:15:02.192775 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:15:02.194616 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:15:02.195606 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:15:02.235722 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:15:02.236824 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:15:02.237681 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:15:02.238704 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:15:02.240865 (MainThread): Parsing macros/etc.sql
2020-05-25 13:15:02.241488 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:15:02.248975 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:15:02.269671 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:15:02.271525 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:15:02.272877 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:15:02.282507 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:15:02.294292 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:15:02.312661 (MainThread): Partial parsing not enabled
2020-05-25 13:15:02.313045 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:15:02.343510 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:15:02.343631 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:15:02.358648 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:15:02.358757 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:02.364566 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:15:02.364648 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:02.372533 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:15:02.372615 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:02.378651 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:15:02.378743 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:02.383626 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:15:02.383707 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:02.414844 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:15:02.414967 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:02.423400 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:15:02.423509 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:02.662477 (MainThread): Found 6 models, 2 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:15:02.666507 (MainThread): 
2020-05-25 13:15:02.666891 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 13:15:02.666970 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:02.680170 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:15:04.193087 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 13:15:04.193581 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-05-25 13:15:04.194270 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:15:04.672082 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:15:05.542841 (MainThread): 23:15:05 | Concurrency: 1 threads (target='dev')
2020-05-25 13:15:05.543073 (MainThread): 23:15:05 | 
2020-05-25 13:15:05.546751 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:15:05.546979 (Thread-1): 23:15:05 | 1 of 2 START test accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22 [RUN]
2020-05-25 13:15:05.547300 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:15:05.547406 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 13:15:05.547526 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:15:05.569450 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"
2020-05-25 13:15:05.569916 (Thread-1): finished collecting timing info
2020-05-25 13:15:05.570223 (Thread-1): On test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"} */





with all_values as (

    select distinct
        region_code as value_field

    from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22
    )
)

select count(*)
from validation_errors


2020-05-25 13:15:09.723267 (Thread-1): finished collecting timing info
2020-05-25 13:15:09.724142 (Thread-1): 23:15:09 | 1 of 2 PASS accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22 [PASS in 4.18s]
2020-05-25 13:15:09.724392 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:15:09.724630 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:15:09.724863 (Thread-1): 23:15:09 | 2 of 2 START test not_null_Confirmed_Case_Per_Reigons_region_code.... [RUN]
2020-05-25 13:15:09.725384 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:15:09.725527 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22).
2020-05-25 13:15:09.725656 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:15:09.735591 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 13:15:09.736055 (Thread-1): finished collecting timing info
2020-05-25 13:15:09.736334 (Thread-1): On test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
where region_code is null


2020-05-25 13:15:11.974299 (Thread-1): finished collecting timing info
2020-05-25 13:15:11.975010 (Thread-1): 23:15:11 | 2 of 2 PASS not_null_Confirmed_Case_Per_Reigons_region_code.......... [PASS in 2.25s]
2020-05-25 13:15:11.975205 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:15:11.976630 (MainThread): 23:15:11 | 
2020-05-25 13:15:11.976786 (MainThread): 23:15:11 | Finished running 2 tests in 9.31s.
2020-05-25 13:15:11.976923 (MainThread): Connection 'master' was left open.
2020-05-25 13:15:11.977023 (MainThread): Connection 'test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code' was left open.
2020-05-25 13:15:11.983337 (MainThread): 
2020-05-25 13:15:11.983489 (MainThread): Completed successfully
2020-05-25 13:15:11.983619 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-05-25 13:15:11.983863 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ab5fe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ab6e280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11abc1df0>]}
2020-05-25 13:15:11.984128 (MainThread): Flushing usage events
2020-05-25 13:15:14.071487 (MainThread): Running with dbt=0.16.1
2020-05-25 13:15:14.434933 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-25 13:15:14.435804 (MainThread): Tracking: tracking
2020-05-25 13:15:14.441569 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bd81a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bd90700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bd906d0>]}
2020-05-25 13:15:14.462977 (MainThread): Partial parsing not enabled
2020-05-25 13:15:14.464831 (MainThread): Parsing macros/core.sql
2020-05-25 13:15:14.469157 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:15:14.477136 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:15:14.478851 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:15:14.495470 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:15:14.528959 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:15:14.549064 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:15:14.550880 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:15:14.556695 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:15:14.568964 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:15:14.575473 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:15:14.581443 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:15:14.586113 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:15:14.587031 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:15:14.588053 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:15:14.589610 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:15:14.591575 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:15:14.600191 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:15:14.602093 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:15:14.603085 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:15:14.643802 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:15:14.644918 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:15:14.645860 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:15:14.646891 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:15:14.649061 (MainThread): Parsing macros/etc.sql
2020-05-25 13:15:14.649684 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:15:14.656990 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:15:14.678746 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:15:14.680634 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:15:14.681989 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:15:14.691051 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:15:14.702880 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:15:14.720623 (MainThread): Partial parsing not enabled
2020-05-25 13:15:14.720964 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:15:14.751450 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:15:14.751569 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:15:14.766764 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:15:14.766877 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:14.772695 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:15:14.772786 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:14.781184 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:15:14.781289 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:14.787342 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:15:14.787431 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:14.792415 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:15:14.792508 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:14.822099 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:15:14.822217 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:14.830431 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:15:14.830524 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:15.068142 (MainThread): Found 6 models, 2 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:15:15.072054 (MainThread): 
2020-05-25 13:15:15.072317 (MainThread): Acquiring new bigquery connection "master".
2020-05-25 13:15:15.072393 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:15.081712 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-05-25 13:15:15.081814 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-25 13:15:15.082631 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:15:17.134964 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:15:18.694618 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-05-25 13:15:18.695973 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-05-25 13:15:18.696377 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:15:19.135731 (MainThread): 23:15:19 | Concurrency: 1 threads (target='dev')
2020-05-25 13:15:19.135955 (MainThread): 23:15:19 | 
2020-05-25 13:15:19.139595 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:15:19.139799 (Thread-1): 23:15:19 | 1 of 6 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-05-25 13:15:19.140115 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:15:19.140216 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-05-25 13:15:19.140338 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:15:19.160847 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 13:15:19.162293 (Thread-1): finished collecting timing info
2020-05-25 13:15:19.201391 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:15:19.896674 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 13:15:19.897337 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 13:15:22.732858 (Thread-1): finished collecting timing info
2020-05-25 13:15:22.733818 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b45be4a-4496-44d2-a508-7a849dd81659', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11beda730>]}
2020-05-25 13:15:22.734218 (Thread-1): 23:15:22 | 1 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 3.59s]
2020-05-25 13:15:22.734412 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:15:22.734600 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:15:22.734785 (Thread-1): 23:15:22 | 2 of 6 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-05-25 13:15:22.735300 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:15:22.735444 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-05-25 13:15:22.735592 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:15:22.743533 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 13:15:22.743973 (Thread-1): finished collecting timing info
2020-05-25 13:15:22.748150 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:15:23.143475 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 13:15:23.144144 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-05-25 13:15:26.213488 (Thread-1): finished collecting timing info
2020-05-25 13:15:26.214376 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b45be4a-4496-44d2-a508-7a849dd81659', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11beb5490>]}
2020-05-25 13:15:26.214715 (Thread-1): 23:15:26 | 2 of 6 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.48s]
2020-05-25 13:15:26.214894 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:15:26.215074 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:15:26.215410 (Thread-1): 23:15:26 | 3 of 6 START view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [RUN]
2020-05-25 13:15:26.215941 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:15:26.216085 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-05-25 13:15:26.216215 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:15:26.225403 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 13:15:26.225859 (Thread-1): finished collecting timing info
2020-05-25 13:15:26.244054 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 13:15:26.244508 (Thread-1): On model.dbt_servian_demo.Weekly_Total_Confirmed_Cases: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_Total_Confirmed_Cases`
  OPTIONS()
  as (
     

SELECT
  TIMESTAMP_TRUNC(date,WEEK) as date,
  country,
  region_name,
  province_name,
  province_abbreviation,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM 
	`bigquery-public-data`.`covid19_italy`.`data_by_province`

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
      , 
   
     4
      , 
   
     5
     
   

  );

2020-05-25 13:15:27.954612 (Thread-1): finished collecting timing info
2020-05-25 13:15:27.955529 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b45be4a-4496-44d2-a508-7a849dd81659', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bedbe80>]}
2020-05-25 13:15:27.955858 (Thread-1): 23:15:27 | 3 of 6 OK created view model covid_19_italy_insights.Weekly_Total_Confirmed_Cases [CREATE VIEW in 1.74s]
2020-05-25 13:15:27.956034 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:15:27.956217 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:15:27.956387 (Thread-1): 23:15:27 | 4 of 6 START view model covid_19_italy_insights.Weekly_national_trend_macro [RUN]
2020-05-25 13:15:27.956810 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:15:27.956927 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_Total_Confirmed_Cases).
2020-05-25 13:15:27.957034 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:15:27.966497 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 13:15:27.966955 (Thread-1): finished collecting timing info
2020-05-25 13:15:27.971696 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 13:15:27.972123 (Thread-1): On model.dbt_servian_demo.Weekly_national_trend_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trend_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trend_macro`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,
	
	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	

FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 13:15:29.816345 (Thread-1): finished collecting timing info
2020-05-25 13:15:29.817224 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b45be4a-4496-44d2-a508-7a849dd81659', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c031670>]}
2020-05-25 13:15:29.817549 (Thread-1): 23:15:29 | 4 of 6 OK created view model covid_19_italy_insights.Weekly_national_trend_macro [CREATE VIEW in 1.86s]
2020-05-25 13:15:29.817725 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:15:29.817903 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:15:29.818077 (Thread-1): 23:15:29 | 5 of 6 START view model covid_19_italy_insights.Weekly_national_trends [RUN]
2020-05-25 13:15:29.818476 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:15:29.818608 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trend_macro).
2020-05-25 13:15:29.818712 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:15:29.828406 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 13:15:29.830593 (Thread-1): finished collecting timing info
2020-05-25 13:15:29.835737 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 13:15:29.836230 (Thread-1): On model.dbt_servian_demo.Weekly_national_trends: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trends"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trends`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,

	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	
FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-05-25 13:15:31.588034 (Thread-1): finished collecting timing info
2020-05-25 13:15:31.588907 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b45be4a-4496-44d2-a508-7a849dd81659', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11beb4c70>]}
2020-05-25 13:15:31.589227 (Thread-1): 23:15:31 | 5 of 6 OK created view model covid_19_italy_insights.Weekly_national_trends [CREATE VIEW in 1.77s]
2020-05-25 13:15:31.589399 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:15:31.589576 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:15:31.589745 (Thread-1): 23:15:31 | 6 of 6 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-05-25 13:15:31.590186 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:15:31.590302 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trends).
2020-05-25 13:15:31.590408 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:15:31.599135 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 13:15:31.599648 (Thread-1): finished collecting timing info
2020-05-25 13:15:31.603504 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-25 13:15:32.091307 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 13:15:32.091938 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-05-25 13:15:35.006048 (Thread-1): finished collecting timing info
2020-05-25 13:15:35.006950 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b45be4a-4496-44d2-a508-7a849dd81659', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bedd0a0>]}
2020-05-25 13:15:35.007284 (Thread-1): 23:15:35 | 6 of 6 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.42s]
2020-05-25 13:15:35.007462 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:15:35.009037 (MainThread): 23:15:35 | 
2020-05-25 13:15:35.009190 (MainThread): 23:15:35 | Finished running 3 table models, 3 view models in 19.94s.
2020-05-25 13:15:35.009364 (MainThread): Connection 'master' was left open.
2020-05-25 13:15:35.009477 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-05-25 13:15:35.026006 (MainThread): 
2020-05-25 13:15:35.026201 (MainThread): Completed successfully
2020-05-25 13:15:35.026343 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2020-05-25 13:15:35.026589 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11befcfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11befc580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11befc880>]}
2020-05-25 13:15:35.026825 (MainThread): Flushing usage events
2020-05-25 13:15:37.494753 (MainThread): Running with dbt=0.16.1
2020-05-25 13:15:37.905367 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-05-25 13:15:37.906068 (MainThread): Tracking: tracking
2020-05-25 13:15:37.912881 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116834e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1168445e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1168445b0>]}
2020-05-25 13:15:37.913801 (MainThread): Checking target/*
2020-05-25 13:15:37.916273 (MainThread):  Cleaned target/*
2020-05-25 13:15:37.916397 (MainThread): Checking dbt_modules/*
2020-05-25 13:15:37.916746 (MainThread):  Cleaned dbt_modules/*
2020-05-25 13:15:37.916840 (MainThread): Finished cleaning all paths.
2020-05-25 13:15:37.917012 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116834e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116844580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116844550>]}
2020-05-25 13:15:37.917184 (MainThread): Flushing usage events
2020-05-25 13:15:40.095102 (MainThread): Running with dbt=0.16.1
2020-05-25 13:15:40.483519 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2020-05-25 13:15:40.484260 (MainThread): Tracking: tracking
2020-05-25 13:15:40.490879 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123e1b7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123e2b760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123e2b730>]}
2020-05-25 13:15:40.510795 (MainThread): Partial parsing not enabled
2020-05-25 13:15:40.513494 (MainThread): Parsing macros/core.sql
2020-05-25 13:15:40.518329 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-25 13:15:40.526156 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-25 13:15:40.527959 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-25 13:15:40.544521 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-25 13:15:40.578361 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-25 13:15:40.598594 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-25 13:15:40.600432 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-25 13:15:40.606294 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-25 13:15:40.618997 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-25 13:15:40.625465 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-25 13:15:40.631420 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-25 13:15:40.636089 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-25 13:15:40.637005 (MainThread): Parsing macros/etc/query.sql
2020-05-25 13:15:40.638018 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-25 13:15:40.639568 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-25 13:15:40.641597 (MainThread): Parsing macros/etc/datetime.sql
2020-05-25 13:15:40.650444 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-25 13:15:40.652396 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-25 13:15:40.653445 (MainThread): Parsing macros/adapters/common.sql
2020-05-25 13:15:40.694488 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-25 13:15:40.695664 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-25 13:15:40.696554 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-25 13:15:40.697618 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-25 13:15:40.701240 (MainThread): Parsing macros/etc.sql
2020-05-25 13:15:40.702047 (MainThread): Parsing macros/catalog.sql
2020-05-25 13:15:40.710071 (MainThread): Parsing macros/adapters.sql
2020-05-25 13:15:40.731171 (MainThread): Parsing macros/materializations/seed.sql
2020-05-25 13:15:40.733128 (MainThread): Parsing macros/materializations/view.sql
2020-05-25 13:15:40.734578 (MainThread): Parsing macros/materializations/table.sql
2020-05-25 13:15:40.744027 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-25 13:15:40.756094 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-25 13:15:40.774886 (MainThread): Partial parsing not enabled
2020-05-25 13:15:40.775253 (MainThread): Parsing macros/project_macros.sql
2020-05-25 13:15:40.806838 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:15:40.806964 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:15:40.822556 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:15:40.822675 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:40.828672 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:15:40.828759 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:40.836948 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:15:40.837041 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:40.843287 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:15:40.843386 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:40.848570 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:15:40.848675 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:40.879547 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:15:40.879672 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:40.888112 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:15:40.888223 (MainThread): Opening a new connection, currently in state closed
2020-05-25 13:15:41.125333 (MainThread): Found 6 models, 2 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 3 sources
2020-05-25 13:15:41.129233 (MainThread): 
2020-05-25 13:15:41.129368 (MainThread): 23:15:41 | Concurrency: 1 threads (target='dev')
2020-05-25 13:15:41.129459 (MainThread): 23:15:41 | 
2020-05-25 13:15:41.131853 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:15:41.132214 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-05-25 13:15:41.132316 (Thread-1): Opening a new connection, currently in state init
2020-05-25 13:15:41.132400 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:15:41.147395 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-05-25 13:15:41.147924 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.148147 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.148482 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-05-25 13:15:41.148594 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:15:41.148792 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-05-25 13:15:41.148868 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:15:41.148941 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:15:41.154527 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-05-25 13:15:41.154977 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.155184 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.155497 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-05-25 13:15:41.155605 (Thread-1): Began running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:15:41.155818 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases".
2020-05-25 13:15:41.155897 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:15:41.155972 (Thread-1): Compiling model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:15:41.163332 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_Total_Confirmed_Cases"
2020-05-25 13:15:41.163910 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.164180 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.164593 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_Total_Confirmed_Cases
2020-05-25 13:15:41.164711 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:15:41.164946 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-05-25 13:15:41.165024 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:15:41.165116 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:15:41.173378 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-05-25 13:15:41.173762 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.174031 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.174389 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-05-25 13:15:41.174510 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:15:41.174812 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-05-25 13:15:41.174907 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:15:41.174991 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:15:41.182794 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-05-25 13:15:41.183155 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.183377 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.183721 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-05-25 13:15:41.183842 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:15:41.184063 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-05-25 13:15:41.184148 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:15:41.184231 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:15:41.197615 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"
2020-05-25 13:15:41.198021 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.198229 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.198558 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-05-25 13:15:41.198669 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:15:41.198870 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-05-25 13:15:41.198947 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:15:41.199021 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:15:41.205798 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-05-25 13:15:41.206079 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.206280 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.206577 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-05-25 13:15:41.206686 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:15:41.206886 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-05-25 13:15:41.206963 (Thread-1): Opening a new connection, currently in state closed
2020-05-25 13:15:41.207038 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:15:41.213352 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-05-25 13:15:41.213689 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.213892 (Thread-1): finished collecting timing info
2020-05-25 13:15:41.214199 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-05-25 13:15:41.214885 (MainThread): Connection 'test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22' was properly closed.
2020-05-25 13:15:41.214974 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-05-25 13:15:41.230192 (MainThread): 23:15:41 | Done.
2020-05-25 13:15:41.231250 (MainThread): Acquiring new bigquery connection "generate_catalog".
2020-05-25 13:15:41.231349 (MainThread): Opening a new connection, currently in state init
2020-05-25 13:15:41.231422 (MainThread): 23:15:41 | Building catalog
2020-05-25 13:15:41.248467 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:15:43.789418 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "graham-hamza-bq-dbt-webinar.information_schema".
2020-05-25 13:15:43.789827 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-25 13:15:43.865069 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-05-25 13:15:44.390753 (ThreadPoolExecutor-0_0): On graham-hamza-bq-dbt-webinar.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "graham-hamza-bq-dbt-webinar.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `graham-hamza-bq-dbt-webinar`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('covid_19_italy_insights'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-05-25 13:15:49.383777 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "bigquery-public-data.information_schema".
2020-05-25 13:15:49.383998 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly graham-hamza-bq-dbt-webinar.information_schema).
2020-05-25 13:15:49.386529 (ThreadPoolExecutor-0_0): On bigquery-public-data.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "bigquery-public-data.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `bigquery-public-data`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('covid19_italy'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bigquery-public-data`.`covid19_italy`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `bigquery-public-data`.`covid19_italy`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `bigquery-public-data`.`covid19_italy`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-05-25 13:15:50.079434 (ThreadPoolExecutor-0_0): Unhandled error while running:
macro get_catalog
2020-05-25 13:15:50.079663 (ThreadPoolExecutor-0_0): Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-05-25 13:15:50.080256 (MainThread): Encountered an error while generating catalog: Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-05-25 13:15:50.172333 (MainThread): dbt encountered 1 failure while writing the catalog
2020-05-25 13:15:50.172666 (MainThread): 23:15:50 | Catalog written to /Users/hamzakhan/Desktop/Work/Servian/dbt-demo/dbt-demo-servian/target/catalog.json
2020-05-25 13:15:50.172898 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123e1b7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1240abca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123eefeb0>]}
2020-05-25 13:15:50.173098 (MainThread): Flushing usage events
2020-05-25 13:15:51.250142 (MainThread): Connection 'generate_catalog' was left open.
2020-05-25 13:15:51.250340 (MainThread): Connection 'bigquery-public-data.information_schema' was left open.
2020-05-25 13:15:52.272806 (MainThread): Running with dbt=0.16.1
2020-05-25 13:15:52.735186 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, port=8001, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='serve', write_json=True)
2020-05-25 13:15:52.735886 (MainThread): Tracking: tracking
2020-05-25 13:15:52.741713 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116701f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116711670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116711640>]}
2020-05-25 13:15:52.743520 (MainThread): Serving docs at 0.0.0.0:8001
2020-05-25 13:15:52.743701 (MainThread): To access from your browser, navigate to:  http://localhost:8001
2020-05-25 13:15:52.743795 (MainThread): Press Ctrl+C to exit.


2020-05-25 13:17:10.028562 (MainThread): Flushing usage events
2020-05-25 13:17:11.278248 (MainThread): ctrl-c
2020-06-01 15:29:19.645154 (MainThread): Running with dbt=0.16.1
2020-06-01 15:29:20.386639 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-06-01 15:29:20.390730 (MainThread): Tracking: tracking
2020-06-01 15:29:20.408478 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121746670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121759760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121759730>]}
2020-06-01 15:29:20.431950 (MainThread): Partial parsing not enabled
2020-06-01 15:29:20.434713 (MainThread): Parsing macros/core.sql
2020-06-01 15:29:20.441523 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-01 15:29:20.451607 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-01 15:29:20.454106 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-01 15:29:20.473526 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-01 15:29:20.512004 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-01 15:29:20.538159 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-01 15:29:20.540804 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-01 15:29:20.548024 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-01 15:29:20.562144 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-01 15:29:20.569009 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-01 15:29:20.575352 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-01 15:29:20.580265 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-01 15:29:20.581425 (MainThread): Parsing macros/etc/query.sql
2020-06-01 15:29:20.582920 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-01 15:29:20.586284 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-01 15:29:20.589334 (MainThread): Parsing macros/etc/datetime.sql
2020-06-01 15:29:20.599952 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-01 15:29:20.602517 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-01 15:29:20.604202 (MainThread): Parsing macros/adapters/common.sql
2020-06-01 15:29:20.646403 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-01 15:29:20.649177 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-01 15:29:20.650623 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-01 15:29:20.653144 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-01 15:29:20.657199 (MainThread): Parsing macros/etc.sql
2020-06-01 15:29:20.658609 (MainThread): Parsing macros/catalog.sql
2020-06-01 15:29:20.668692 (MainThread): Parsing macros/adapters.sql
2020-06-01 15:29:20.690813 (MainThread): Parsing macros/materializations/seed.sql
2020-06-01 15:29:20.693153 (MainThread): Parsing macros/materializations/view.sql
2020-06-01 15:29:20.695354 (MainThread): Parsing macros/materializations/table.sql
2020-06-01 15:29:20.706268 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-01 15:29:20.719069 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-01 15:29:20.739250 (MainThread): Partial parsing not enabled
2020-06-01 15:29:20.740550 (MainThread): Parsing macros/project_macros.sql
2020-06-01 15:29:20.772421 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-06-01 15:29:20.772554 (MainThread): Opening a new connection, currently in state init
2020-06-01 15:29:20.788231 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-06-01 15:29:20.788358 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:29:20.795646 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-06-01 15:29:20.795772 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:29:20.805121 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-06-01 15:29:20.805259 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:29:20.811803 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-06-01 15:29:20.811941 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:29:20.845721 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-06-01 15:29:20.845843 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:29:20.854039 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-06-01 15:29:20.854136 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:29:21.103624 (MainThread): Found 5 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-01 15:29:21.107779 (MainThread): 
2020-06-01 15:29:21.108071 (MainThread): Acquiring new bigquery connection "master".
2020-06-01 15:29:21.108153 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:29:21.119382 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-06-01 15:29:21.119535 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-01 15:29:21.126065 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-01 15:29:23.627860 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-01 15:29:24.954354 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-06-01 15:29:24.954823 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-06-01 15:29:24.955097 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-01 15:29:25.551570 (MainThread): 01:29:25 | Concurrency: 1 threads (target='dev')
2020-06-01 15:29:25.551799 (MainThread): 01:29:25 | 
2020-06-01 15:29:25.557440 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-01 15:29:25.557914 (Thread-1): 01:29:25 | 1 of 5 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-06-01 15:29:25.558264 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-06-01 15:29:25.558367 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-06-01 15:29:25.558495 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-01 15:29:25.579143 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-06-01 15:29:25.580648 (Thread-1): finished collecting timing info
2020-06-01 15:29:25.619403 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-01 15:29:26.167102 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-06-01 15:29:26.167720 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-06-01 15:29:29.195360 (Thread-1): finished collecting timing info
2020-06-01 15:29:29.196294 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4014685-513c-4c02-921b-b8c52ddc8ca0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1217cce20>]}
2020-06-01 15:29:29.196686 (Thread-1): 01:29:29 | 1 of 5 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 3.64s]
2020-06-01 15:29:29.196868 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-01 15:29:29.197049 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-01 15:29:29.197233 (Thread-1): 01:29:29 | 2 of 5 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-06-01 15:29:29.197573 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-06-01 15:29:29.197698 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-06-01 15:29:29.197823 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-01 15:29:29.205843 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-06-01 15:29:29.206299 (Thread-1): finished collecting timing info
2020-06-01 15:29:29.210307 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-01 15:29:29.742702 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-06-01 15:29:29.743421 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-06-01 15:29:32.713239 (Thread-1): finished collecting timing info
2020-06-01 15:29:32.714143 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4014685-513c-4c02-921b-b8c52ddc8ca0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12190dbe0>]}
2020-06-01 15:29:32.714473 (Thread-1): 01:29:32 | 2 of 5 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.52s]
2020-06-01 15:29:32.714668 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-01 15:29:32.714851 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-01 15:29:32.715031 (Thread-1): 01:29:32 | 3 of 5 START view model covid_19_italy_insights.Weekly_national_trend_macro [RUN]
2020-06-01 15:29:32.715620 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-06-01 15:29:32.715768 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-06-01 15:29:32.715915 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-01 15:29:32.725383 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-06-01 15:29:32.725840 (Thread-1): finished collecting timing info
2020-06-01 15:29:32.744614 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-06-01 15:29:32.745086 (Thread-1): On model.dbt_servian_demo.Weekly_national_trend_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trend_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trend_macro`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,
	
	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	

FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-06-01 15:29:34.744636 (Thread-1): finished collecting timing info
2020-06-01 15:29:34.745520 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4014685-513c-4c02-921b-b8c52ddc8ca0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12198c040>]}
2020-06-01 15:29:34.745848 (Thread-1): 01:29:34 | 3 of 5 OK created view model covid_19_italy_insights.Weekly_national_trend_macro [CREATE VIEW in 2.03s]
2020-06-01 15:29:34.746025 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-01 15:29:34.746205 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-06-01 15:29:34.746441 (Thread-1): 01:29:34 | 4 of 5 START view model covid_19_italy_insights.Weekly_national_trends [RUN]
2020-06-01 15:29:34.746760 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-06-01 15:29:34.746870 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trend_macro).
2020-06-01 15:29:34.746978 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-06-01 15:29:34.756632 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-06-01 15:29:34.757062 (Thread-1): finished collecting timing info
2020-06-01 15:29:34.761722 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-06-01 15:29:34.762115 (Thread-1): On model.dbt_servian_demo.Weekly_national_trends: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trends"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trends`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,

	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	
FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-06-01 15:29:36.708239 (Thread-1): finished collecting timing info
2020-06-01 15:29:36.709104 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4014685-513c-4c02-921b-b8c52ddc8ca0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1218b0250>]}
2020-06-01 15:29:36.709426 (Thread-1): 01:29:36 | 4 of 5 OK created view model covid_19_italy_insights.Weekly_national_trends [CREATE VIEW in 1.96s]
2020-06-01 15:29:36.709600 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-06-01 15:29:36.709778 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-01 15:29:36.709974 (Thread-1): 01:29:36 | 5 of 5 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-06-01 15:29:36.710368 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-06-01 15:29:36.710488 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trends).
2020-06-01 15:29:36.710597 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-01 15:29:36.719409 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-06-01 15:29:36.719857 (Thread-1): finished collecting timing info
2020-06-01 15:29:36.723785 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-01 15:29:37.218388 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-06-01 15:29:37.219037 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-06-01 15:29:40.495411 (Thread-1): finished collecting timing info
2020-06-01 15:29:40.496292 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4014685-513c-4c02-921b-b8c52ddc8ca0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12187b040>]}
2020-06-01 15:29:40.496618 (Thread-1): 01:29:40 | 5 of 5 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.79s]
2020-06-01 15:29:40.496792 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-01 15:29:40.498188 (MainThread): 01:29:40 | 
2020-06-01 15:29:40.498339 (MainThread): 01:29:40 | Finished running 3 table models, 2 view models in 19.39s.
2020-06-01 15:29:40.498480 (MainThread): Connection 'master' was left open.
2020-06-01 15:29:40.498572 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-06-01 15:29:40.513569 (MainThread): 
2020-06-01 15:29:40.513785 (MainThread): Completed successfully
2020-06-01 15:29:40.513922 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2020-06-01 15:29:40.514138 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1218fbd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1218fb2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1218fbc40>]}
2020-06-01 15:29:40.514363 (MainThread): Flushing usage events
2020-06-01 15:30:10.525132 (MainThread): Running with dbt=0.16.1
2020-06-01 15:30:10.885455 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-06-01 15:30:10.886130 (MainThread): Tracking: tracking
2020-06-01 15:30:10.891687 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fa336a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fa4b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fa4b760>]}
2020-06-01 15:30:10.911871 (MainThread): Partial parsing not enabled
2020-06-01 15:30:10.913591 (MainThread): Parsing macros/core.sql
2020-06-01 15:30:10.917952 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-01 15:30:10.925605 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-01 15:30:10.927306 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-01 15:30:10.943506 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-01 15:30:10.977061 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-01 15:30:10.997620 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-01 15:30:10.999539 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-01 15:30:11.005818 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-01 15:30:11.018343 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-01 15:30:11.024830 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-01 15:30:11.030905 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-01 15:30:11.035570 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-01 15:30:11.036490 (MainThread): Parsing macros/etc/query.sql
2020-06-01 15:30:11.037493 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-01 15:30:11.039171 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-01 15:30:11.041217 (MainThread): Parsing macros/etc/datetime.sql
2020-06-01 15:30:11.049821 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-01 15:30:11.051692 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-01 15:30:11.052699 (MainThread): Parsing macros/adapters/common.sql
2020-06-01 15:30:11.093095 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-01 15:30:11.094249 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-01 15:30:11.095109 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-01 15:30:11.096132 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-01 15:30:11.098395 (MainThread): Parsing macros/etc.sql
2020-06-01 15:30:11.099019 (MainThread): Parsing macros/catalog.sql
2020-06-01 15:30:11.106262 (MainThread): Parsing macros/adapters.sql
2020-06-01 15:30:11.126959 (MainThread): Parsing macros/materializations/seed.sql
2020-06-01 15:30:11.128812 (MainThread): Parsing macros/materializations/view.sql
2020-06-01 15:30:11.130176 (MainThread): Parsing macros/materializations/table.sql
2020-06-01 15:30:11.139633 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-01 15:30:11.151941 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-01 15:30:11.170562 (MainThread): Partial parsing not enabled
2020-06-01 15:30:11.170894 (MainThread): Parsing macros/project_macros.sql
2020-06-01 15:30:11.200835 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-06-01 15:30:11.200951 (MainThread): Opening a new connection, currently in state init
2020-06-01 15:30:11.215538 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-06-01 15:30:11.215644 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:30:11.222027 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-06-01 15:30:11.222119 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:30:11.229544 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-06-01 15:30:11.229631 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:30:11.235842 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-06-01 15:30:11.235965 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:30:11.265900 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-06-01 15:30:11.266025 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:30:11.274242 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-06-01 15:30:11.274338 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:30:11.511504 (MainThread): Found 5 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-01 15:30:11.515080 (MainThread): 
2020-06-01 15:30:11.515341 (MainThread): Acquiring new bigquery connection "master".
2020-06-01 15:30:11.515418 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:30:11.523363 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-06-01 15:30:11.523460 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-01 15:30:11.524287 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-01 15:30:12.854215 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-06-01 15:30:12.854569 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-06-01 15:30:12.854728 (ThreadPoolExecutor-0_0): Creating schema "graham-hamza-bq-dbt-webinar.covid_19_italy_insights".
2020-06-01 15:30:12.854958 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-01 15:30:13.790483 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-01 15:30:15.837959 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-06-01 15:30:15.838474 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly create_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-06-01 15:30:15.838755 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-01 15:30:16.317574 (MainThread): 01:30:16 | Concurrency: 1 threads (target='dev')
2020-06-01 15:30:16.317908 (MainThread): 01:30:16 | 
2020-06-01 15:30:16.322714 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-01 15:30:16.322943 (Thread-1): 01:30:16 | 1 of 5 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-06-01 15:30:16.323288 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-06-01 15:30:16.323399 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-06-01 15:30:16.323530 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-01 15:30:16.344659 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-06-01 15:30:16.345127 (Thread-1): finished collecting timing info
2020-06-01 15:30:16.468834 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-06-01 15:30:16.469258 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-06-01 15:30:19.818922 (Thread-1): finished collecting timing info
2020-06-01 15:30:19.819875 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7d0036b-6d3a-472d-8ef2-23214b428fd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fafb070>]}
2020-06-01 15:30:19.820259 (Thread-1): 01:30:19 | 1 of 5 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 3.50s]
2020-06-01 15:30:19.820449 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-01 15:30:19.820633 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-01 15:30:19.820822 (Thread-1): 01:30:19 | 2 of 5 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-06-01 15:30:19.821324 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-06-01 15:30:19.821485 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-06-01 15:30:19.821602 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-01 15:30:19.829746 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-06-01 15:30:19.830204 (Thread-1): finished collecting timing info
2020-06-01 15:30:19.835208 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-06-01 15:30:19.835633 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-06-01 15:30:22.947664 (Thread-1): finished collecting timing info
2020-06-01 15:30:22.948425 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7d0036b-6d3a-472d-8ef2-23214b428fd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fb00a90>]}
2020-06-01 15:30:22.948694 (Thread-1): 01:30:22 | 2 of 5 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.13s]
2020-06-01 15:30:22.948847 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-01 15:30:22.948992 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-01 15:30:22.949138 (Thread-1): 01:30:22 | 3 of 5 START view model covid_19_italy_insights.Weekly_national_trend_macro [RUN]
2020-06-01 15:30:22.949409 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-06-01 15:30:22.949707 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-06-01 15:30:22.949841 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-01 15:30:22.959006 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-06-01 15:30:22.959430 (Thread-1): finished collecting timing info
2020-06-01 15:30:22.977884 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-06-01 15:30:22.978379 (Thread-1): On model.dbt_servian_demo.Weekly_national_trend_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trend_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trend_macro`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,
	
	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	

FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-06-01 15:30:25.017841 (Thread-1): finished collecting timing info
2020-06-01 15:30:25.018718 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7d0036b-6d3a-472d-8ef2-23214b428fd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fc89280>]}
2020-06-01 15:30:25.019045 (Thread-1): 01:30:25 | 3 of 5 OK created view model covid_19_italy_insights.Weekly_national_trend_macro [CREATE VIEW in 2.07s]
2020-06-01 15:30:25.019223 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-01 15:30:25.019406 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-06-01 15:30:25.019590 (Thread-1): 01:30:25 | 4 of 5 START view model covid_19_italy_insights.Weekly_national_trends [RUN]
2020-06-01 15:30:25.019995 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-06-01 15:30:25.020114 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trend_macro).
2020-06-01 15:30:25.020220 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-06-01 15:30:25.029869 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-06-01 15:30:25.030302 (Thread-1): finished collecting timing info
2020-06-01 15:30:25.034882 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-06-01 15:30:25.035276 (Thread-1): On model.dbt_servian_demo.Weekly_national_trends: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trends"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trends`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,

	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	
FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-06-01 15:30:27.031582 (Thread-1): finished collecting timing info
2020-06-01 15:30:27.032468 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7d0036b-6d3a-472d-8ef2-23214b428fd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fbc12e0>]}
2020-06-01 15:30:27.032794 (Thread-1): 01:30:27 | 4 of 5 OK created view model covid_19_italy_insights.Weekly_national_trends [CREATE VIEW in 2.01s]
2020-06-01 15:30:27.032969 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-06-01 15:30:27.033151 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-01 15:30:27.033347 (Thread-1): 01:30:27 | 5 of 5 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-06-01 15:30:27.033767 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-06-01 15:30:27.033895 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trends).
2020-06-01 15:30:27.034011 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-01 15:30:27.043166 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-06-01 15:30:27.043626 (Thread-1): finished collecting timing info
2020-06-01 15:30:27.048655 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-06-01 15:30:27.049098 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-06-01 15:30:30.059082 (Thread-1): finished collecting timing info
2020-06-01 15:30:30.059980 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7d0036b-6d3a-472d-8ef2-23214b428fd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fae2910>]}
2020-06-01 15:30:30.060311 (Thread-1): 01:30:30 | 5 of 5 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.03s]
2020-06-01 15:30:30.060490 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-01 15:30:30.061922 (MainThread): 01:30:30 | 
2020-06-01 15:30:30.062074 (MainThread): 01:30:30 | Finished running 3 table models, 2 view models in 18.55s.
2020-06-01 15:30:30.062197 (MainThread): Connection 'master' was left open.
2020-06-01 15:30:30.062290 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-06-01 15:30:30.075897 (MainThread): 
2020-06-01 15:30:30.076077 (MainThread): Completed successfully
2020-06-01 15:30:30.076211 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2020-06-01 15:30:30.076434 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fad9310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fa9a5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fa9a7f0>]}
2020-06-01 15:30:30.076646 (MainThread): Flushing usage events
2020-06-01 15:34:14.272573 (MainThread): Running with dbt=0.16.1
2020-06-01 15:34:14.950068 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2020-06-01 15:34:14.951984 (MainThread): Tracking: tracking
2020-06-01 15:34:14.962944 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11502e850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11503d7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11503d7c0>]}
2020-06-01 15:34:14.985777 (MainThread): Partial parsing not enabled
2020-06-01 15:34:14.989068 (MainThread): Parsing macros/core.sql
2020-06-01 15:34:14.994816 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-01 15:34:15.003662 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-01 15:34:15.005845 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-01 15:34:15.022759 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-01 15:34:15.057020 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-01 15:34:15.078198 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-01 15:34:15.080571 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-01 15:34:15.087160 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-01 15:34:15.100030 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-01 15:34:15.108793 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-01 15:34:15.116415 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-01 15:34:15.121981 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-01 15:34:15.123233 (MainThread): Parsing macros/etc/query.sql
2020-06-01 15:34:15.124662 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-01 15:34:15.126791 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-01 15:34:15.129500 (MainThread): Parsing macros/etc/datetime.sql
2020-06-01 15:34:15.138790 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-01 15:34:15.140954 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-01 15:34:15.142521 (MainThread): Parsing macros/adapters/common.sql
2020-06-01 15:34:15.184476 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-01 15:34:15.185892 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-01 15:34:15.187017 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-01 15:34:15.188457 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-01 15:34:15.191182 (MainThread): Parsing macros/etc.sql
2020-06-01 15:34:15.192430 (MainThread): Parsing macros/catalog.sql
2020-06-01 15:34:15.201361 (MainThread): Parsing macros/adapters.sql
2020-06-01 15:34:15.222503 (MainThread): Parsing macros/materializations/seed.sql
2020-06-01 15:34:15.224597 (MainThread): Parsing macros/materializations/view.sql
2020-06-01 15:34:15.226469 (MainThread): Parsing macros/materializations/table.sql
2020-06-01 15:34:15.237279 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-01 15:34:15.249609 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-01 15:34:15.267695 (MainThread): Partial parsing not enabled
2020-06-01 15:34:15.268868 (MainThread): Parsing macros/project_macros.sql
2020-06-01 15:34:15.301075 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-06-01 15:34:15.301208 (MainThread): Opening a new connection, currently in state init
2020-06-01 15:34:15.316821 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-06-01 15:34:15.316949 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:34:15.324404 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-06-01 15:34:15.324533 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:34:15.333247 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-06-01 15:34:15.333381 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:34:15.340509 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-06-01 15:34:15.340657 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:34:15.374180 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-06-01 15:34:15.374308 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:34:15.382407 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-06-01 15:34:15.382497 (MainThread): Opening a new connection, currently in state closed
2020-06-01 15:34:15.619946 (MainThread): Found 5 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-01 15:34:15.623582 (MainThread): 
2020-06-01 15:34:15.623717 (MainThread): 01:34:15 | Concurrency: 1 threads (target='dev')
2020-06-01 15:34:15.623813 (MainThread): 01:34:15 | 
2020-06-01 15:34:15.627008 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-01 15:34:15.627335 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-06-01 15:34:15.627426 (Thread-1): Opening a new connection, currently in state init
2020-06-01 15:34:15.627513 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-01 15:34:15.642618 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-06-01 15:34:15.642964 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.643185 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.643509 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-01 15:34:15.643618 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-01 15:34:15.643816 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-06-01 15:34:15.643894 (Thread-1): Opening a new connection, currently in state closed
2020-06-01 15:34:15.644107 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-01 15:34:15.649679 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-06-01 15:34:15.649962 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.650158 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.650455 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-01 15:34:15.650563 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-01 15:34:15.650758 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-06-01 15:34:15.650835 (Thread-1): Opening a new connection, currently in state closed
2020-06-01 15:34:15.650908 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-01 15:34:15.658187 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-06-01 15:34:15.658581 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.658791 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.659125 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-01 15:34:15.659237 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-06-01 15:34:15.659443 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-06-01 15:34:15.659522 (Thread-1): Opening a new connection, currently in state closed
2020-06-01 15:34:15.659598 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-06-01 15:34:15.667053 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-06-01 15:34:15.667351 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.667562 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.667889 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-06-01 15:34:15.668004 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-06-01 15:34:15.668209 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-06-01 15:34:15.668295 (Thread-1): Opening a new connection, currently in state closed
2020-06-01 15:34:15.668372 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-06-01 15:34:15.681402 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"
2020-06-01 15:34:15.681767 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.681983 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.682292 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-06-01 15:34:15.682408 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-06-01 15:34:15.682621 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-06-01 15:34:15.682707 (Thread-1): Opening a new connection, currently in state closed
2020-06-01 15:34:15.682842 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-06-01 15:34:15.689919 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-06-01 15:34:15.690247 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.690454 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.690754 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-06-01 15:34:15.690866 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-01 15:34:15.691066 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-06-01 15:34:15.691146 (Thread-1): Opening a new connection, currently in state closed
2020-06-01 15:34:15.691222 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-01 15:34:15.697649 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-06-01 15:34:15.697942 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.698139 (Thread-1): finished collecting timing info
2020-06-01 15:34:15.698438 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-01 15:34:15.699101 (MainThread): Connection 'test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22' was properly closed.
2020-06-01 15:34:15.699193 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-06-01 15:34:15.712984 (MainThread): 01:34:15 | Done.
2020-06-01 15:34:15.718058 (MainThread): Acquiring new bigquery connection "generate_catalog".
2020-06-01 15:34:15.718239 (MainThread): Opening a new connection, currently in state init
2020-06-01 15:34:15.718363 (MainThread): 01:34:15 | Building catalog
2020-06-01 15:34:15.736816 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-01 15:34:18.530320 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "graham-hamza-bq-dbt-webinar.information_schema".
2020-06-01 15:34:18.530783 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-01 15:34:18.608060 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-01 15:34:19.070805 (ThreadPoolExecutor-0_0): On graham-hamza-bq-dbt-webinar.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "graham-hamza-bq-dbt-webinar.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `graham-hamza-bq-dbt-webinar`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('covid_19_italy_insights'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-01 15:34:23.926976 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "bigquery-public-data.information_schema".
2020-06-01 15:34:23.927193 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly graham-hamza-bq-dbt-webinar.information_schema).
2020-06-01 15:34:23.930637 (ThreadPoolExecutor-0_0): On bigquery-public-data.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "bigquery-public-data.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `bigquery-public-data`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('covid19_italy'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bigquery-public-data`.`covid19_italy`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `bigquery-public-data`.`covid19_italy`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `bigquery-public-data`.`covid19_italy`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-01 15:34:24.679080 (ThreadPoolExecutor-0_0): Unhandled error while running:
macro get_catalog
2020-06-01 15:34:24.679320 (ThreadPoolExecutor-0_0): Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-01 15:34:24.679919 (MainThread): Encountered an error while generating catalog: Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-01 15:34:24.764874 (MainThread): dbt encountered 1 failure while writing the catalog
2020-06-01 15:34:24.765112 (MainThread): 01:34:24 | Catalog written to /Users/hamzakhan/Desktop/Work/Servian/dbt-demo/dbt-demo-servian/target/catalog.json
2020-06-01 15:34:24.765364 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11502e850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1151db5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1151dbc40>]}
2020-06-01 15:34:24.765575 (MainThread): Flushing usage events
2020-06-01 15:34:25.790548 (MainThread): Connection 'generate_catalog' was left open.
2020-06-01 15:34:25.790751 (MainThread): Connection 'bigquery-public-data.information_schema' was left open.
2020-06-01 15:34:45.899324 (MainThread): Running with dbt=0.16.1
2020-06-01 15:34:46.277617 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, port=8001, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='serve', write_json=True)
2020-06-01 15:34:46.278588 (MainThread): Tracking: tracking
2020-06-01 15:34:46.284223 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124aa5730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124ab4730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124ab4700>]}
2020-06-01 15:34:46.285918 (MainThread): Serving docs at 0.0.0.0:8001
2020-06-01 15:34:46.286082 (MainThread): To access from your browser, navigate to:  http://localhost:8001
2020-06-01 15:34:46.286168 (MainThread): Press Ctrl+C to exit.


2020-06-01 15:36:45.801902 (MainThread): Flushing usage events
2020-06-01 15:36:46.883454 (MainThread): ctrl-c
2020-06-02 22:54:08.664809 (MainThread): Running with dbt=0.16.1
2020-06-02 22:54:09.411151 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-06-02 22:54:09.412364 (MainThread): Tracking: tracking
2020-06-02 22:54:09.422387 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb58b1906a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb58b1a7790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb58b1a7760>]}
2020-06-02 22:54:09.448720 (MainThread): Partial parsing not enabled
2020-06-02 22:54:09.451322 (MainThread): Parsing macros/core.sql
2020-06-02 22:54:09.458077 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-02 22:54:09.467934 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-02 22:54:09.470318 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-02 22:54:09.490307 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-02 22:54:09.530332 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-02 22:54:09.554121 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-02 22:54:09.556875 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-02 22:54:09.564695 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-02 22:54:09.579991 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-02 22:54:09.587642 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-02 22:54:09.594719 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-02 22:54:09.600184 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-02 22:54:09.601345 (MainThread): Parsing macros/etc/query.sql
2020-06-02 22:54:09.602861 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-02 22:54:09.605120 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-02 22:54:09.607983 (MainThread): Parsing macros/etc/datetime.sql
2020-06-02 22:54:09.618960 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-02 22:54:09.621520 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-02 22:54:09.623258 (MainThread): Parsing macros/adapters/common.sql
2020-06-02 22:54:09.672353 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-02 22:54:09.673883 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-02 22:54:09.675125 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-02 22:54:09.676628 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-02 22:54:09.679995 (MainThread): Parsing macros/etc.sql
2020-06-02 22:54:09.681415 (MainThread): Parsing macros/catalog.sql
2020-06-02 22:54:09.691122 (MainThread): Parsing macros/adapters.sql
2020-06-02 22:54:09.716618 (MainThread): Parsing macros/materializations/seed.sql
2020-06-02 22:54:09.718947 (MainThread): Parsing macros/materializations/view.sql
2020-06-02 22:54:09.721147 (MainThread): Parsing macros/materializations/table.sql
2020-06-02 22:54:09.733004 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-02 22:54:09.747924 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-02 22:54:09.769523 (MainThread): Partial parsing not enabled
2020-06-02 22:54:09.770267 (MainThread): Parsing macros/project_macros.sql
2020-06-02 22:54:09.806863 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-06-02 22:54:09.807012 (MainThread): Opening a new connection, currently in state init
2020-06-02 22:54:09.824419 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-06-02 22:54:09.824555 (MainThread): Opening a new connection, currently in state closed
2020-06-02 22:54:09.832877 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-06-02 22:54:09.833020 (MainThread): Opening a new connection, currently in state closed
2020-06-02 22:54:09.842982 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-06-02 22:54:09.843132 (MainThread): Opening a new connection, currently in state closed
2020-06-02 22:54:09.849979 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-06-02 22:54:09.850124 (MainThread): Opening a new connection, currently in state closed
2020-06-02 22:54:09.889797 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-06-02 22:54:09.889952 (MainThread): Opening a new connection, currently in state closed
2020-06-02 22:54:09.900999 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-06-02 22:54:09.901162 (MainThread): Opening a new connection, currently in state closed
2020-06-02 22:54:10.175624 (MainThread): Found 5 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-02 22:54:10.180122 (MainThread): 
2020-06-02 22:54:10.180478 (MainThread): Acquiring new bigquery connection "master".
2020-06-02 22:54:10.180577 (MainThread): Opening a new connection, currently in state closed
2020-06-02 22:54:10.190594 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-06-02 22:54:10.190802 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-02 22:54:10.193644 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-02 22:54:13.631519 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-02 22:54:15.016868 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights".
2020-06-02 22:54:15.017170 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-06-02 22:54:15.017351 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-02 22:54:15.431781 (MainThread): 08:54:15 | Concurrency: 1 threads (target='dev')
2020-06-02 22:54:15.432038 (MainThread): 08:54:15 | 
2020-06-02 22:54:15.437330 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-02 22:54:15.437555 (Thread-1): 08:54:15 | 1 of 5 START table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [RUN]
2020-06-02 22:54:15.437901 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-06-02 22:54:15.438000 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_covid_19_italy_insights).
2020-06-02 22:54:15.438126 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-02 22:54:15.459314 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-06-02 22:54:15.459952 (Thread-1): finished collecting timing info
2020-06-02 22:54:15.501372 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-02 22:54:16.224870 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-06-02 22:54:16.225389 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  SAFE_CAST(region_code AS int64) AS region_code,
  region_name,
  SUM(confirmed_cases) as Total_Confirmed_Cases
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_province`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-06-02 22:54:19.420926 (Thread-1): finished collecting timing info
2020-06-02 22:54:19.421707 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f684056-f182-4ead-85fd-f5d496a7a21a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb58b2ccdc0>]}
2020-06-02 22:54:19.422021 (Thread-1): 08:54:19 | 1 of 5 OK created table model covid_19_italy_insights.Confirmed_Case_Per_Reigons [CREATE TABLE (21) in 3.98s]
2020-06-02 22:54:19.422171 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-02 22:54:19.422321 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-02 22:54:19.422585 (Thread-1): 08:54:19 | 2 of 5 START table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [RUN]
2020-06-02 22:54:19.422877 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-06-02 22:54:19.422977 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Confirmed_Case_Per_Reigons).
2020-06-02 22:54:19.423101 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-02 22:54:19.430778 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-06-02 22:54:19.431242 (Thread-1): finished collecting timing info
2020-06-02 22:54:19.435623 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-02 22:54:19.819484 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-06-02 22:54:19.820010 (Thread-1): On model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons`
  
  
  OPTIONS()
  as (
    SELECT
  region_code,
  region_name,
  SUM(total_hospitalized_patients) as Total_Hospitalized_Patients
FROM
  `bigquery-public-data`.`covid19_italy`.`data_by_region`
GROUP BY
  1,
  2
ORDER BY
  1
  );
    
2020-06-02 22:54:22.845249 (Thread-1): finished collecting timing info
2020-06-02 22:54:22.846182 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f684056-f182-4ead-85fd-f5d496a7a21a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb58b358040>]}
2020-06-02 22:54:22.846462 (Thread-1): 08:54:22 | 2 of 5 OK created table model covid_19_italy_insights.Hospitalized_Patients_Per_Reigons [CREATE TABLE (21) in 3.42s]
2020-06-02 22:54:22.846606 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-02 22:54:22.846761 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-02 22:54:22.846902 (Thread-1): 08:54:22 | 3 of 5 START view model covid_19_italy_insights.Weekly_national_trend_macro [RUN]
2020-06-02 22:54:22.847306 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-06-02 22:54:22.847521 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons).
2020-06-02 22:54:22.847654 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-02 22:54:22.857141 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-06-02 22:54:22.857622 (Thread-1): finished collecting timing info
2020-06-02 22:54:22.877099 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-06-02 22:54:22.877729 (Thread-1): On model.dbt_servian_demo.Weekly_national_trend_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trend_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trend_macro`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,
	
	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	

FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-06-02 22:54:24.586714 (Thread-1): finished collecting timing info
2020-06-02 22:54:24.587471 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f684056-f182-4ead-85fd-f5d496a7a21a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb58b3dc760>]}
2020-06-02 22:54:24.587751 (Thread-1): 08:54:24 | 3 of 5 OK created view model covid_19_italy_insights.Weekly_national_trend_macro [CREATE VIEW in 1.74s]
2020-06-02 22:54:24.587901 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-02 22:54:24.588060 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-06-02 22:54:24.588303 (Thread-1): 08:54:24 | 4 of 5 START view model covid_19_italy_insights.Weekly_national_trends [RUN]
2020-06-02 22:54:24.588657 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-06-02 22:54:24.588771 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trend_macro).
2020-06-02 22:54:24.588875 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-06-02 22:54:24.598170 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-06-02 22:54:24.598634 (Thread-1): finished collecting timing info
2020-06-02 22:54:24.603283 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-06-02 22:54:24.603782 (Thread-1): On model.dbt_servian_demo.Weekly_national_trends: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Weekly_national_trends"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Weekly_national_trends`
  OPTIONS()
  as (
     



SELECT
	TIMESTAMP_TRUNC(date, WEEK) as Date,

	
		SUM(hospitalized_patients_symptoms) as hospitalized_patients_symptoms,
	
		SUM(hospitalized_patients_intensive_care) as hospitalized_patients_intensive_care,
	
		SUM(total_hospitalized_patients) as total_hospitalized_patients,
	
		SUM(home_confinement_cases) as home_confinement_cases,
	
		SUM(total_current_confirmed_cases) as total_current_confirmed_cases,
	
		SUM(new_current_confirmed_cases) as new_current_confirmed_cases,
	
		SUM(new_total_confirmed_cases) as new_total_confirmed_cases,
	
		SUM(recovered) as recovered,
	
		SUM(deaths) as deaths,
	
		SUM(total_confirmed_cases) as total_confirmed_cases,
	
		SUM(tests_performed) as tests_performed,
	
FROM
	`bigquery-public-data`.`covid19_italy`.`national_trends`
GROUP BY 
	1
  );

2020-06-02 22:54:26.385717 (Thread-1): finished collecting timing info
2020-06-02 22:54:26.386469 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f684056-f182-4ead-85fd-f5d496a7a21a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb58b358550>]}
2020-06-02 22:54:26.386748 (Thread-1): 08:54:26 | 4 of 5 OK created view model covid_19_italy_insights.Weekly_national_trends [CREATE VIEW in 1.80s]
2020-06-02 22:54:26.386893 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-06-02 22:54:26.387043 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-02 22:54:26.387287 (Thread-1): 08:54:26 | 5 of 5 START table model covid_19_italy_insights.Confirmed_Case_Hospitalized [RUN]
2020-06-02 22:54:26.387579 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-06-02 22:54:26.387680 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.Weekly_national_trends).
2020-06-02 22:54:26.387780 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-02 22:54:26.397020 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-06-02 22:54:26.397518 (Thread-1): finished collecting timing info
2020-06-02 22:54:26.401655 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-02 22:54:26.823448 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-06-02 22:54:26.823979 (Thread-1): On model.dbt_servian_demo.Confirmed_Case_Hospitalized: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.Confirmed_Case_Hospitalized"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Hospitalized`
  
  
  OPTIONS()
  as (
    SELECT
	Confirmed_Cases.region_code,
	Confirmed_Cases.region_name,
	Confirmed_Cases.Total_Confirmed_Cases,
	Hospitalized_Patients.Total_Hospitalized_Patients
FROM
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Confirmed_Case_Per_Reigons` Confirmed_Cases
JOIN
	`graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.`Hospitalized_Patients_Per_Reigons` Hospitalized_Patients
ON
	Confirmed_Cases.region_code = Hospitalized_Patients.region_code
ORDER BY 
	1
  );
    
2020-06-02 22:54:30.210332 (Thread-1): finished collecting timing info
2020-06-02 22:54:30.211397 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f684056-f182-4ead-85fd-f5d496a7a21a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb58b3c03a0>]}
2020-06-02 22:54:30.211707 (Thread-1): 08:54:30 | 5 of 5 OK created table model covid_19_italy_insights.Confirmed_Case_Hospitalized [CREATE TABLE (21) in 3.82s]
2020-06-02 22:54:30.211854 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-02 22:54:30.213169 (MainThread): 08:54:30 | 
2020-06-02 22:54:30.213325 (MainThread): 08:54:30 | Finished running 3 table models, 2 view models in 20.03s.
2020-06-02 22:54:30.213444 (MainThread): Connection 'master' was left open.
2020-06-02 22:54:30.213534 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was left open.
2020-06-02 22:54:30.226268 (MainThread): 
2020-06-02 22:54:30.226460 (MainThread): Completed successfully
2020-06-02 22:54:30.226599 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2020-06-02 22:54:30.226822 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb58b31d6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb58b31da00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb58b31de80>]}
2020-06-02 22:54:30.227045 (MainThread): Flushing usage events
2020-06-02 23:02:17.889969 (MainThread): Running with dbt=0.16.1
2020-06-02 23:02:18.323087 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2020-06-02 23:02:18.324141 (MainThread): Tracking: tracking
2020-06-02 23:02:18.330472 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf9f8977c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf9f8a7760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf9f8a7730>]}
2020-06-02 23:02:18.354869 (MainThread): Partial parsing not enabled
2020-06-02 23:02:18.357171 (MainThread): Parsing macros/core.sql
2020-06-02 23:02:18.362441 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-02 23:02:18.372102 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-02 23:02:18.374252 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-02 23:02:18.394147 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-02 23:02:18.433302 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-02 23:02:18.457053 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-02 23:02:18.459154 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-02 23:02:18.465944 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-02 23:02:18.479559 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-02 23:02:18.486933 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-02 23:02:18.494066 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-02 23:02:18.499868 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-02 23:02:18.500973 (MainThread): Parsing macros/etc/query.sql
2020-06-02 23:02:18.502127 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-02 23:02:18.503930 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-02 23:02:18.506212 (MainThread): Parsing macros/etc/datetime.sql
2020-06-02 23:02:18.516372 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-02 23:02:18.518602 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-02 23:02:18.519776 (MainThread): Parsing macros/adapters/common.sql
2020-06-02 23:02:18.565513 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-02 23:02:18.566846 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-02 23:02:18.567837 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-02 23:02:18.569029 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-02 23:02:18.571538 (MainThread): Parsing macros/etc.sql
2020-06-02 23:02:18.572333 (MainThread): Parsing macros/catalog.sql
2020-06-02 23:02:18.581282 (MainThread): Parsing macros/adapters.sql
2020-06-02 23:02:18.603355 (MainThread): Parsing macros/materializations/seed.sql
2020-06-02 23:02:18.605460 (MainThread): Parsing macros/materializations/view.sql
2020-06-02 23:02:18.607298 (MainThread): Parsing macros/materializations/table.sql
2020-06-02 23:02:18.617039 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-02 23:02:18.630420 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-02 23:02:18.649941 (MainThread): Partial parsing not enabled
2020-06-02 23:02:18.650308 (MainThread): Parsing macros/project_macros.sql
2020-06-02 23:02:18.684701 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-06-02 23:02:18.684853 (MainThread): Opening a new connection, currently in state init
2020-06-02 23:02:18.702710 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-06-02 23:02:18.702846 (MainThread): Opening a new connection, currently in state closed
2020-06-02 23:02:18.710799 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-06-02 23:02:18.710936 (MainThread): Opening a new connection, currently in state closed
2020-06-02 23:02:18.719606 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-06-02 23:02:18.719727 (MainThread): Opening a new connection, currently in state closed
2020-06-02 23:02:18.725995 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-06-02 23:02:18.726128 (MainThread): Opening a new connection, currently in state closed
2020-06-02 23:02:18.762389 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-06-02 23:02:18.762536 (MainThread): Opening a new connection, currently in state closed
2020-06-02 23:02:18.772577 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-06-02 23:02:18.772735 (MainThread): Opening a new connection, currently in state closed
2020-06-02 23:02:19.039851 (MainThread): Found 5 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-02 23:02:19.044256 (MainThread): 
2020-06-02 23:02:19.044445 (MainThread): 09:02:19 | Concurrency: 1 threads (target='dev')
2020-06-02 23:02:19.044555 (MainThread): 09:02:19 | 
2020-06-02 23:02:19.047476 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-02 23:02:19.047818 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Per_Reigons".
2020-06-02 23:02:19.047914 (Thread-1): Opening a new connection, currently in state init
2020-06-02 23:02:19.048005 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-02 23:02:19.064640 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Per_Reigons"
2020-06-02 23:02:19.065187 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.065481 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.065902 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Per_Reigons
2020-06-02 23:02:19.066045 (Thread-1): Began running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-02 23:02:19.066274 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons".
2020-06-02 23:02:19.066358 (Thread-1): Opening a new connection, currently in state closed
2020-06-02 23:02:19.066618 (Thread-1): Compiling model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-02 23:02:19.073029 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons"
2020-06-02 23:02:19.073392 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.073622 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.073989 (Thread-1): Finished running node model.dbt_servian_demo.Hospitalized_Patients_Per_Reigons
2020-06-02 23:02:19.074116 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-02 23:02:19.074347 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trend_macro".
2020-06-02 23:02:19.074434 (Thread-1): Opening a new connection, currently in state closed
2020-06-02 23:02:19.074517 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-02 23:02:19.083372 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trend_macro"
2020-06-02 23:02:19.083780 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.084018 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.084380 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trend_macro
2020-06-02 23:02:19.084505 (Thread-1): Began running node model.dbt_servian_demo.Weekly_national_trends
2020-06-02 23:02:19.084732 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Weekly_national_trends".
2020-06-02 23:02:19.084820 (Thread-1): Opening a new connection, currently in state closed
2020-06-02 23:02:19.084905 (Thread-1): Compiling model.dbt_servian_demo.Weekly_national_trends
2020-06-02 23:02:19.093407 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Weekly_national_trends"
2020-06-02 23:02:19.093833 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.094073 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.094457 (Thread-1): Finished running node model.dbt_servian_demo.Weekly_national_trends
2020-06-02 23:02:19.094588 (Thread-1): Began running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-06-02 23:02:19.094934 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22".
2020-06-02 23:02:19.095057 (Thread-1): Opening a new connection, currently in state closed
2020-06-02 23:02:19.095137 (Thread-1): Compiling test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-06-02 23:02:19.110455 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22"
2020-06-02 23:02:19.110954 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.111245 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.111681 (Thread-1): Finished running node test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22
2020-06-02 23:02:19.111818 (Thread-1): Began running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-06-02 23:02:19.112070 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code".
2020-06-02 23:02:19.112291 (Thread-1): Opening a new connection, currently in state closed
2020-06-02 23:02:19.112403 (Thread-1): Compiling test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-06-02 23:02:19.121063 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code"
2020-06-02 23:02:19.121498 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.121741 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.122117 (Thread-1): Finished running node test.dbt_servian_demo.not_null_Confirmed_Case_Per_Reigons_region_code
2020-06-02 23:02:19.122246 (Thread-1): Began running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-02 23:02:19.122491 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.Confirmed_Case_Hospitalized".
2020-06-02 23:02:19.122581 (Thread-1): Opening a new connection, currently in state closed
2020-06-02 23:02:19.122672 (Thread-1): Compiling model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-02 23:02:19.130789 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.Confirmed_Case_Hospitalized"
2020-06-02 23:02:19.131223 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.131468 (Thread-1): finished collecting timing info
2020-06-02 23:02:19.131847 (Thread-1): Finished running node model.dbt_servian_demo.Confirmed_Case_Hospitalized
2020-06-02 23:02:19.132687 (MainThread): Connection 'test.dbt_servian_demo.accepted_values_Confirmed_Case_Per_Reigons_region_code__False__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22' was properly closed.
2020-06-02 23:02:19.132791 (MainThread): Connection 'model.dbt_servian_demo.Confirmed_Case_Hospitalized' was properly closed.
2020-06-02 23:02:19.148452 (MainThread): 09:02:19 | Done.
2020-06-02 23:02:19.151013 (MainThread): Acquiring new bigquery connection "generate_catalog".
2020-06-02 23:02:19.151163 (MainThread): Opening a new connection, currently in state init
2020-06-02 23:02:19.151274 (MainThread): 09:02:19 | Building catalog
2020-06-02 23:02:19.170072 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-02 23:02:21.662809 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "graham-hamza-bq-dbt-webinar.information_schema".
2020-06-02 23:02:21.663381 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-02 23:02:21.741021 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-02 23:02:22.314202 (ThreadPoolExecutor-0_0): On graham-hamza-bq-dbt-webinar.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "graham-hamza-bq-dbt-webinar.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `graham-hamza-bq-dbt-webinar`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('covid_19_italy_insights'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `graham-hamza-bq-dbt-webinar`.`covid_19_italy_insights`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-02 23:02:26.494566 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "bigquery-public-data.information_schema".
2020-06-02 23:02:26.494799 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly graham-hamza-bq-dbt-webinar.information_schema).
2020-06-02 23:02:26.498206 (ThreadPoolExecutor-0_0): On bigquery-public-data.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "bigquery-public-data.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `bigquery-public-data`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('covid19_italy'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bigquery-public-data`.`covid19_italy`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `bigquery-public-data`.`covid19_italy`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `bigquery-public-data`.`covid19_italy`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-02 23:02:27.226199 (ThreadPoolExecutor-0_0): Unhandled error while running:
macro get_catalog
2020-06-02 23:02:27.226363 (ThreadPoolExecutor-0_0): Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-02 23:02:27.226741 (MainThread): Encountered an error while generating catalog: Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-02 23:02:27.317650 (MainThread): dbt encountered 1 failure while writing the catalog
2020-06-02 23:02:27.317994 (MainThread): 09:02:27 | Catalog written to /Users/hamzakhan/Desktop/Work/Servian/dbt-demo/dbt-demo-servian/target/catalog.json
2020-06-02 23:02:27.318304 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf9f8977c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf9fd416d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf9fb61cd0>]}
2020-06-02 23:02:27.318542 (MainThread): Flushing usage events
2020-06-02 23:02:28.304756 (MainThread): Connection 'generate_catalog' was left open.
2020-06-02 23:02:28.304923 (MainThread): Connection 'bigquery-public-data.information_schema' was left open.
2020-06-02 23:02:47.979651 (MainThread): Running with dbt=0.16.1
2020-06-02 23:02:48.449778 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, port=8001, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='serve', write_json=True)
2020-06-02 23:02:48.450797 (MainThread): Tracking: tracking
2020-06-02 23:02:48.458814 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca25a95730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca25aa7730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca25aa7700>]}
2020-06-02 23:02:48.461609 (MainThread): Serving docs at 0.0.0.0:8001
2020-06-02 23:02:48.461861 (MainThread): To access from your browser, navigate to:  http://localhost:8001
2020-06-02 23:02:48.461966 (MainThread): Press Ctrl+C to exit.


2020-06-02 23:49:19.372097 (MainThread): Flushing usage events
2020-06-02 23:49:20.215656 (MainThread): ctrl-c
2020-06-03 13:21:33.113521 (MainThread): Running with dbt=0.16.1
2020-06-03 13:21:33.478178 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-06-03 13:21:33.479921 (MainThread): Tracking: tracking
2020-06-03 13:21:33.485348 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff888b97b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff888ba9700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff888ba96d0>]}
2020-06-03 13:21:33.505968 (MainThread): Partial parsing not enabled
2020-06-03 13:21:33.508325 (MainThread): Parsing macros/core.sql
2020-06-03 13:21:33.514478 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:21:33.522608 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:21:33.525028 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:21:33.541673 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:21:33.575874 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:21:33.596448 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:21:33.598768 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:21:33.605425 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:21:33.618052 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:21:33.624637 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:21:33.631062 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:21:33.636550 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:21:33.637651 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:21:33.639040 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:21:33.641213 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:21:33.643772 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:21:33.653200 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:21:33.655803 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:21:33.657401 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:21:33.699051 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:21:33.700574 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:21:33.701584 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:21:33.702849 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:21:33.705371 (MainThread): Parsing macros/etc.sql
2020-06-03 13:21:33.706235 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:21:33.714334 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:21:33.735340 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:21:33.737732 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:21:33.739643 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:21:33.749663 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:21:33.761846 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:21:33.781045 (MainThread): Partial parsing not enabled
2020-06-03 13:21:33.781954 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:21:33.813214 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:21:33.813345 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:21:33.829079 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:21:33.829214 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:33.835901 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:21:33.836030 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:33.843483 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:21:33.843633 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:33.877764 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:21:33.877899 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:33.886508 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:21:33.886627 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:34.072369 (MainThread): WARNING: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_servian_demo.medicare_provider_2011_analysis_bq

2020-06-03 13:21:34.120548 (MainThread): Found 4 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:21:34.126924 (MainThread): 
2020-06-03 13:21:34.127110 (MainThread): 23:21:34 | Concurrency: 1 threads (target='dev')
2020-06-03 13:21:34.127240 (MainThread): 23:21:34 | 
2020-06-03 13:21:34.132980 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:21:34.133403 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:21:34.133520 (Thread-1): Opening a new connection, currently in state init
2020-06-03 13:21:34.133629 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:21:34.151495 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:21:34.151997 (Thread-1): finished collecting timing info
2020-06-03 13:21:34.152243 (Thread-1): finished collecting timing info
2020-06-03 13:21:34.152605 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:21:34.152727 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:21:34.152950 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:21:34.153048 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:21:34.153132 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:21:34.160372 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:21:34.160819 (Thread-1): finished collecting timing info
2020-06-03 13:21:34.161055 (Thread-1): finished collecting timing info
2020-06-03 13:21:34.161423 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:21:34.161548 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:21:34.161773 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:21:34.161860 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:21:34.161943 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:21:34.169771 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:21:34.170142 (Thread-1): finished collecting timing info
2020-06-03 13:21:34.170363 (Thread-1): finished collecting timing info
2020-06-03 13:21:34.170703 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:21:34.170823 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:21:34.171038 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:21:34.171122 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:21:34.171202 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:21:34.183964 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"
2020-06-03 13:21:34.184347 (Thread-1): finished collecting timing info
2020-06-03 13:21:34.184571 (Thread-1): finished collecting timing info
2020-06-03 13:21:34.184917 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:21:34.185038 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:21:34.185258 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:21:34.185342 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:21:34.185422 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:21:34.192421 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:21:34.192731 (Thread-1): finished collecting timing info
2020-06-03 13:21:34.192943 (Thread-1): finished collecting timing info
2020-06-03 13:21:34.193279 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:21:34.193414 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:21:34.193634 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:21:34.193717 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:21:34.193795 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:21:34.201725 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"
2020-06-03 13:21:34.202150 (Thread-1): finished collecting timing info
2020-06-03 13:21:34.202388 (Thread-1): finished collecting timing info
2020-06-03 13:21:34.202744 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:21:34.203433 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id' was properly closed.
2020-06-03 13:21:34.203534 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id' was properly closed.
2020-06-03 13:21:34.215715 (MainThread): 23:21:34 | Done.
2020-06-03 13:21:34.215880 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff888ba9a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff888e2df10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff888e2d5e0>]}
2020-06-03 13:21:34.216046 (MainThread): Flushing usage events
2020-06-03 13:21:36.242719 (MainThread): Running with dbt=0.16.1
2020-06-03 13:21:36.628020 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-06-03 13:21:36.628938 (MainThread): Tracking: tracking
2020-06-03 13:21:36.636298 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f3f7956a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f3f7a7790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f3f7a7760>]}
2020-06-03 13:21:36.658050 (MainThread): Partial parsing not enabled
2020-06-03 13:21:36.660026 (MainThread): Parsing macros/core.sql
2020-06-03 13:21:36.665370 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:21:36.674087 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:21:36.676015 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:21:36.694135 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:21:36.728503 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:21:36.749017 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:21:36.750863 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:21:36.756660 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:21:36.769133 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:21:36.775617 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:21:36.781625 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:21:36.786564 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:21:36.787508 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:21:36.788666 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:21:36.790228 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:21:36.792190 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:21:36.801004 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:21:36.802985 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:21:36.804009 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:21:36.845364 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:21:36.846549 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:21:36.847482 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:21:36.848547 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:21:36.850910 (MainThread): Parsing macros/etc.sql
2020-06-03 13:21:36.851581 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:21:36.859003 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:21:36.880099 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:21:36.882049 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:21:36.883487 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:21:36.892893 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:21:36.905192 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:21:36.924490 (MainThread): Partial parsing not enabled
2020-06-03 13:21:36.924904 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:21:36.955275 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:21:36.955395 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:21:36.970023 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:21:36.970134 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:36.975851 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:21:36.975946 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:36.981878 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:21:36.981979 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:37.012009 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:21:37.012129 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:37.020366 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:21:37.020473 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:37.204622 (MainThread): WARNING: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_servian_demo.medicare_provider_2011_analysis_bq

2020-06-03 13:21:37.251812 (MainThread): Found 4 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:21:37.255230 (MainThread): 
2020-06-03 13:21:37.255516 (MainThread): Acquiring new bigquery connection "master".
2020-06-03 13:21:37.255596 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:37.267951 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:21:38.801655 (MainThread): Skipping catalog for graham-hamza-bq-dbt-webinar.medicare_provider_2011_analysis_dbt - schema does not exist
2020-06-03 13:21:38.802665 (MainThread): 23:21:38 | Concurrency: 1 threads (target='dev')
2020-06-03 13:21:38.802870 (MainThread): 23:21:38 | 
2020-06-03 13:21:38.806812 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:21:38.807011 (Thread-1): 23:21:38 | 1 of 2 START test not_null_provider_inpatient_charges_2011_inpatient_provider_id [RUN]
2020-06-03 13:21:38.807354 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:21:38.807461 (Thread-1): Opening a new connection, currently in state init
2020-06-03 13:21:38.807584 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:21:38.827991 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"
2020-06-03 13:21:38.828476 (Thread-1): finished collecting timing info
2020-06-03 13:21:38.829030 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:21:39.315582 (Thread-1): On test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
where inpatient_provider_id is null


2020-06-03 13:21:40.946376 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
where inpatient_provider_id is null


2020-06-03 13:21:40.946546 (Thread-1): 404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US

(job ID: dc54a542-11f7-4224-b30c-1a7525853d05)

                                                                                        -----Query Job SQL Follows-----                                                                                        

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */
   2:
   3:
   4:
   5:
   6:select count(*)
   7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
   8:where inpatient_provider_id is null
   9:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:21:40.946769 (Thread-1): finished collecting timing info
2020-06-03 13:21:40.947508 (Thread-1): Runtime Error in test not_null_provider_inpatient_charges_2011_inpatient_provider_id (models/medicare_provider_2011_analysis_dbt/schema.yml)
  404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US
  
  (job ID: dc54a542-11f7-4224-b30c-1a7525853d05)
  
                                                                                          -----Query Job SQL Follows-----                                                                                        
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */
     2:
     3:
     4:
     5:
     6:select count(*)
     7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
     8:where inpatient_provider_id is null
     9:
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US

(job ID: dc54a542-11f7-4224-b30c-1a7525853d05)

                                                                                        -----Query Job SQL Follows-----                                                                                        

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */
   2:
   3:
   4:
   5:
   6:select count(*)
   7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
   8:where inpatient_provider_id is null
   9:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 577, in execute
    failed_rows = self.execute_test(test)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 558, in execute_test
    res, table = self.adapter.execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 217, in execute
    return self.connections.execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 98, in exception_handler
    raise RuntimeException(str(e))
dbt.exceptions.RuntimeException: Runtime Error in test not_null_provider_inpatient_charges_2011_inpatient_provider_id (models/medicare_provider_2011_analysis_dbt/schema.yml)
  404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US
  
  (job ID: dc54a542-11f7-4224-b30c-1a7525853d05)
  
                                                                                          -----Query Job SQL Follows-----                                                                                        
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */
     2:
     3:
     4:
     5:
     6:select count(*)
     7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
     8:where inpatient_provider_id is null
     9:
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:21:40.957319 (Thread-1): 23:21:40 | 1 of 2 ERROR not_null_provider_inpatient_charges_2011_inpatient_provider_id [ERROR in 2.15s]
2020-06-03 13:21:40.957529 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:21:40.957766 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:21:40.958221 (Thread-1): 23:21:40 | 2 of 2 START test not_null_provider_outpatient_charges_2011_outpatient_provider_id [RUN]
2020-06-03 13:21:40.958576 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:21:40.958677 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id).
2020-06-03 13:21:40.958784 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:21:40.968709 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"
2020-06-03 13:21:40.969203 (Thread-1): finished collecting timing info
2020-06-03 13:21:40.969484 (Thread-1): On test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
where outpatient_provider_id is null


2020-06-03 13:21:41.484497 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
where outpatient_provider_id is null


2020-06-03 13:21:41.484728 (Thread-1): 404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US

(job ID: c8a64bdd-5e72-441d-b024-dd113155ebd0)

                                                                                         -----Query Job SQL Follows-----                                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */
   2:
   3:
   4:
   5:
   6:select count(*)
   7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
   8:where outpatient_provider_id is null
   9:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:21:41.484939 (Thread-1): finished collecting timing info
2020-06-03 13:21:41.485661 (Thread-1): Runtime Error in test not_null_provider_outpatient_charges_2011_outpatient_provider_id (models/medicare_provider_2011_analysis_dbt/schema.yml)
  404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US
  
  (job ID: c8a64bdd-5e72-441d-b024-dd113155ebd0)
  
                                                                                           -----Query Job SQL Follows-----                                                                                         
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */
     2:
     3:
     4:
     5:
     6:select count(*)
     7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
     8:where outpatient_provider_id is null
     9:
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US

(job ID: c8a64bdd-5e72-441d-b024-dd113155ebd0)

                                                                                         -----Query Job SQL Follows-----                                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */
   2:
   3:
   4:
   5:
   6:select count(*)
   7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
   8:where outpatient_provider_id is null
   9:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 577, in execute
    failed_rows = self.execute_test(test)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 558, in execute_test
    res, table = self.adapter.execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 217, in execute
    return self.connections.execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 98, in exception_handler
    raise RuntimeException(str(e))
dbt.exceptions.RuntimeException: Runtime Error in test not_null_provider_outpatient_charges_2011_outpatient_provider_id (models/medicare_provider_2011_analysis_dbt/schema.yml)
  404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US
  
  (job ID: c8a64bdd-5e72-441d-b024-dd113155ebd0)
  
                                                                                           -----Query Job SQL Follows-----                                                                                         
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */
     2:
     3:
     4:
     5:
     6:select count(*)
     7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
     8:where outpatient_provider_id is null
     9:
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:21:41.486394 (Thread-1): 23:21:41 | 2 of 2 ERROR not_null_provider_outpatient_charges_2011_outpatient_provider_id [ERROR in 0.53s]
2020-06-03 13:21:41.486567 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:21:41.488322 (MainThread): 23:21:41 | 
2020-06-03 13:21:41.488509 (MainThread): 23:21:41 | Finished running 2 tests in 4.23s.
2020-06-03 13:21:41.488656 (MainThread): Connection 'master' was left open.
2020-06-03 13:21:41.488765 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id' was left open.
2020-06-03 13:21:41.495005 (MainThread): 
2020-06-03 13:21:41.495152 (MainThread): Completed with 2 errors and 0 warnings:
2020-06-03 13:21:41.495278 (MainThread): 
2020-06-03 13:21:41.495396 (MainThread): Runtime Error in test not_null_provider_inpatient_charges_2011_inpatient_provider_id (models/medicare_provider_2011_analysis_dbt/schema.yml)
2020-06-03 13:21:41.495501 (MainThread):   404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US
2020-06-03 13:21:41.495597 (MainThread):   
2020-06-03 13:21:41.495688 (MainThread):   (job ID: dc54a542-11f7-4224-b30c-1a7525853d05)
2020-06-03 13:21:41.495781 (MainThread):   
2020-06-03 13:21:41.495872 (MainThread):                                                                                           -----Query Job SQL Follows-----                                                                                        
2020-06-03 13:21:41.495964 (MainThread):   
2020-06-03 13:21:41.496053 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:21:41.496143 (MainThread):      1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */
2020-06-03 13:21:41.496232 (MainThread):      2:
2020-06-03 13:21:41.496320 (MainThread):      3:
2020-06-03 13:21:41.496408 (MainThread):      4:
2020-06-03 13:21:41.496496 (MainThread):      5:
2020-06-03 13:21:41.496586 (MainThread):      6:select count(*)
2020-06-03 13:21:41.496676 (MainThread):      7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
2020-06-03 13:21:41.496766 (MainThread):      8:where inpatient_provider_id is null
2020-06-03 13:21:41.496854 (MainThread):      9:
2020-06-03 13:21:41.496943 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:21:41.497043 (MainThread): 
2020-06-03 13:21:41.497149 (MainThread): Runtime Error in test not_null_provider_outpatient_charges_2011_outpatient_provider_id (models/medicare_provider_2011_analysis_dbt/schema.yml)
2020-06-03 13:21:41.497244 (MainThread):   404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US
2020-06-03 13:21:41.497337 (MainThread):   
2020-06-03 13:21:41.497427 (MainThread):   (job ID: c8a64bdd-5e72-441d-b024-dd113155ebd0)
2020-06-03 13:21:41.497516 (MainThread):   
2020-06-03 13:21:41.497649 (MainThread):                                                                                            -----Query Job SQL Follows-----                                                                                         
2020-06-03 13:21:41.497791 (MainThread):   
2020-06-03 13:21:41.497899 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:21:41.497999 (MainThread):      1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */
2020-06-03 13:21:41.498094 (MainThread):      2:
2020-06-03 13:21:41.498185 (MainThread):      3:
2020-06-03 13:21:41.498275 (MainThread):      4:
2020-06-03 13:21:41.498365 (MainThread):      5:
2020-06-03 13:21:41.498453 (MainThread):      6:select count(*)
2020-06-03 13:21:41.498542 (MainThread):      7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
2020-06-03 13:21:41.498630 (MainThread):      8:where outpatient_provider_id is null
2020-06-03 13:21:41.498719 (MainThread):      9:
2020-06-03 13:21:41.498807 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:21:41.498908 (MainThread): 
Done. PASS=0 WARN=0 ERROR=2 SKIP=0 TOTAL=2
2020-06-03 13:21:41.499135 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f4026ee80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f4014cdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f4014c9a0>]}
2020-06-03 13:21:41.499384 (MainThread): Flushing usage events
2020-06-03 13:21:43.425694 (MainThread): Running with dbt=0.16.1
2020-06-03 13:21:43.845002 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-06-03 13:21:43.845823 (MainThread): Tracking: tracking
2020-06-03 13:21:43.851765 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb30f697af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb30f6a7700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb30f6a76d0>]}
2020-06-03 13:21:43.873087 (MainThread): Partial parsing not enabled
2020-06-03 13:21:43.875015 (MainThread): Parsing macros/core.sql
2020-06-03 13:21:43.880116 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:21:43.888735 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:21:43.890669 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:21:43.907668 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:21:43.941794 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:21:43.962523 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:21:43.964344 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:21:43.970154 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:21:43.984422 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:21:43.991093 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:21:43.997230 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:21:44.001915 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:21:44.002831 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:21:44.003866 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:21:44.005429 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:21:44.007393 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:21:44.016119 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:21:44.018025 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:21:44.019031 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:21:44.060314 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:21:44.061472 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:21:44.062353 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:21:44.063393 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:21:44.065606 (MainThread): Parsing macros/etc.sql
2020-06-03 13:21:44.066235 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:21:44.073986 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:21:44.095525 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:21:44.097459 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:21:44.098843 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:21:44.108288 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:21:44.120561 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:21:44.139188 (MainThread): Partial parsing not enabled
2020-06-03 13:21:44.139543 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:21:44.169809 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:21:44.169934 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:21:44.184844 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:21:44.184992 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:44.190947 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:21:44.191062 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:44.196986 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:21:44.197075 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:44.226867 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:21:44.226987 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:44.235064 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:21:44.235151 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:44.419283 (MainThread): WARNING: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_servian_demo.medicare_provider_2011_analysis_bq

2020-06-03 13:21:44.466651 (MainThread): Found 4 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:21:44.470178 (MainThread): 
2020-06-03 13:21:44.470462 (MainThread): Acquiring new bigquery connection "master".
2020-06-03 13:21:44.470545 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:21:44.476961 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-06-03 13:21:44.477078 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-03 13:21:44.477911 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:21:45.900442 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt".
2020-06-03 13:21:45.900784 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-06-03 13:21:45.900949 (ThreadPoolExecutor-0_0): Creating schema "graham-hamza-bq-dbt-webinar.medicare_provider_2011_analysis_dbt".
2020-06-03 13:21:45.901191 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:21:46.776978 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:21:48.946133 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt".
2020-06-03 13:21:48.946494 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly create_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt).
2020-06-03 13:21:48.946719 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:21:49.430036 (MainThread): 23:21:49 | Concurrency: 1 threads (target='dev')
2020-06-03 13:21:49.430300 (MainThread): 23:21:49 | 
2020-06-03 13:21:49.434693 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:21:49.434907 (Thread-1): 23:21:49 | 1 of 4 START view model medicare_provider_2011_analysis_dbt.provider_inpatient_charges_2011 [RUN]
2020-06-03 13:21:49.435230 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:21:49.435339 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt).
2020-06-03 13:21:49.435469 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:21:49.456599 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:21:49.457091 (Thread-1): finished collecting timing info
2020-06-03 13:21:49.574835 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:21:49.576032 (Thread-1): On model.dbt_servian_demo.provider_inpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.provider_inpatient_charges_2011"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
  OPTIONS()
  as (
    SELECT
  provider_id as inpatient_provider_id,
  provider_name as inpatient_provider_name,
  provider_city as inpatient_provider_city,
  provider_state as inpatient_provider_state,
  ROUND(SUM(total_discharges),2) as inpatient_sum_total_discharges,
  ROUND(SUM(average_covered_charges),2) as inpatient_sum_average_covered_charges,
  ROUND(SUM(average_total_payments),2) as inpatient_sum_average_total_payments,
  ROUND(SUM(average_medicare_payments),2) as inpatient_average_medicare_payments
FROM
  `bigquery-public-data`.`medicare`.`inpatient_charges_2011`
GROUP BY
  1,
  2,
  3,
  4
  );

2020-06-03 13:21:51.493266 (Thread-1): finished collecting timing info
2020-06-03 13:21:51.494196 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3f31a84a-92c2-45fa-aa35-27d5cd836648', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb310288c70>]}
2020-06-03 13:21:51.494581 (Thread-1): 23:21:51 | 1 of 4 OK created view model medicare_provider_2011_analysis_dbt.provider_inpatient_charges_2011 [CREATE VIEW in 2.06s]
2020-06-03 13:21:51.494773 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:21:51.494922 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:21:51.495065 (Thread-1): 23:21:51 | 2 of 4 START view model medicare_provider_2011_analysis_dbt.provider_outpatient_charges_2011 [RUN]
2020-06-03 13:21:51.495470 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:21:51.495587 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.provider_inpatient_charges_2011).
2020-06-03 13:21:51.495690 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:21:51.504204 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:21:51.504645 (Thread-1): finished collecting timing info
2020-06-03 13:21:51.509469 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:21:51.509879 (Thread-1): On model.dbt_servian_demo.provider_outpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.provider_outpatient_charges_2011"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
  OPTIONS()
  as (
    SELECT
  provider_id as outpatient_provider_id,
  provider_name as outpatient_provider_name,
  provider_city as outpatient_provider_city,
  provider_state as outpatient_provider_state,
  ROUND(SUM(outpatient_services),2) as outpatient_sum_outpatient_services,
  ROUND(SUM(average_estimated_submitted_charges),2) as outpatient_sum_average_estimated_submitted_charges,
  ROUND(SUM(average_total_payments),2) as outpatient_sum_average_total_payments
FROM
  `bigquery-public-data`.`medicare`.`outpatient_charges_2011`
GROUP BY
  1,
  2,
  3,
  4
  );

2020-06-03 13:21:53.327521 (Thread-1): finished collecting timing info
2020-06-03 13:21:53.328396 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3f31a84a-92c2-45fa-aa35-27d5cd836648', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb31029cbb0>]}
2020-06-03 13:21:53.328733 (Thread-1): 23:21:53 | 2 of 4 OK created view model medicare_provider_2011_analysis_dbt.provider_outpatient_charges_2011 [CREATE VIEW in 1.83s]
2020-06-03 13:21:53.328913 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:21:53.329196 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:21:53.329383 (Thread-1): 23:21:53 | 3 of 4 START view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_analysis [RUN]
2020-06-03 13:21:53.329900 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:21:53.330022 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.provider_outpatient_charges_2011).
2020-06-03 13:21:53.330130 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:21:53.339553 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:21:53.339988 (Thread-1): finished collecting timing info
2020-06-03 13:21:53.344618 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:21:53.345036 (Thread-1): On model.dbt_servian_demo.physicians_supplier_2012_analysis: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.physicians_supplier_2012_analysis"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`physicians_supplier_2012_analysis`
  OPTIONS()
  as (
     


SELECT
  nppes_provider_city,
 	
 		ROUND(SUM(line_srvc_cnt)) as sum_line_srvc_cnt,
	
 		ROUND(SUM(bene_unique_cnt)) as sum_bene_unique_cnt,
	
 		ROUND(SUM(bene_day_srvc_cnt)) as sum_bene_day_srvc_cnt,
	
 		ROUND(SUM(average_medicare_allowed_amt)) as sum_average_medicare_allowed_amt,
	
 		ROUND(SUM(stdev_medicare_allowed_amt)) as sum_stdev_medicare_allowed_amt,
	
 		ROUND(SUM(average_submitted_chrg_amt)) as sum_average_submitted_chrg_amt,
	
 		ROUND(SUM(stdev_submitted_chrg_amt)) as sum_stdev_submitted_chrg_amt,
	
 		ROUND(SUM(average_medicare_payment_amt)) as sum_average_medicare_payment_amt,
	
 		ROUND(SUM(stdev_medicare_payment_amt)) as sum_stdev_medicare_payment_amt,
	
FROM
  `bigquery-public-data`.`medicare`.`physicians_and_other_supplier_2012`
GROUP BY
  1
  );

2020-06-03 13:21:55.300721 (Thread-1): finished collecting timing info
2020-06-03 13:21:55.301622 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3f31a84a-92c2-45fa-aa35-27d5cd836648', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3100e25b0>]}
2020-06-03 13:21:55.301972 (Thread-1): 23:21:55 | 3 of 4 OK created view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_analysis [CREATE VIEW in 1.97s]
2020-06-03 13:21:55.302126 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:21:55.302280 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:21:55.302431 (Thread-1): 23:21:55 | 4 of 4 START view model medicare_provider_2011_analysis_dbt.outpatient_inpatient_charges_2011 [RUN]
2020-06-03 13:21:55.302824 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:21:55.302944 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.physicians_supplier_2012_analysis).
2020-06-03 13:21:55.303051 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:21:55.311694 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:21:55.312124 (Thread-1): finished collecting timing info
2020-06-03 13:21:55.317638 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:21:55.318109 (Thread-1): On model.dbt_servian_demo.outpatient_inpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.outpatient_inpatient_charges_2011"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`outpatient_inpatient_charges_2011`
  OPTIONS()
  as (
    SELECT
	*
FROM
 	`graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011` outpatient
JOIN
	`graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011` inpatient
ON
	outpatient_provider_id = inpatient_provider_id
  );

2020-06-03 13:21:57.615261 (Thread-1): finished collecting timing info
2020-06-03 13:21:57.616128 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3f31a84a-92c2-45fa-aa35-27d5cd836648', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3102f2430>]}
2020-06-03 13:21:57.616461 (Thread-1): 23:21:57 | 4 of 4 OK created view model medicare_provider_2011_analysis_dbt.outpatient_inpatient_charges_2011 [CREATE VIEW in 2.31s]
2020-06-03 13:21:57.616639 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:21:57.618143 (MainThread): 23:21:57 | 
2020-06-03 13:21:57.618298 (MainThread): 23:21:57 | Finished running 4 view models in 13.15s.
2020-06-03 13:21:57.618420 (MainThread): Connection 'master' was left open.
2020-06-03 13:21:57.618513 (MainThread): Connection 'model.dbt_servian_demo.outpatient_inpatient_charges_2011' was left open.
2020-06-03 13:21:57.630630 (MainThread): 
2020-06-03 13:21:57.630856 (MainThread): Completed successfully
2020-06-03 13:21:57.631011 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2020-06-03 13:21:57.631276 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb31025f070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb31025f760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb31025f4f0>]}
2020-06-03 13:21:57.631549 (MainThread): Flushing usage events
2020-06-03 13:21:59.886261 (MainThread): Running with dbt=0.16.1
2020-06-03 13:22:00.271845 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-06-03 13:22:00.272579 (MainThread): Tracking: tracking
2020-06-03 13:22:00.278021 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc674197e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6741a85b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6741a8580>]}
2020-06-03 13:22:00.278612 (MainThread): Checking target/*
2020-06-03 13:22:00.286855 (MainThread):  Cleaned target/*
2020-06-03 13:22:00.287021 (MainThread): Checking dbt_modules/*
2020-06-03 13:22:00.287412 (MainThread):  Cleaned dbt_modules/*
2020-06-03 13:22:00.287513 (MainThread): Finished cleaning all paths.
2020-06-03 13:22:00.287705 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc674197e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6741a8550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6741a8520>]}
2020-06-03 13:22:00.287902 (MainThread): Flushing usage events
2020-06-03 13:22:02.325495 (MainThread): Running with dbt=0.16.1
2020-06-03 13:22:02.701672 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2020-06-03 13:22:02.702286 (MainThread): Tracking: tracking
2020-06-03 13:22:02.707946 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a03f7afd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a03f8a6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a03f8a670>]}
2020-06-03 13:22:02.729731 (MainThread): Partial parsing not enabled
2020-06-03 13:22:02.731678 (MainThread): Parsing macros/core.sql
2020-06-03 13:22:02.736725 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:22:02.745801 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:22:02.748190 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:22:02.766183 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:22:02.800923 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:22:02.821459 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:22:02.823312 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:22:02.829349 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:22:02.841851 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:22:02.848511 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:22:02.854609 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:22:02.859409 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:22:02.860352 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:22:02.861378 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:22:02.862930 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:22:02.864891 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:22:02.873796 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:22:02.875842 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:22:02.876868 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:22:02.919055 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:22:02.920215 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:22:02.921105 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:22:02.922167 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:22:02.924708 (MainThread): Parsing macros/etc.sql
2020-06-03 13:22:02.925424 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:22:02.933079 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:22:02.954912 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:22:02.957010 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:22:02.958447 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:22:02.968035 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:22:02.980432 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:22:03.026489 (MainThread): Partial parsing not enabled
2020-06-03 13:22:03.026922 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:22:03.060361 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:22:03.060491 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:22:03.075645 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:22:03.075761 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:22:03.081487 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:22:03.081584 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:22:03.087567 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:22:03.087668 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:22:03.118665 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:22:03.119264 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:22:03.128097 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:22:03.128215 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:22:03.307854 (MainThread): WARNING: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_servian_demo.medicare_provider_2011_analysis_bq

2020-06-03 13:22:03.353987 (MainThread): Found 4 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:22:03.357460 (MainThread): 
2020-06-03 13:22:03.357614 (MainThread): 23:22:03 | Concurrency: 1 threads (target='dev')
2020-06-03 13:22:03.357705 (MainThread): 23:22:03 | 
2020-06-03 13:22:03.360010 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:22:03.360309 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:22:03.360395 (Thread-1): Opening a new connection, currently in state init
2020-06-03 13:22:03.360475 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:22:03.376036 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:22:03.376567 (Thread-1): finished collecting timing info
2020-06-03 13:22:03.376789 (Thread-1): finished collecting timing info
2020-06-03 13:22:03.377160 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:22:03.377319 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:22:03.377541 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:22:03.377623 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:22:03.377702 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:22:03.383995 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:22:03.384297 (Thread-1): finished collecting timing info
2020-06-03 13:22:03.384504 (Thread-1): finished collecting timing info
2020-06-03 13:22:03.384816 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:22:03.384928 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:22:03.385299 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:22:03.385387 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:22:03.385466 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:22:03.393497 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:22:03.394138 (Thread-1): finished collecting timing info
2020-06-03 13:22:03.394402 (Thread-1): finished collecting timing info
2020-06-03 13:22:03.394809 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:22:03.394960 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:22:03.395204 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:22:03.395290 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:22:03.395377 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:22:03.408799 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"
2020-06-03 13:22:03.409309 (Thread-1): finished collecting timing info
2020-06-03 13:22:03.409543 (Thread-1): finished collecting timing info
2020-06-03 13:22:03.409968 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:22:03.410096 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:22:03.410422 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:22:03.410518 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:22:03.410603 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:22:03.417702 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:22:03.418058 (Thread-1): finished collecting timing info
2020-06-03 13:22:03.418281 (Thread-1): finished collecting timing info
2020-06-03 13:22:03.418622 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:22:03.418743 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:22:03.418963 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:22:03.419048 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:22:03.419130 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:22:03.426531 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"
2020-06-03 13:22:03.426884 (Thread-1): finished collecting timing info
2020-06-03 13:22:03.427103 (Thread-1): finished collecting timing info
2020-06-03 13:22:03.427442 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:22:03.428159 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id' was properly closed.
2020-06-03 13:22:03.428256 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id' was properly closed.
2020-06-03 13:22:03.440311 (MainThread): 23:22:03 | Done.
2020-06-03 13:22:03.443045 (MainThread): Acquiring new bigquery connection "generate_catalog".
2020-06-03 13:22:03.443185 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:22:03.443276 (MainThread): 23:22:03 | Building catalog
2020-06-03 13:22:03.459606 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:22:06.766168 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "graham-hamza-bq-dbt-webinar.information_schema".
2020-06-03 13:22:06.766569 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-03 13:22:06.844595 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:22:07.324019 (ThreadPoolExecutor-0_0): On graham-hamza-bq-dbt-webinar.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "graham-hamza-bq-dbt-webinar.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `graham-hamza-bq-dbt-webinar`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('medicare_provider_2011_analysis_dbt'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-03 13:22:12.414678 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "bigquery-public-data.information_schema".
2020-06-03 13:22:12.414896 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly graham-hamza-bq-dbt-webinar.information_schema).
2020-06-03 13:22:12.417436 (ThreadPoolExecutor-0_0): On bigquery-public-data.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "bigquery-public-data.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `bigquery-public-data`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('medicare'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bigquery-public-data`.`medicare`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `bigquery-public-data`.`medicare`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `bigquery-public-data`.`medicare`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-03 13:22:13.141594 (ThreadPoolExecutor-0_0): Unhandled error while running:
macro get_catalog
2020-06-03 13:22:13.141820 (ThreadPoolExecutor-0_0): Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-03 13:22:13.142368 (MainThread): Encountered an error while generating catalog: Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-03 13:22:13.230517 (MainThread): dbt encountered 1 failure while writing the catalog
2020-06-03 13:22:13.230763 (MainThread): 23:22:13 | Catalog written to /Users/hamzakhan/Desktop/Work/Servian/dbt-demo/dbt-demo-servian/target/catalog.json
2020-06-03 13:22:13.230968 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a04b12a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a04b12eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a04b12fa0>]}
2020-06-03 13:22:13.231181 (MainThread): Flushing usage events
2020-06-03 13:22:14.234706 (MainThread): Connection 'generate_catalog' was left open.
2020-06-03 13:22:14.234895 (MainThread): Connection 'bigquery-public-data.information_schema' was left open.
2020-06-03 13:22:15.255962 (MainThread): Running with dbt=0.16.1
2020-06-03 13:22:15.633457 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, port=8001, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='serve', write_json=True)
2020-06-03 13:22:15.634272 (MainThread): Tracking: tracking
2020-06-03 13:22:15.640938 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8685898eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86858a7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86858a75e0>]}
2020-06-03 13:22:15.642660 (MainThread): Serving docs at 0.0.0.0:8001
2020-06-03 13:22:15.642819 (MainThread): To access from your browser, navigate to:  http://localhost:8001
2020-06-03 13:22:15.642906 (MainThread): Press Ctrl+C to exit.


2020-06-03 13:24:02.831167 (MainThread): Flushing usage events
2020-06-03 13:24:03.749629 (MainThread): ctrl-c
2020-06-03 13:24:27.018375 (MainThread): Running with dbt=0.16.1
2020-06-03 13:24:27.378697 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-06-03 13:24:27.380138 (MainThread): Tracking: tracking
2020-06-03 13:24:27.385991 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99918746d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99918867c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9991886790>]}
2020-06-03 13:24:27.406826 (MainThread): Partial parsing not enabled
2020-06-03 13:24:27.408506 (MainThread): Parsing macros/core.sql
2020-06-03 13:24:27.412799 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:24:27.420646 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:24:27.422320 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:24:27.438121 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:24:27.471299 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:24:27.491131 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:24:27.492893 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:24:27.498545 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:24:27.511562 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:24:27.517919 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:24:27.523667 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:24:27.528166 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:24:27.529087 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:24:27.530073 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:24:27.531581 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:24:27.533484 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:24:27.542091 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:24:27.543927 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:24:27.544904 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:24:27.586663 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:24:27.587768 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:24:27.588632 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:24:27.589653 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:24:27.591837 (MainThread): Parsing macros/etc.sql
2020-06-03 13:24:27.592458 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:24:27.599735 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:24:27.620159 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:24:27.622007 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:24:27.623373 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:24:27.632672 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:24:27.644601 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:24:27.662263 (MainThread): Partial parsing not enabled
2020-06-03 13:24:27.662586 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:24:27.692909 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:24:27.693038 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:24:27.708269 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:24:27.708377 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:27.713877 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:24:27.713966 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:27.719705 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:24:27.719787 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:27.749207 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:24:27.749319 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:27.757286 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:24:27.757381 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:27.986141 (MainThread): Found 4 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:24:27.989645 (MainThread): 
2020-06-03 13:24:27.989785 (MainThread): 23:24:27 | Concurrency: 1 threads (target='dev')
2020-06-03 13:24:27.989879 (MainThread): 23:24:27 | 
2020-06-03 13:24:27.992308 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:24:27.992604 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:24:27.992691 (Thread-1): Opening a new connection, currently in state init
2020-06-03 13:24:27.992773 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:24:28.007375 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:24:28.007727 (Thread-1): finished collecting timing info
2020-06-03 13:24:28.007942 (Thread-1): finished collecting timing info
2020-06-03 13:24:28.008265 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:24:28.008375 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:24:28.008574 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:24:28.008651 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:24:28.008725 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:24:28.014674 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:24:28.015095 (Thread-1): finished collecting timing info
2020-06-03 13:24:28.015294 (Thread-1): finished collecting timing info
2020-06-03 13:24:28.015593 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:24:28.015702 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:24:28.015900 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:24:28.016044 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:24:28.016222 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:24:28.023210 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:24:28.023607 (Thread-1): finished collecting timing info
2020-06-03 13:24:28.023815 (Thread-1): finished collecting timing info
2020-06-03 13:24:28.024152 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:24:28.024268 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:24:28.024557 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:24:28.024644 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:24:28.024721 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:24:28.036575 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"
2020-06-03 13:24:28.036961 (Thread-1): finished collecting timing info
2020-06-03 13:24:28.037170 (Thread-1): finished collecting timing info
2020-06-03 13:24:28.037503 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:24:28.037620 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:24:28.037835 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:24:28.037912 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:24:28.037988 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:24:28.044998 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:24:28.045329 (Thread-1): finished collecting timing info
2020-06-03 13:24:28.045547 (Thread-1): finished collecting timing info
2020-06-03 13:24:28.045886 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:24:28.046006 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:24:28.046225 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:24:28.046310 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:24:28.046390 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:24:28.053618 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"
2020-06-03 13:24:28.053925 (Thread-1): finished collecting timing info
2020-06-03 13:24:28.054133 (Thread-1): finished collecting timing info
2020-06-03 13:24:28.054465 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:24:28.055114 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id' was properly closed.
2020-06-03 13:24:28.055208 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id' was properly closed.
2020-06-03 13:24:28.067115 (MainThread): 23:24:28 | Done.
2020-06-03 13:24:28.067286 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f999189d640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9991a54e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9991a54fd0>]}
2020-06-03 13:24:28.067461 (MainThread): Flushing usage events
2020-06-03 13:24:30.076231 (MainThread): Running with dbt=0.16.1
2020-06-03 13:24:30.441961 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-06-03 13:24:30.442905 (MainThread): Tracking: tracking
2020-06-03 13:24:30.448397 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd774e99fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd774ea8670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd774ea8640>]}
2020-06-03 13:24:30.468108 (MainThread): Partial parsing not enabled
2020-06-03 13:24:30.469839 (MainThread): Parsing macros/core.sql
2020-06-03 13:24:30.474128 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:24:30.481623 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:24:30.483379 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:24:30.499601 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:24:30.532319 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:24:30.552059 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:24:30.553814 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:24:30.559471 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:24:30.571563 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:24:30.578060 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:24:30.583918 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:24:30.588607 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:24:30.589488 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:24:30.590555 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:24:30.592058 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:24:30.593956 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:24:30.602288 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:24:30.604118 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:24:30.605100 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:24:30.645309 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:24:30.646410 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:24:30.647263 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:24:30.648274 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:24:30.650421 (MainThread): Parsing macros/etc.sql
2020-06-03 13:24:30.651040 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:24:30.658493 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:24:30.678701 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:24:30.680527 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:24:30.681909 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:24:30.691072 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:24:30.703231 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:24:30.722168 (MainThread): Partial parsing not enabled
2020-06-03 13:24:30.722503 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:24:30.752418 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:24:30.752544 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:24:30.766807 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:24:30.766910 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:30.772392 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:24:30.772481 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:30.778332 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:24:30.778417 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:30.808007 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:24:30.808117 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:30.816046 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:24:30.816135 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:31.043899 (MainThread): Found 4 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:24:31.047218 (MainThread): 
2020-06-03 13:24:31.047474 (MainThread): Acquiring new bigquery connection "master".
2020-06-03 13:24:31.047551 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:31.057359 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:24:32.394815 (MainThread): Skipping catalog for graham-hamza-bq-dbt-webinar.medicare_provider_2011_analysis_dbt - schema does not exist
2020-06-03 13:24:32.395654 (MainThread): 23:24:32 | Concurrency: 1 threads (target='dev')
2020-06-03 13:24:32.395832 (MainThread): 23:24:32 | 
2020-06-03 13:24:32.399455 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:24:32.399671 (Thread-1): 23:24:32 | 1 of 2 START test not_null_provider_inpatient_charges_2011_inpatient_provider_id [RUN]
2020-06-03 13:24:32.400038 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:24:32.400150 (Thread-1): Opening a new connection, currently in state init
2020-06-03 13:24:32.400277 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:24:32.420490 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"
2020-06-03 13:24:32.420953 (Thread-1): finished collecting timing info
2020-06-03 13:24:32.421499 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:24:32.900154 (Thread-1): On test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
where inpatient_provider_id is null


2020-06-03 13:24:33.942861 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
where inpatient_provider_id is null


2020-06-03 13:24:33.943119 (Thread-1): 404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US

(job ID: 2eafadda-d6b8-4d99-b612-7e0d1fecdc49)

                                                                                        -----Query Job SQL Follows-----                                                                                        

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */
   2:
   3:
   4:
   5:
   6:select count(*)
   7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
   8:where inpatient_provider_id is null
   9:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:24:33.943437 (Thread-1): finished collecting timing info
2020-06-03 13:24:33.944547 (Thread-1): Runtime Error in test not_null_provider_inpatient_charges_2011_inpatient_provider_id (models/medicare_provider_2011_analysis_dbt/schema.yml)
  404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US
  
  (job ID: 2eafadda-d6b8-4d99-b612-7e0d1fecdc49)
  
                                                                                          -----Query Job SQL Follows-----                                                                                        
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */
     2:
     3:
     4:
     5:
     6:select count(*)
     7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
     8:where inpatient_provider_id is null
     9:
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US

(job ID: 2eafadda-d6b8-4d99-b612-7e0d1fecdc49)

                                                                                        -----Query Job SQL Follows-----                                                                                        

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */
   2:
   3:
   4:
   5:
   6:select count(*)
   7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
   8:where inpatient_provider_id is null
   9:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 577, in execute
    failed_rows = self.execute_test(test)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 558, in execute_test
    res, table = self.adapter.execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 217, in execute
    return self.connections.execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 98, in exception_handler
    raise RuntimeException(str(e))
dbt.exceptions.RuntimeException: Runtime Error in test not_null_provider_inpatient_charges_2011_inpatient_provider_id (models/medicare_provider_2011_analysis_dbt/schema.yml)
  404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US
  
  (job ID: 2eafadda-d6b8-4d99-b612-7e0d1fecdc49)
  
                                                                                          -----Query Job SQL Follows-----                                                                                        
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */
     2:
     3:
     4:
     5:
     6:select count(*)
     7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
     8:where inpatient_provider_id is null
     9:
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:24:33.955406 (Thread-1): 23:24:33 | 1 of 2 ERROR not_null_provider_inpatient_charges_2011_inpatient_provider_id [ERROR in 1.56s]
2020-06-03 13:24:33.955665 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:24:33.955917 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:24:33.956110 (Thread-1): 23:24:33 | 2 of 2 START test not_null_provider_outpatient_charges_2011_outpatient_provider_id [RUN]
2020-06-03 13:24:33.956845 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:24:33.956996 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id).
2020-06-03 13:24:33.957139 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:24:33.967559 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"
2020-06-03 13:24:33.967969 (Thread-1): finished collecting timing info
2020-06-03 13:24:33.968246 (Thread-1): On test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
where outpatient_provider_id is null


2020-06-03 13:24:34.589736 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
where outpatient_provider_id is null


2020-06-03 13:24:34.589973 (Thread-1): 404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US

(job ID: 6456bdd7-3b2c-43f1-ae9c-858c8adbe3c4)

                                                                                         -----Query Job SQL Follows-----                                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */
   2:
   3:
   4:
   5:
   6:select count(*)
   7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
   8:where outpatient_provider_id is null
   9:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:24:34.590194 (Thread-1): finished collecting timing info
2020-06-03 13:24:34.590930 (Thread-1): Runtime Error in test not_null_provider_outpatient_charges_2011_outpatient_provider_id (models/medicare_provider_2011_analysis_dbt/schema.yml)
  404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US
  
  (job ID: 6456bdd7-3b2c-43f1-ae9c-858c8adbe3c4)
  
                                                                                           -----Query Job SQL Follows-----                                                                                         
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */
     2:
     3:
     4:
     5:
     6:select count(*)
     7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
     8:where outpatient_provider_id is null
     9:
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US

(job ID: 6456bdd7-3b2c-43f1-ae9c-858c8adbe3c4)

                                                                                         -----Query Job SQL Follows-----                                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */
   2:
   3:
   4:
   5:
   6:select count(*)
   7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
   8:where outpatient_provider_id is null
   9:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 577, in execute
    failed_rows = self.execute_test(test)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/node_runners.py", line 558, in execute_test
    res, table = self.adapter.execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 217, in execute
    return self.connections.execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in _retry_and_handle
    return retry.retry_target(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 98, in exception_handler
    raise RuntimeException(str(e))
dbt.exceptions.RuntimeException: Runtime Error in test not_null_provider_outpatient_charges_2011_outpatient_provider_id (models/medicare_provider_2011_analysis_dbt/schema.yml)
  404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US
  
  (job ID: 6456bdd7-3b2c-43f1-ae9c-858c8adbe3c4)
  
                                                                                           -----Query Job SQL Follows-----                                                                                         
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */
     2:
     3:
     4:
     5:
     6:select count(*)
     7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
     8:where outpatient_provider_id is null
     9:
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:24:34.591912 (Thread-1): 23:24:34 | 2 of 2 ERROR not_null_provider_outpatient_charges_2011_outpatient_provider_id [ERROR in 0.64s]
2020-06-03 13:24:34.592100 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:24:34.593781 (MainThread): 23:24:34 | 
2020-06-03 13:24:34.593972 (MainThread): 23:24:34 | Finished running 2 tests in 3.55s.
2020-06-03 13:24:34.594123 (MainThread): Connection 'master' was left open.
2020-06-03 13:24:34.594238 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id' was left open.
2020-06-03 13:24:34.600348 (MainThread): 
2020-06-03 13:24:34.600499 (MainThread): Completed with 2 errors and 0 warnings:
2020-06-03 13:24:34.600624 (MainThread): 
2020-06-03 13:24:34.600744 (MainThread): Runtime Error in test not_null_provider_inpatient_charges_2011_inpatient_provider_id (models/medicare_provider_2011_analysis_dbt/schema.yml)
2020-06-03 13:24:34.600852 (MainThread):   404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US
2020-06-03 13:24:34.600950 (MainThread):   
2020-06-03 13:24:34.601046 (MainThread):   (job ID: 2eafadda-d6b8-4d99-b612-7e0d1fecdc49)
2020-06-03 13:24:34.601141 (MainThread):   
2020-06-03 13:24:34.601236 (MainThread):                                                                                           -----Query Job SQL Follows-----                                                                                        
2020-06-03 13:24:34.601333 (MainThread):   
2020-06-03 13:24:34.601427 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:24:34.601522 (MainThread):      1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */
2020-06-03 13:24:34.601617 (MainThread):      2:
2020-06-03 13:24:34.601710 (MainThread):      3:
2020-06-03 13:24:34.601804 (MainThread):      4:
2020-06-03 13:24:34.601897 (MainThread):      5:
2020-06-03 13:24:34.601989 (MainThread):      6:select count(*)
2020-06-03 13:24:34.602083 (MainThread):      7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
2020-06-03 13:24:34.602177 (MainThread):      8:where inpatient_provider_id is null
2020-06-03 13:24:34.602270 (MainThread):      9:
2020-06-03 13:24:34.602362 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:24:34.602463 (MainThread): 
2020-06-03 13:24:34.602574 (MainThread): Runtime Error in test not_null_provider_outpatient_charges_2011_outpatient_provider_id (models/medicare_provider_2011_analysis_dbt/schema.yml)
2020-06-03 13:24:34.602675 (MainThread):   404 Not found: Dataset graham-hamza-bq-dbt-webinar:medicare_provider_2011_analysis_dbt was not found in location US
2020-06-03 13:24:34.602769 (MainThread):   
2020-06-03 13:24:34.602863 (MainThread):   (job ID: 6456bdd7-3b2c-43f1-ae9c-858c8adbe3c4)
2020-06-03 13:24:34.602956 (MainThread):   
2020-06-03 13:24:34.603049 (MainThread):                                                                                            -----Query Job SQL Follows-----                                                                                         
2020-06-03 13:24:34.603148 (MainThread):   
2020-06-03 13:24:34.603240 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:24:34.603335 (MainThread):      1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */
2020-06-03 13:24:34.603431 (MainThread):      2:
2020-06-03 13:24:34.603525 (MainThread):      3:
2020-06-03 13:24:34.603617 (MainThread):      4:
2020-06-03 13:24:34.603710 (MainThread):      5:
2020-06-03 13:24:34.603802 (MainThread):      6:select count(*)
2020-06-03 13:24:34.603895 (MainThread):      7:from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
2020-06-03 13:24:34.603988 (MainThread):      8:where outpatient_provider_id is null
2020-06-03 13:24:34.604081 (MainThread):      9:
2020-06-03 13:24:34.604174 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-06-03 13:24:34.604278 (MainThread): 
Done. PASS=0 WARN=0 ERROR=2 SKIP=0 TOTAL=2
2020-06-03 13:24:34.604506 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77515c0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77514bcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77514bb20>]}
2020-06-03 13:24:34.604756 (MainThread): Flushing usage events
2020-06-03 13:24:36.592032 (MainThread): Running with dbt=0.16.1
2020-06-03 13:24:36.973883 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-06-03 13:24:36.974935 (MainThread): Tracking: tracking
2020-06-03 13:24:36.981261 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f4796ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f47a8700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f47a86d0>]}
2020-06-03 13:24:37.003364 (MainThread): Partial parsing not enabled
2020-06-03 13:24:37.005308 (MainThread): Parsing macros/core.sql
2020-06-03 13:24:37.010417 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:24:37.018816 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:24:37.020581 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:24:37.037151 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:24:37.071319 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:24:37.091899 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:24:37.093725 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:24:37.099578 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:24:37.111958 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:24:37.118550 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:24:37.124680 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:24:37.129346 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:24:37.130259 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:24:37.131279 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:24:37.132837 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:24:37.134802 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:24:37.143667 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:24:37.145634 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:24:37.146682 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:24:37.187446 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:24:37.188615 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:24:37.189484 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:24:37.190504 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:24:37.192950 (MainThread): Parsing macros/etc.sql
2020-06-03 13:24:37.193617 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:24:37.201628 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:24:37.222611 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:24:37.224470 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:24:37.225825 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:24:37.235301 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:24:37.247131 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:24:37.265318 (MainThread): Partial parsing not enabled
2020-06-03 13:24:37.265655 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:24:37.296728 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:24:37.296855 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:24:37.312021 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:24:37.312143 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:37.318158 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:24:37.318282 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:37.324332 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:24:37.324423 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:37.355439 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:24:37.355573 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:37.363899 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:24:37.364005 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:37.595650 (MainThread): Found 4 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:24:37.599098 (MainThread): 
2020-06-03 13:24:37.599359 (MainThread): Acquiring new bigquery connection "master".
2020-06-03 13:24:37.599438 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:24:37.605792 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-06-03 13:24:37.605892 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-03 13:24:37.606729 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:24:39.016698 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt".
2020-06-03 13:24:39.016972 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-06-03 13:24:39.017099 (ThreadPoolExecutor-0_0): Creating schema "graham-hamza-bq-dbt-webinar.medicare_provider_2011_analysis_dbt".
2020-06-03 13:24:39.017310 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:24:39.999559 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:24:41.350396 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt".
2020-06-03 13:24:41.350708 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly create_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt).
2020-06-03 13:24:41.350896 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:24:41.819251 (MainThread): 23:24:41 | Concurrency: 1 threads (target='dev')
2020-06-03 13:24:41.819506 (MainThread): 23:24:41 | 
2020-06-03 13:24:41.823377 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:24:41.823588 (Thread-1): 23:24:41 | 1 of 4 START table model medicare_provider_2011_analysis_dbt.provider_inpatient_charges_2011 [RUN]
2020-06-03 13:24:41.823940 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:24:41.824035 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt).
2020-06-03 13:24:41.824151 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:24:41.844208 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:24:41.844643 (Thread-1): finished collecting timing info
2020-06-03 13:24:41.966240 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:24:41.966863 (Thread-1): On model.dbt_servian_demo.provider_inpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.provider_inpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
  provider_id as inpatient_provider_id,
  provider_name as inpatient_provider_name,
  provider_city as inpatient_provider_city,
  provider_state as inpatient_provider_state,
  ROUND(SUM(total_discharges),2) as inpatient_sum_total_discharges,
  ROUND(SUM(average_covered_charges),2) as inpatient_sum_average_covered_charges,
  ROUND(SUM(average_total_payments),2) as inpatient_sum_average_total_payments,
  ROUND(SUM(average_medicare_payments),2) as inpatient_average_medicare_payments
FROM
  `bigquery-public-data`.`medicare`.`inpatient_charges_2011`
GROUP BY
  1,
  2,
  3,
  4
  );
    
2020-06-03 13:24:45.201917 (Thread-1): finished collecting timing info
2020-06-03 13:24:45.202881 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '08459589-3913-49b3-9060-705420297585', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f51b7af0>]}
2020-06-03 13:24:45.203251 (Thread-1): 23:24:45 | 1 of 4 OK created table model medicare_provider_2011_analysis_dbt.provider_inpatient_charges_2011 [CREATE TABLE (3337) in 3.38s]
2020-06-03 13:24:45.203405 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:24:45.203564 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:24:45.203833 (Thread-1): 23:24:45 | 2 of 4 START table model medicare_provider_2011_analysis_dbt.provider_outpatient_charges_2011 [RUN]
2020-06-03 13:24:45.204138 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:24:45.204239 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.provider_inpatient_charges_2011).
2020-06-03 13:24:45.204336 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:24:45.212708 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:24:45.213142 (Thread-1): finished collecting timing info
2020-06-03 13:24:45.218174 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:24:45.218566 (Thread-1): On model.dbt_servian_demo.provider_outpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.provider_outpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
  provider_id as outpatient_provider_id,
  provider_name as outpatient_provider_name,
  provider_city as outpatient_provider_city,
  provider_state as outpatient_provider_state,
  ROUND(SUM(outpatient_services),2) as outpatient_sum_outpatient_services,
  ROUND(SUM(average_estimated_submitted_charges),2) as outpatient_sum_average_estimated_submitted_charges,
  ROUND(SUM(average_total_payments),2) as outpatient_sum_average_total_payments
FROM
  `bigquery-public-data`.`medicare`.`outpatient_charges_2011`
GROUP BY
  1,
  2,
  3,
  4
  );
    
2020-06-03 13:24:49.431190 (Thread-1): finished collecting timing info
2020-06-03 13:24:49.432082 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '08459589-3913-49b3-9060-705420297585', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f5200df0>]}
2020-06-03 13:24:49.432403 (Thread-1): 23:24:49 | 2 of 4 OK created table model medicare_provider_2011_analysis_dbt.provider_outpatient_charges_2011 [CREATE TABLE (3135) in 4.23s]
2020-06-03 13:24:49.432577 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:24:49.432754 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:24:49.432926 (Thread-1): 23:24:49 | 3 of 4 START view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_analysis [RUN]
2020-06-03 13:24:49.433395 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:24:49.433522 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.provider_outpatient_charges_2011).
2020-06-03 13:24:49.433645 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:24:49.443374 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:24:49.443848 (Thread-1): finished collecting timing info
2020-06-03 13:24:49.461804 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:24:49.462274 (Thread-1): On model.dbt_servian_demo.physicians_supplier_2012_analysis: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.physicians_supplier_2012_analysis"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`physicians_supplier_2012_analysis`
  OPTIONS()
  as (
     


SELECT
  nppes_provider_city,
 	
 		ROUND(SUM(line_srvc_cnt)) as sum_line_srvc_cnt,
	
 		ROUND(SUM(bene_unique_cnt)) as sum_bene_unique_cnt,
	
 		ROUND(SUM(bene_day_srvc_cnt)) as sum_bene_day_srvc_cnt,
	
 		ROUND(SUM(average_medicare_allowed_amt)) as sum_average_medicare_allowed_amt,
	
 		ROUND(SUM(stdev_medicare_allowed_amt)) as sum_stdev_medicare_allowed_amt,
	
 		ROUND(SUM(average_submitted_chrg_amt)) as sum_average_submitted_chrg_amt,
	
 		ROUND(SUM(stdev_submitted_chrg_amt)) as sum_stdev_submitted_chrg_amt,
	
 		ROUND(SUM(average_medicare_payment_amt)) as sum_average_medicare_payment_amt,
	
 		ROUND(SUM(stdev_medicare_payment_amt)) as sum_stdev_medicare_payment_amt,
	
FROM
  `bigquery-public-data`.`medicare`.`physicians_and_other_supplier_2012`
GROUP BY
  1
  );

2020-06-03 13:24:51.313057 (Thread-1): finished collecting timing info
2020-06-03 13:24:51.313945 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '08459589-3913-49b3-9060-705420297585', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f51b7af0>]}
2020-06-03 13:24:51.314286 (Thread-1): 23:24:51 | 3 of 4 OK created view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_analysis [CREATE VIEW in 1.88s]
2020-06-03 13:24:51.314461 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:24:51.314643 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:24:51.314931 (Thread-1): 23:24:51 | 4 of 4 START table model medicare_provider_2011_analysis_dbt.outpatient_inpatient_charges_2011 [RUN]
2020-06-03 13:24:51.315284 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:24:51.315408 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.physicians_supplier_2012_analysis).
2020-06-03 13:24:51.315528 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:24:51.325460 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:24:51.325868 (Thread-1): finished collecting timing info
2020-06-03 13:24:51.330722 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:24:51.331138 (Thread-1): On model.dbt_servian_demo.outpatient_inpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.outpatient_inpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`outpatient_inpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
	*
FROM
 	`graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011` outpatient
JOIN
	`graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011` inpatient
ON
	outpatient_provider_id = inpatient_provider_id
  );
    
2020-06-03 13:24:54.885695 (Thread-1): finished collecting timing info
2020-06-03 13:24:54.886592 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '08459589-3913-49b3-9060-705420297585', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f5194b80>]}
2020-06-03 13:24:54.886923 (Thread-1): 23:24:54 | 4 of 4 OK created table model medicare_provider_2011_analysis_dbt.outpatient_inpatient_charges_2011 [CREATE TABLE (3135) in 3.57s]
2020-06-03 13:24:54.887104 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:24:54.888337 (MainThread): 23:24:54 | 
2020-06-03 13:24:54.888484 (MainThread): 23:24:54 | Finished running 3 table models, 1 view model in 17.29s.
2020-06-03 13:24:54.888605 (MainThread): Connection 'master' was left open.
2020-06-03 13:24:54.888696 (MainThread): Connection 'model.dbt_servian_demo.outpatient_inpatient_charges_2011' was left open.
2020-06-03 13:24:54.899675 (MainThread): 
2020-06-03 13:24:54.899833 (MainThread): Completed successfully
2020-06-03 13:24:54.899961 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2020-06-03 13:24:54.900166 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f5163610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f5163ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f5163f10>]}
2020-06-03 13:24:54.900364 (MainThread): Flushing usage events
2020-06-03 13:24:57.052926 (MainThread): Running with dbt=0.16.1
2020-06-03 13:24:57.418393 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-06-03 13:24:57.419129 (MainThread): Tracking: tracking
2020-06-03 13:24:57.424813 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdd098e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdd0a75e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdd0a75b0>]}
2020-06-03 13:24:57.425405 (MainThread): Checking target/*
2020-06-03 13:24:57.427591 (MainThread):  Cleaned target/*
2020-06-03 13:24:57.427750 (MainThread): Checking dbt_modules/*
2020-06-03 13:24:57.428147 (MainThread):  Cleaned dbt_modules/*
2020-06-03 13:24:57.428241 (MainThread): Finished cleaning all paths.
2020-06-03 13:24:57.428431 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdd098e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdd0a7580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdd0a7550>]}
2020-06-03 13:24:57.428612 (MainThread): Flushing usage events
2020-06-03 13:24:59.387773 (MainThread): Running with dbt=0.16.1
2020-06-03 13:24:59.748066 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2020-06-03 13:24:59.748830 (MainThread): Tracking: tracking
2020-06-03 13:24:59.754683 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9ded967f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9deda7790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9deda7760>]}
2020-06-03 13:24:59.775658 (MainThread): Partial parsing not enabled
2020-06-03 13:24:59.777358 (MainThread): Parsing macros/core.sql
2020-06-03 13:24:59.781676 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:24:59.789671 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:24:59.791385 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:24:59.807672 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:24:59.841758 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:24:59.861755 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:24:59.863546 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:24:59.869317 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:24:59.881507 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:24:59.887943 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:24:59.893863 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:24:59.898483 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:24:59.899420 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:24:59.900488 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:24:59.902082 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:24:59.904046 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:24:59.912615 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:24:59.914493 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:24:59.915494 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:24:59.955992 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:24:59.957107 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:24:59.957977 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:24:59.959012 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:24:59.961222 (MainThread): Parsing macros/etc.sql
2020-06-03 13:24:59.961854 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:24:59.969341 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:24:59.990427 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:24:59.992249 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:24:59.993681 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:25:00.002979 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:25:00.015073 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:25:00.033176 (MainThread): Partial parsing not enabled
2020-06-03 13:25:00.033506 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:25:00.062956 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:25:00.063079 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:25:00.077846 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:25:00.077954 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:25:00.083420 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:25:00.083505 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:25:00.089231 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:25:00.089312 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:25:00.118778 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:25:00.118883 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:25:00.126760 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:25:00.126856 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:25:00.355433 (MainThread): Found 4 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:25:00.358842 (MainThread): 
2020-06-03 13:25:00.358973 (MainThread): 23:25:00 | Concurrency: 1 threads (target='dev')
2020-06-03 13:25:00.359067 (MainThread): 23:25:00 | 
2020-06-03 13:25:00.361410 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:25:00.361700 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:25:00.361790 (Thread-1): Opening a new connection, currently in state init
2020-06-03 13:25:00.361874 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:25:00.376896 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:25:00.377433 (Thread-1): finished collecting timing info
2020-06-03 13:25:00.377667 (Thread-1): finished collecting timing info
2020-06-03 13:25:00.378007 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:25:00.378122 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:25:00.378325 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:25:00.378544 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:25:00.378639 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:25:00.385187 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:25:00.385539 (Thread-1): finished collecting timing info
2020-06-03 13:25:00.385749 (Thread-1): finished collecting timing info
2020-06-03 13:25:00.386072 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:25:00.386185 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:25:00.386388 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:25:00.386467 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:25:00.386543 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:25:00.394065 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:25:00.394598 (Thread-1): finished collecting timing info
2020-06-03 13:25:00.394813 (Thread-1): finished collecting timing info
2020-06-03 13:25:00.395158 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:25:00.395271 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:25:00.395483 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:25:00.395562 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:25:00.395743 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:25:00.408563 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"
2020-06-03 13:25:00.409023 (Thread-1): finished collecting timing info
2020-06-03 13:25:00.409247 (Thread-1): finished collecting timing info
2020-06-03 13:25:00.409589 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:25:00.409710 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:25:00.409928 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:25:00.410012 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:25:00.410093 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:25:00.417265 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:25:00.417638 (Thread-1): finished collecting timing info
2020-06-03 13:25:00.417853 (Thread-1): finished collecting timing info
2020-06-03 13:25:00.418218 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:25:00.418339 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:25:00.418565 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:25:00.418650 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:25:00.418732 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:25:00.426381 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"
2020-06-03 13:25:00.426753 (Thread-1): finished collecting timing info
2020-06-03 13:25:00.426984 (Thread-1): finished collecting timing info
2020-06-03 13:25:00.427330 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:25:00.428012 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id' was properly closed.
2020-06-03 13:25:00.428109 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id' was properly closed.
2020-06-03 13:25:00.441177 (MainThread): 23:25:00 | Done.
2020-06-03 13:25:00.443021 (MainThread): Acquiring new bigquery connection "generate_catalog".
2020-06-03 13:25:00.443168 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:25:00.443255 (MainThread): 23:25:00 | Building catalog
2020-06-03 13:25:00.459248 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:25:03.997084 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "graham-hamza-bq-dbt-webinar.information_schema".
2020-06-03 13:25:03.997469 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-03 13:25:04.069054 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:25:04.543214 (ThreadPoolExecutor-0_0): On graham-hamza-bq-dbt-webinar.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "graham-hamza-bq-dbt-webinar.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `graham-hamza-bq-dbt-webinar`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('medicare_provider_2011_analysis_dbt'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-03 13:25:09.205249 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "bigquery-public-data.information_schema".
2020-06-03 13:25:09.205462 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly graham-hamza-bq-dbt-webinar.information_schema).
2020-06-03 13:25:09.208041 (ThreadPoolExecutor-0_0): On bigquery-public-data.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "bigquery-public-data.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `bigquery-public-data`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('medicare'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bigquery-public-data`.`medicare`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `bigquery-public-data`.`medicare`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `bigquery-public-data`.`medicare`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-03 13:25:10.057678 (ThreadPoolExecutor-0_0): Unhandled error while running:
macro get_catalog
2020-06-03 13:25:10.057834 (ThreadPoolExecutor-0_0): Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-03 13:25:10.058228 (MainThread): Encountered an error while generating catalog: Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-03 13:25:10.142474 (MainThread): dbt encountered 1 failure while writing the catalog
2020-06-03 13:25:10.142709 (MainThread): 23:25:10 | Catalog written to /Users/hamzakhan/Desktop/Work/Servian/dbt-demo/dbt-demo-servian/target/catalog.json
2020-06-03 13:25:10.142907 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9def64610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9def642e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9dee57b80>]}
2020-06-03 13:25:10.143104 (MainThread): Flushing usage events
2020-06-03 13:25:11.073125 (MainThread): Connection 'generate_catalog' was left open.
2020-06-03 13:25:11.073292 (MainThread): Connection 'bigquery-public-data.information_schema' was left open.
2020-06-03 13:25:12.035985 (MainThread): Running with dbt=0.16.1
2020-06-03 13:25:12.430900 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, port=8001, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='serve', write_json=True)
2020-06-03 13:25:12.431706 (MainThread): Tracking: tracking
2020-06-03 13:25:12.438681 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca3bd97f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca3bda76a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca3bda7670>]}
2020-06-03 13:25:12.440409 (MainThread): Serving docs at 0.0.0.0:8001
2020-06-03 13:25:12.440569 (MainThread): To access from your browser, navigate to:  http://localhost:8001
2020-06-03 13:25:12.440655 (MainThread): Press Ctrl+C to exit.


2020-06-03 13:26:14.415163 (MainThread): Flushing usage events
2020-06-03 13:26:15.045175 (MainThread): ctrl-c
2020-06-03 13:26:15.045649 (MainThread): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.105', 52968), raddr=('52.0.42.206', 443)>
2020-06-03 13:26:24.305598 (MainThread): Running with dbt=0.16.1
2020-06-03 13:26:24.772505 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-06-03 13:26:24.773419 (MainThread): Tracking: tracking
2020-06-03 13:26:24.780506 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc01e9777f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc01e988790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc01e988760>]}
2020-06-03 13:26:24.819309 (MainThread): Partial parsing not enabled
2020-06-03 13:26:24.822244 (MainThread): Parsing macros/core.sql
2020-06-03 13:26:24.829199 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:26:24.838753 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:26:24.840726 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:26:24.860410 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:26:24.896577 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:26:24.920662 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:26:24.922768 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:26:24.929349 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:26:24.944941 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:26:24.952644 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:26:24.959989 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:26:24.965596 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:26:24.966755 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:26:24.968240 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:26:24.970316 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:26:24.973560 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:26:24.984568 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:26:24.987740 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:26:24.989048 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:26:25.041654 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:26:25.043379 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:26:25.044496 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:26:25.046189 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:26:25.049183 (MainThread): Parsing macros/etc.sql
2020-06-03 13:26:25.050002 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:26:25.059564 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:26:25.085973 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:26:25.088497 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:26:25.090384 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:26:25.102333 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:26:25.116662 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:26:25.140346 (MainThread): Partial parsing not enabled
2020-06-03 13:26:25.140768 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:26:25.182473 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:26:25.182623 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:26:25.204015 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:26:25.204244 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:25.212708 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:26:25.212896 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:25.221643 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:26:25.221788 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:25.261257 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:26:25.261406 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:25.271701 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:26:25.271847 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:25.537668 (MainThread): Found 4 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:26:25.542340 (MainThread): 
2020-06-03 13:26:25.542551 (MainThread): 23:26:25 | Concurrency: 1 threads (target='dev')
2020-06-03 13:26:25.542658 (MainThread): 23:26:25 | 
2020-06-03 13:26:25.545499 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:26:25.545858 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:26:25.545959 (Thread-1): Opening a new connection, currently in state init
2020-06-03 13:26:25.546094 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:26:25.563521 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:26:25.563953 (Thread-1): finished collecting timing info
2020-06-03 13:26:25.564217 (Thread-1): finished collecting timing info
2020-06-03 13:26:25.564604 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:26:25.564730 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:26:25.564956 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:26:25.565043 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:26:25.565127 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:26:25.572371 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:26:25.572977 (Thread-1): finished collecting timing info
2020-06-03 13:26:25.573255 (Thread-1): finished collecting timing info
2020-06-03 13:26:25.573782 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:26:25.573929 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:26:25.574179 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:26:25.574269 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:26:25.574357 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:26:25.583333 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:26:25.583963 (Thread-1): finished collecting timing info
2020-06-03 13:26:25.584299 (Thread-1): finished collecting timing info
2020-06-03 13:26:25.584715 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:26:25.584847 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:26:25.585191 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:26:25.585383 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:26:25.585496 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:26:25.599253 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"
2020-06-03 13:26:25.599691 (Thread-1): finished collecting timing info
2020-06-03 13:26:25.599924 (Thread-1): finished collecting timing info
2020-06-03 13:26:25.600291 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:26:25.600418 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:26:25.600649 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:26:25.600737 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:26:25.600825 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:26:25.608859 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:26:25.609341 (Thread-1): finished collecting timing info
2020-06-03 13:26:25.609701 (Thread-1): finished collecting timing info
2020-06-03 13:26:25.610157 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:26:25.610358 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:26:25.610770 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:26:25.611002 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:26:25.611155 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:26:25.620144 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"
2020-06-03 13:26:25.620586 (Thread-1): finished collecting timing info
2020-06-03 13:26:25.620830 (Thread-1): finished collecting timing info
2020-06-03 13:26:25.621210 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:26:25.621908 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id' was properly closed.
2020-06-03 13:26:25.622010 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id' was properly closed.
2020-06-03 13:26:25.635813 (MainThread): 23:26:25 | Done.
2020-06-03 13:26:25.636028 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc01ec2cac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc01e9771c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc01e9779d0>]}
2020-06-03 13:26:25.636226 (MainThread): Flushing usage events
2020-06-03 13:26:27.648091 (MainThread): Running with dbt=0.16.1
2020-06-03 13:26:28.064816 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-06-03 13:26:28.066300 (MainThread): Tracking: tracking
2020-06-03 13:26:28.072628 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62a197a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62a1a7700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62a1a76d0>]}
2020-06-03 13:26:28.096115 (MainThread): Partial parsing not enabled
2020-06-03 13:26:28.098854 (MainThread): Parsing macros/core.sql
2020-06-03 13:26:28.104060 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:26:28.113034 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:26:28.115057 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:26:28.134807 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:26:28.171720 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:26:28.192954 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:26:28.195185 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:26:28.201477 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:26:28.215172 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:26:28.222134 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:26:28.228988 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:26:28.234649 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:26:28.235784 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:26:28.236956 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:26:28.238718 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:26:28.240935 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:26:28.250670 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:26:28.252618 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:26:28.253654 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:26:28.295884 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:26:28.297074 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:26:28.297957 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:26:28.299028 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:26:28.301288 (MainThread): Parsing macros/etc.sql
2020-06-03 13:26:28.301945 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:26:28.309497 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:26:28.330833 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:26:28.332867 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:26:28.334411 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:26:28.344095 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:26:28.356399 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:26:28.375832 (MainThread): Partial parsing not enabled
2020-06-03 13:26:28.376209 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:26:28.407637 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:26:28.407775 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:26:28.423327 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:26:28.423448 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:28.429559 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:26:28.429690 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:28.436496 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:26:28.436629 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:28.471238 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:26:28.471385 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:28.481233 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:26:28.481370 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:28.714507 (MainThread): Found 4 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:26:28.718327 (MainThread): 
2020-06-03 13:26:28.718681 (MainThread): Acquiring new bigquery connection "master".
2020-06-03 13:26:28.718770 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:28.730015 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:26:30.312200 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt".
2020-06-03 13:26:30.312575 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-06-03 13:26:30.313140 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:26:30.821628 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:26:31.860801 (MainThread): 23:26:31 | Concurrency: 1 threads (target='dev')
2020-06-03 13:26:31.861031 (MainThread): 23:26:31 | 
2020-06-03 13:26:31.865173 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:26:31.865424 (Thread-1): 23:26:31 | 1 of 2 START test not_null_provider_inpatient_charges_2011_inpatient_provider_id [RUN]
2020-06-03 13:26:31.865793 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:26:31.865913 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt).
2020-06-03 13:26:31.866034 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:26:31.886177 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"
2020-06-03 13:26:31.886649 (Thread-1): finished collecting timing info
2020-06-03 13:26:31.886946 (Thread-1): On test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
where inpatient_provider_id is null


2020-06-03 13:26:35.256459 (Thread-1): finished collecting timing info
2020-06-03 13:26:35.257173 (Thread-1): 23:26:35 | 1 of 2 PASS not_null_provider_inpatient_charges_2011_inpatient_provider_id [PASS in 3.39s]
2020-06-03 13:26:35.257371 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:26:35.257560 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:26:35.257730 (Thread-1): 23:26:35 | 2 of 2 START test not_null_provider_outpatient_charges_2011_outpatient_provider_id [RUN]
2020-06-03 13:26:35.258237 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:26:35.258387 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id).
2020-06-03 13:26:35.258516 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:26:35.267578 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"
2020-06-03 13:26:35.267965 (Thread-1): finished collecting timing info
2020-06-03 13:26:35.268209 (Thread-1): On test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
where outpatient_provider_id is null


2020-06-03 13:26:38.374194 (Thread-1): finished collecting timing info
2020-06-03 13:26:38.374992 (Thread-1): 23:26:38 | 2 of 2 PASS not_null_provider_outpatient_charges_2011_outpatient_provider_id [PASS in 3.12s]
2020-06-03 13:26:38.375183 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:26:38.376811 (MainThread): 23:26:38 | 
2020-06-03 13:26:38.376967 (MainThread): 23:26:38 | Finished running 2 tests in 9.66s.
2020-06-03 13:26:38.377092 (MainThread): Connection 'master' was left open.
2020-06-03 13:26:38.377183 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id' was left open.
2020-06-03 13:26:38.383443 (MainThread): 
2020-06-03 13:26:38.383604 (MainThread): Completed successfully
2020-06-03 13:26:38.383736 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-06-03 13:26:38.383977 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62a351bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62a3636a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62a363910>]}
2020-06-03 13:26:38.384236 (MainThread): Flushing usage events
2020-06-03 13:26:40.386939 (MainThread): Running with dbt=0.16.1
2020-06-03 13:26:40.806611 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-06-03 13:26:40.807255 (MainThread): Tracking: tracking
2020-06-03 13:26:40.812833 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe067498a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0674a8700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0674a86d0>]}
2020-06-03 13:26:40.834310 (MainThread): Partial parsing not enabled
2020-06-03 13:26:40.836223 (MainThread): Parsing macros/core.sql
2020-06-03 13:26:40.840740 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:26:40.848766 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:26:40.850759 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:26:40.868463 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:26:40.902202 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:26:40.922584 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:26:40.924524 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:26:40.930781 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:26:40.943380 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:26:40.950043 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:26:40.956174 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:26:40.960915 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:26:40.961857 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:26:40.962899 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:26:40.964477 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:26:40.966471 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:26:40.975212 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:26:40.977137 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:26:40.978170 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:26:41.019780 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:26:41.021083 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:26:41.022036 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:26:41.023126 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:26:41.025553 (MainThread): Parsing macros/etc.sql
2020-06-03 13:26:41.026279 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:26:41.033856 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:26:41.055751 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:26:41.057687 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:26:41.059113 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:26:41.068265 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:26:41.080236 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:26:41.098852 (MainThread): Partial parsing not enabled
2020-06-03 13:26:41.099198 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:26:41.128768 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:26:41.128883 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:26:41.143580 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:26:41.143702 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:41.149383 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:26:41.149473 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:41.155373 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:26:41.155459 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:41.185216 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:26:41.185328 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:41.193451 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:26:41.193546 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:41.428377 (MainThread): Found 4 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:26:41.431858 (MainThread): 
2020-06-03 13:26:41.432154 (MainThread): Acquiring new bigquery connection "master".
2020-06-03 13:26:41.432236 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:26:41.439056 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-06-03 13:26:41.439250 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-03 13:26:41.440125 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:26:42.839283 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:26:44.240833 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt".
2020-06-03 13:26:44.241312 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-06-03 13:26:44.241613 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:26:44.661053 (MainThread): 23:26:44 | Concurrency: 1 threads (target='dev')
2020-06-03 13:26:44.661273 (MainThread): 23:26:44 | 
2020-06-03 13:26:44.664759 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:26:44.664979 (Thread-1): 23:26:44 | 1 of 4 START table model medicare_provider_2011_analysis_dbt.provider_inpatient_charges_2011 [RUN]
2020-06-03 13:26:44.665435 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:26:44.666101 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt).
2020-06-03 13:26:44.666262 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:26:44.687178 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:26:44.687628 (Thread-1): finished collecting timing info
2020-06-03 13:26:44.726080 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:26:45.461060 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:26:45.461662 (Thread-1): On model.dbt_servian_demo.provider_inpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.provider_inpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
  provider_id as inpatient_provider_id,
  provider_name as inpatient_provider_name,
  provider_city as inpatient_provider_city,
  provider_state as inpatient_provider_state,
  ROUND(SUM(total_discharges),2) as inpatient_sum_total_discharges,
  ROUND(SUM(average_covered_charges),2) as inpatient_sum_average_covered_charges,
  ROUND(SUM(average_total_payments),2) as inpatient_sum_average_total_payments,
  ROUND(SUM(average_medicare_payments),2) as inpatient_average_medicare_payments
FROM
  `bigquery-public-data`.`medicare`.`inpatient_charges_2011`
GROUP BY
  1,
  2,
  3,
  4
  );
    
2020-06-03 13:26:48.649166 (Thread-1): finished collecting timing info
2020-06-03 13:26:48.650168 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fa384cf-39f6-4bcc-ada0-1e5751594527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe06769f2e0>]}
2020-06-03 13:26:48.650562 (Thread-1): 23:26:48 | 1 of 4 OK created table model medicare_provider_2011_analysis_dbt.provider_inpatient_charges_2011 [CREATE TABLE (3337) in 3.98s]
2020-06-03 13:26:48.650750 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:26:48.650962 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:26:48.651229 (Thread-1): 23:26:48 | 2 of 4 START table model medicare_provider_2011_analysis_dbt.provider_outpatient_charges_2011 [RUN]
2020-06-03 13:26:48.651533 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:26:48.651636 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.provider_inpatient_charges_2011).
2020-06-03 13:26:48.651736 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:26:48.660170 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:26:48.660612 (Thread-1): finished collecting timing info
2020-06-03 13:26:48.664670 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:26:49.056988 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:26:49.057760 (Thread-1): On model.dbt_servian_demo.provider_outpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.provider_outpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
  provider_id as outpatient_provider_id,
  provider_name as outpatient_provider_name,
  provider_city as outpatient_provider_city,
  provider_state as outpatient_provider_state,
  ROUND(SUM(outpatient_services),2) as outpatient_sum_outpatient_services,
  ROUND(SUM(average_estimated_submitted_charges),2) as outpatient_sum_average_estimated_submitted_charges,
  ROUND(SUM(average_total_payments),2) as outpatient_sum_average_total_payments
FROM
  `bigquery-public-data`.`medicare`.`outpatient_charges_2011`
GROUP BY
  1,
  2,
  3,
  4
  );
    
2020-06-03 13:26:52.646579 (Thread-1): finished collecting timing info
2020-06-03 13:26:52.647480 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fa384cf-39f6-4bcc-ada0-1e5751594527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe06768fdc0>]}
2020-06-03 13:26:52.647817 (Thread-1): 23:26:52 | 2 of 4 OK created table model medicare_provider_2011_analysis_dbt.provider_outpatient_charges_2011 [CREATE TABLE (3135) in 4.00s]
2020-06-03 13:26:52.647995 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:26:52.648176 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:26:52.648354 (Thread-1): 23:26:52 | 3 of 4 START view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_analysis [RUN]
2020-06-03 13:26:52.648841 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:26:52.648991 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.provider_outpatient_charges_2011).
2020-06-03 13:26:52.649126 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:26:52.658999 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:26:52.659424 (Thread-1): finished collecting timing info
2020-06-03 13:26:52.677432 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:26:52.677891 (Thread-1): On model.dbt_servian_demo.physicians_supplier_2012_analysis: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.physicians_supplier_2012_analysis"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`physicians_supplier_2012_analysis`
  OPTIONS()
  as (
     


SELECT
  nppes_provider_city,
 	
 		ROUND(SUM(line_srvc_cnt)) as sum_line_srvc_cnt,
	
 		ROUND(SUM(bene_unique_cnt)) as sum_bene_unique_cnt,
	
 		ROUND(SUM(bene_day_srvc_cnt)) as sum_bene_day_srvc_cnt,
	
 		ROUND(SUM(average_medicare_allowed_amt)) as sum_average_medicare_allowed_amt,
	
 		ROUND(SUM(stdev_medicare_allowed_amt)) as sum_stdev_medicare_allowed_amt,
	
 		ROUND(SUM(average_submitted_chrg_amt)) as sum_average_submitted_chrg_amt,
	
 		ROUND(SUM(stdev_submitted_chrg_amt)) as sum_stdev_submitted_chrg_amt,
	
 		ROUND(SUM(average_medicare_payment_amt)) as sum_average_medicare_payment_amt,
	
 		ROUND(SUM(stdev_medicare_payment_amt)) as sum_stdev_medicare_payment_amt,
	
FROM
  `bigquery-public-data`.`medicare`.`physicians_and_other_supplier_2012`
GROUP BY
  1
  );

2020-06-03 13:26:54.561686 (Thread-1): finished collecting timing info
2020-06-03 13:26:54.562575 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fa384cf-39f6-4bcc-ada0-1e5751594527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe067756e50>]}
2020-06-03 13:26:54.562905 (Thread-1): 23:26:54 | 3 of 4 OK created view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_analysis [CREATE VIEW in 1.91s]
2020-06-03 13:26:54.563082 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:26:54.563261 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:26:54.563457 (Thread-1): 23:26:54 | 4 of 4 START table model medicare_provider_2011_analysis_dbt.outpatient_inpatient_charges_2011 [RUN]
2020-06-03 13:26:54.563877 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:26:54.563999 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.physicians_supplier_2012_analysis).
2020-06-03 13:26:54.564108 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:26:54.573476 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:26:54.573891 (Thread-1): finished collecting timing info
2020-06-03 13:26:54.577826 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:26:54.994124 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:26:54.994839 (Thread-1): On model.dbt_servian_demo.outpatient_inpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.outpatient_inpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`outpatient_inpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
	*
FROM
 	`graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011` outpatient
JOIN
	`graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011` inpatient
ON
	outpatient_provider_id = inpatient_provider_id
  );
    
2020-06-03 13:26:58.620746 (Thread-1): finished collecting timing info
2020-06-03 13:26:58.621633 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fa384cf-39f6-4bcc-ada0-1e5751594527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0674daeb0>]}
2020-06-03 13:26:58.621971 (Thread-1): 23:26:58 | 4 of 4 OK created table model medicare_provider_2011_analysis_dbt.outpatient_inpatient_charges_2011 [CREATE TABLE (3135) in 4.06s]
2020-06-03 13:26:58.622148 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:26:58.623643 (MainThread): 23:26:58 | 
2020-06-03 13:26:58.623797 (MainThread): 23:26:58 | Finished running 3 table models, 1 view model in 17.19s.
2020-06-03 13:26:58.623922 (MainThread): Connection 'master' was left open.
2020-06-03 13:26:58.624016 (MainThread): Connection 'model.dbt_servian_demo.outpatient_inpatient_charges_2011' was left open.
2020-06-03 13:26:58.634915 (MainThread): 
2020-06-03 13:26:58.635062 (MainThread): Completed successfully
2020-06-03 13:26:58.635190 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2020-06-03 13:26:58.635395 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe06764fa60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe06764f760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe06764f520>]}
2020-06-03 13:26:58.635597 (MainThread): Flushing usage events
2020-06-03 13:27:00.958538 (MainThread): Running with dbt=0.16.1
2020-06-03 13:27:01.322604 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-06-03 13:27:01.323349 (MainThread): Tracking: tracking
2020-06-03 13:27:01.328737 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8b947dee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8b948d640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8b948d610>]}
2020-06-03 13:27:01.329340 (MainThread): Checking target/*
2020-06-03 13:27:01.331676 (MainThread):  Cleaned target/*
2020-06-03 13:27:01.331793 (MainThread): Checking dbt_modules/*
2020-06-03 13:27:01.332200 (MainThread):  Cleaned dbt_modules/*
2020-06-03 13:27:01.332291 (MainThread): Finished cleaning all paths.
2020-06-03 13:27:01.332574 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8b947dee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8b948d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8b948d5b0>]}
2020-06-03 13:27:01.332737 (MainThread): Flushing usage events
2020-06-03 13:27:03.227647 (MainThread): Running with dbt=0.16.1
2020-06-03 13:27:03.593572 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2020-06-03 13:27:03.594282 (MainThread): Tracking: tracking
2020-06-03 13:27:03.599595 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683d97640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683da8730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683da8700>]}
2020-06-03 13:27:03.619529 (MainThread): Partial parsing not enabled
2020-06-03 13:27:03.621271 (MainThread): Parsing macros/core.sql
2020-06-03 13:27:03.625673 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:27:03.633266 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:27:03.635019 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:27:03.651241 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:27:03.684790 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:27:03.704857 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:27:03.706664 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:27:03.712461 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:27:03.724695 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:27:03.731159 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:27:03.737084 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:27:03.741659 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:27:03.742543 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:27:03.743523 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:27:03.745025 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:27:03.747167 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:27:03.755919 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:27:03.757769 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:27:03.758754 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:27:03.799211 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:27:03.800292 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:27:03.801142 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:27:03.802190 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:27:03.804358 (MainThread): Parsing macros/etc.sql
2020-06-03 13:27:03.804979 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:27:03.812495 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:27:03.833557 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:27:03.835438 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:27:03.836834 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:27:03.846236 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:27:03.859346 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:27:03.878697 (MainThread): Partial parsing not enabled
2020-06-03 13:27:03.879059 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:27:03.908461 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:27:03.908569 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:27:03.923001 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:27:03.923103 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:27:03.928622 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:27:03.928710 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:27:03.934523 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:27:03.934606 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:27:03.964383 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:27:03.964497 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:27:03.972460 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:27:03.972562 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:27:04.201800 (MainThread): Found 4 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:27:04.205246 (MainThread): 
2020-06-03 13:27:04.205379 (MainThread): 23:27:04 | Concurrency: 1 threads (target='dev')
2020-06-03 13:27:04.205474 (MainThread): 23:27:04 | 
2020-06-03 13:27:04.207886 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:27:04.208226 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:27:04.208314 (Thread-1): Opening a new connection, currently in state init
2020-06-03 13:27:04.208408 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:27:04.223192 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:27:04.223764 (Thread-1): finished collecting timing info
2020-06-03 13:27:04.224004 (Thread-1): finished collecting timing info
2020-06-03 13:27:04.224348 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:27:04.224463 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:27:04.224667 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:27:04.224747 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:27:04.224825 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:27:04.230907 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:27:04.231331 (Thread-1): finished collecting timing info
2020-06-03 13:27:04.231536 (Thread-1): finished collecting timing info
2020-06-03 13:27:04.231839 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:27:04.231951 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:27:04.232149 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:27:04.232226 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:27:04.232302 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:27:04.240668 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:27:04.241327 (Thread-1): finished collecting timing info
2020-06-03 13:27:04.241557 (Thread-1): finished collecting timing info
2020-06-03 13:27:04.242004 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:27:04.242131 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:27:04.242357 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:27:04.242438 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:27:04.242521 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:27:04.255715 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"
2020-06-03 13:27:04.256174 (Thread-1): finished collecting timing info
2020-06-03 13:27:04.256404 (Thread-1): finished collecting timing info
2020-06-03 13:27:04.256758 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:27:04.256885 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:27:04.257111 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:27:04.257199 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:27:04.257284 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:27:04.264045 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:27:04.264344 (Thread-1): finished collecting timing info
2020-06-03 13:27:04.264544 (Thread-1): finished collecting timing info
2020-06-03 13:27:04.264848 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:27:04.264958 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:27:04.265370 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:27:04.265460 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:27:04.265596 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:27:04.272184 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"
2020-06-03 13:27:04.272495 (Thread-1): finished collecting timing info
2020-06-03 13:27:04.272737 (Thread-1): finished collecting timing info
2020-06-03 13:27:04.273089 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:27:04.273867 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id' was properly closed.
2020-06-03 13:27:04.273953 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id' was properly closed.
2020-06-03 13:27:04.285350 (MainThread): 23:27:04 | Done.
2020-06-03 13:27:04.286359 (MainThread): Acquiring new bigquery connection "generate_catalog".
2020-06-03 13:27:04.286447 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:27:04.286519 (MainThread): 23:27:04 | Building catalog
2020-06-03 13:27:04.300976 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:27:07.758042 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "graham-hamza-bq-dbt-webinar.information_schema".
2020-06-03 13:27:07.758454 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-03 13:27:07.834013 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:27:08.285944 (ThreadPoolExecutor-0_0): On graham-hamza-bq-dbt-webinar.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "graham-hamza-bq-dbt-webinar.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `graham-hamza-bq-dbt-webinar`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('medicare_provider_2011_analysis_dbt'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-03 13:27:13.807761 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "bigquery-public-data.information_schema".
2020-06-03 13:27:13.807983 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly graham-hamza-bq-dbt-webinar.information_schema).
2020-06-03 13:27:13.810549 (ThreadPoolExecutor-0_0): On bigquery-public-data.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "bigquery-public-data.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `bigquery-public-data`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('medicare'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bigquery-public-data`.`medicare`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `bigquery-public-data`.`medicare`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `bigquery-public-data`.`medicare`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-03 13:27:14.528446 (ThreadPoolExecutor-0_0): Unhandled error while running:
macro get_catalog
2020-06-03 13:27:14.528679 (ThreadPoolExecutor-0_0): Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-03 13:27:14.529242 (MainThread): Encountered an error while generating catalog: Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-03 13:27:14.616267 (MainThread): dbt encountered 1 failure while writing the catalog
2020-06-03 13:27:14.616528 (MainThread): 23:27:14 | Catalog written to /Users/hamzakhan/Desktop/Work/Servian/dbt-demo/dbt-demo-servian/target/catalog.json
2020-06-03 13:27:14.616738 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86842a0d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86842a0d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86842a0df0>]}
2020-06-03 13:27:14.616960 (MainThread): Flushing usage events
2020-06-03 13:27:15.715702 (MainThread): Connection 'generate_catalog' was left open.
2020-06-03 13:27:15.715909 (MainThread): Connection 'bigquery-public-data.information_schema' was left open.
2020-06-03 13:27:16.662679 (MainThread): Running with dbt=0.16.1
2020-06-03 13:27:17.040211 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, port=8001, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='serve', write_json=True)
2020-06-03 13:27:17.041190 (MainThread): Tracking: tracking
2020-06-03 13:27:17.046946 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc82397f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc823a7670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc823a7640>]}
2020-06-03 13:27:17.048792 (MainThread): Serving docs at 0.0.0.0:8001
2020-06-03 13:27:17.048965 (MainThread): To access from your browser, navigate to:  http://localhost:8001
2020-06-03 13:27:17.049054 (MainThread): Press Ctrl+C to exit.


2020-06-03 13:28:00.501237 (MainThread): Flushing usage events
2020-06-03 13:28:01.040497 (MainThread): ctrl-c
2020-06-03 13:28:01.041053 (MainThread): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.105', 53031), raddr=('54.174.31.151', 443)>
2020-06-03 13:35:49.683588 (MainThread): Running with dbt=0.16.1
2020-06-03 13:35:50.041939 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-06-03 13:35:50.043347 (MainThread): Tracking: tracking
2020-06-03 13:35:50.049356 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9cccb99f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9cccba8640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9cccba8610>]}
2020-06-03 13:35:50.069576 (MainThread): Partial parsing not enabled
2020-06-03 13:35:50.071414 (MainThread): Parsing macros/core.sql
2020-06-03 13:35:50.075740 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:35:50.085110 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:35:50.087038 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:35:50.103162 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:35:50.136464 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:35:50.156356 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:35:50.158174 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:35:50.163999 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:35:50.176319 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:35:50.182825 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:35:50.189140 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:35:50.193881 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:35:50.194794 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:35:50.195821 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:35:50.197386 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:35:50.199346 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:35:50.207937 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:35:50.209825 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:35:50.210838 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:35:50.251482 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:35:50.252611 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:35:50.253469 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:35:50.254481 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:35:50.256771 (MainThread): Parsing macros/etc.sql
2020-06-03 13:35:50.257395 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:35:50.264662 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:35:50.285152 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:35:50.286991 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:35:50.288338 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:35:50.297514 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:35:50.309404 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:35:50.327519 (MainThread): Partial parsing not enabled
2020-06-03 13:35:50.328718 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:35:50.358914 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:35:50.359035 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:35:50.373538 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:35:50.373637 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:35:50.379136 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:35:50.379225 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:35:50.385273 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:35:50.385365 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:35:50.388363 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9cccc27160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ccce45ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ccce4ec10>]}
2020-06-03 13:35:50.388577 (MainThread): Flushing usage events
2020-06-03 13:35:51.461837 (MainThread): Connection 'model.dbt_servian_demo.physicians_supplier_2012_analysis' was properly closed.
2020-06-03 13:35:51.462098 (MainThread): Encountered an error:
2020-06-03 13:35:51.462296 (MainThread): Compilation Error in model physicians_supplier_2012_analysis (models/medicare_provider_2011_analysis_dbt/physicians_supplier_2012_analysis.sql)
  expected token 'end of print statement', got '='
    line 1
      {{ config(materialized='view'),persist_docs={"relation": true} }}
2020-06-03 13:35:51.473436 (MainThread): Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 386, in catch_jinja
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 404, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 1, in template
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got '='
  line 1
    {{ config(materialized='view'),persist_docs={"relation": true} }}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 336, in load_all
    loader.load(internal_manifest=internal_manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 208, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 182, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 138, in parse_with_cache
    parser.parse_file(block)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 380, in parse_file
    self.parse_node(file_block)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 353, in parse_node
    self.render_update(node, config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 329, in render_update
    self.render_with_context(node, config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 264, in render_with_context
    get_rendered(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 413, in get_rendered
    template = get_template(string, ctx, node, capture_macros=capture_macros)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 404, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 389, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model physicians_supplier_2012_analysis (models/medicare_provider_2011_analysis_dbt/physicians_supplier_2012_analysis.sql)
  expected token 'end of print statement', got '='
    line 1
      {{ config(materialized='view'),persist_docs={"relation": true} }}

2020-06-03 13:35:52.391678 (MainThread): Running with dbt=0.16.1
2020-06-03 13:35:52.749240 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-06-03 13:35:52.749991 (MainThread): Tracking: tracking
2020-06-03 13:35:52.755329 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3c7d987c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3c7da8760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3c7da8730>]}
2020-06-03 13:35:52.775042 (MainThread): Partial parsing not enabled
2020-06-03 13:35:52.776704 (MainThread): Parsing macros/core.sql
2020-06-03 13:35:52.781062 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:35:52.788646 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:35:52.790352 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:35:52.806247 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:35:52.839349 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:35:52.860204 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:35:52.862019 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:35:52.867767 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:35:52.879970 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:35:52.886371 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:35:52.892260 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:35:52.896864 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:35:52.897762 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:35:52.898774 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:35:52.900319 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:35:52.902260 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:35:52.910812 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:35:52.912696 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:35:52.913700 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:35:52.954200 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:35:52.955290 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:35:52.956140 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:35:52.957160 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:35:52.959316 (MainThread): Parsing macros/etc.sql
2020-06-03 13:35:52.959937 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:35:52.967273 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:35:52.988065 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:35:52.989958 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:35:52.991315 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:35:53.000496 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:35:53.012117 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:35:53.030452 (MainThread): Partial parsing not enabled
2020-06-03 13:35:53.030779 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:35:53.060480 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:35:53.060600 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:35:53.075178 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:35:53.075288 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:35:53.080841 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:35:53.080931 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:35:53.086778 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:35:53.086863 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:35:53.089264 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3c7e37d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3c7f52fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3c7f4fd30>]}
2020-06-03 13:35:53.089437 (MainThread): Flushing usage events
2020-06-03 13:35:54.246903 (MainThread): Connection 'model.dbt_servian_demo.physicians_supplier_2012_analysis' was properly closed.
2020-06-03 13:35:54.247187 (MainThread): Encountered an error:
2020-06-03 13:35:54.247386 (MainThread): Compilation Error in model physicians_supplier_2012_analysis (models/medicare_provider_2011_analysis_dbt/physicians_supplier_2012_analysis.sql)
  expected token 'end of print statement', got '='
    line 1
      {{ config(materialized='view'),persist_docs={"relation": true} }}
2020-06-03 13:35:54.250239 (MainThread): Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 386, in catch_jinja
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 404, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 1, in template
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got '='
  line 1
    {{ config(materialized='view'),persist_docs={"relation": true} }}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 336, in load_all
    loader.load(internal_manifest=internal_manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 208, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 182, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 138, in parse_with_cache
    parser.parse_file(block)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 380, in parse_file
    self.parse_node(file_block)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 353, in parse_node
    self.render_update(node, config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 329, in render_update
    self.render_with_context(node, config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 264, in render_with_context
    get_rendered(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 413, in get_rendered
    template = get_template(string, ctx, node, capture_macros=capture_macros)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 404, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 389, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model physicians_supplier_2012_analysis (models/medicare_provider_2011_analysis_dbt/physicians_supplier_2012_analysis.sql)
  expected token 'end of print statement', got '='
    line 1
      {{ config(materialized='view'),persist_docs={"relation": true} }}

2020-06-03 13:35:55.185791 (MainThread): Running with dbt=0.16.1
2020-06-03 13:35:55.545209 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-06-03 13:35:55.545897 (MainThread): Tracking: tracking
2020-06-03 13:35:55.551064 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe630599fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6305a8670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6305a8640>]}
2020-06-03 13:35:55.571132 (MainThread): Partial parsing not enabled
2020-06-03 13:35:55.572783 (MainThread): Parsing macros/core.sql
2020-06-03 13:35:55.577088 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:35:55.584536 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:35:55.586422 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:35:55.602173 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:35:55.635567 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:35:55.655732 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:35:55.657496 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:35:55.663161 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:35:55.675588 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:35:55.681969 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:35:55.687855 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:35:55.692478 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:35:55.693367 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:35:55.694359 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:35:55.695956 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:35:55.697865 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:35:55.706303 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:35:55.708155 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:35:55.709144 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:35:55.749494 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:35:55.750610 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:35:55.751469 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:35:55.752480 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:35:55.754656 (MainThread): Parsing macros/etc.sql
2020-06-03 13:35:55.755280 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:35:55.762794 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:35:55.785626 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:35:55.787569 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:35:55.788955 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:35:55.798168 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:35:55.809980 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:35:55.828021 (MainThread): Partial parsing not enabled
2020-06-03 13:35:55.828351 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:35:55.857929 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:35:55.858057 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:35:55.872815 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:35:55.872932 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:35:55.878641 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:35:55.878740 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:35:55.884757 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:35:55.884851 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:35:55.887332 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe630737520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe63084ceb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe630847c40>]}
2020-06-03 13:35:55.887507 (MainThread): Flushing usage events
2020-06-03 13:35:56.947822 (MainThread): Connection 'model.dbt_servian_demo.physicians_supplier_2012_analysis' was properly closed.
2020-06-03 13:35:56.948082 (MainThread): Encountered an error:
2020-06-03 13:35:56.948276 (MainThread): Compilation Error in model physicians_supplier_2012_analysis (models/medicare_provider_2011_analysis_dbt/physicians_supplier_2012_analysis.sql)
  expected token 'end of print statement', got '='
    line 1
      {{ config(materialized='view'),persist_docs={"relation": true} }}
2020-06-03 13:35:56.951124 (MainThread): Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 386, in catch_jinja
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 404, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 1, in template
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got '='
  line 1
    {{ config(materialized='view'),persist_docs={"relation": true} }}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 336, in load_all
    loader.load(internal_manifest=internal_manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 208, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 182, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 138, in parse_with_cache
    parser.parse_file(block)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 380, in parse_file
    self.parse_node(file_block)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 353, in parse_node
    self.render_update(node, config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 329, in render_update
    self.render_with_context(node, config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 264, in render_with_context
    get_rendered(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 413, in get_rendered
    template = get_template(string, ctx, node, capture_macros=capture_macros)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 404, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 389, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model physicians_supplier_2012_analysis (models/medicare_provider_2011_analysis_dbt/physicians_supplier_2012_analysis.sql)
  expected token 'end of print statement', got '='
    line 1
      {{ config(materialized='view'),persist_docs={"relation": true} }}

2020-06-03 13:35:57.896250 (MainThread): Running with dbt=0.16.1
2020-06-03 13:35:58.258259 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-06-03 13:35:58.259135 (MainThread): Tracking: tracking
2020-06-03 13:35:58.264577 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc23fd98e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc23fda75b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc23fda7580>]}
2020-06-03 13:35:58.265106 (MainThread): Checking target/*
2020-06-03 13:35:58.266657 (MainThread):  Cleaned target/*
2020-06-03 13:35:58.266851 (MainThread): Checking dbt_modules/*
2020-06-03 13:35:58.267311 (MainThread):  Cleaned dbt_modules/*
2020-06-03 13:35:58.267418 (MainThread): Finished cleaning all paths.
2020-06-03 13:35:58.267595 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc23fd98e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc23fda7550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc23fda7520>]}
2020-06-03 13:35:58.267772 (MainThread): Flushing usage events
2020-06-03 13:36:00.366272 (MainThread): Running with dbt=0.16.1
2020-06-03 13:36:00.726058 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2020-06-03 13:36:00.726931 (MainThread): Tracking: tracking
2020-06-03 13:36:00.732697 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2aac98fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2aaca9670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2aaca9640>]}
2020-06-03 13:36:00.752730 (MainThread): Partial parsing not enabled
2020-06-03 13:36:00.754434 (MainThread): Parsing macros/core.sql
2020-06-03 13:36:00.758764 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:36:00.766296 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:36:00.767979 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:36:00.784035 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:36:00.817827 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:36:00.838027 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:36:00.839831 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:36:00.845728 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:36:00.857982 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:36:00.864309 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:36:00.870219 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:36:00.874776 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:36:00.875668 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:36:00.876658 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:36:00.878184 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:36:00.880105 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:36:00.888519 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:36:00.890376 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:36:00.891365 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:36:00.932587 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:36:00.933715 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:36:00.934576 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:36:00.935602 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:36:00.937791 (MainThread): Parsing macros/etc.sql
2020-06-03 13:36:00.938416 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:36:00.945951 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:36:00.966708 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:36:00.968593 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:36:00.969961 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:36:00.979180 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:36:00.990898 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:36:01.008825 (MainThread): Partial parsing not enabled
2020-06-03 13:36:01.009150 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:36:01.038793 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:36:01.038907 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:36:01.053404 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:36:01.053506 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:36:01.058972 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:36:01.059057 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:36:01.064845 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:36:01.064930 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:36:01.067435 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2aad377f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2aaf50ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2aaf4dc70>]}
2020-06-03 13:36:01.067612 (MainThread): Flushing usage events
2020-06-03 13:36:02.074903 (MainThread): Connection 'model.dbt_servian_demo.physicians_supplier_2012_analysis' was properly closed.
2020-06-03 13:36:02.075157 (MainThread): Encountered an error:
2020-06-03 13:36:02.075350 (MainThread): Compilation Error in model physicians_supplier_2012_analysis (models/medicare_provider_2011_analysis_dbt/physicians_supplier_2012_analysis.sql)
  expected token 'end of print statement', got '='
    line 1
      {{ config(materialized='view'),persist_docs={"relation": true} }}
2020-06-03 13:36:02.080041 (MainThread): Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 386, in catch_jinja
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 404, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 1, in template
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got '='
  line 1
    {{ config(materialized='view'),persist_docs={"relation": true} }}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/generate.py", line 194, in run
    compile_results = CompileTask.run(self)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 336, in load_all
    loader.load(internal_manifest=internal_manifest)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 208, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 182, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/manifest.py", line 138, in parse_with_cache
    parser.parse_file(block)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 380, in parse_file
    self.parse_node(file_block)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 353, in parse_node
    self.render_update(node, config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 329, in render_update
    self.render_with_context(node, config)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/parser/base.py", line 264, in render_with_context
    get_rendered(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 413, in get_rendered
    template = get_template(string, ctx, node, capture_macros=capture_macros)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 404, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/clients/jinja.py", line 389, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model physicians_supplier_2012_analysis (models/medicare_provider_2011_analysis_dbt/physicians_supplier_2012_analysis.sql)
  expected token 'end of print statement', got '='
    line 1
      {{ config(materialized='view'),persist_docs={"relation": true} }}

2020-06-03 13:36:03.010180 (MainThread): Running with dbt=0.16.1
2020-06-03 13:36:03.370072 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, port=8001, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='serve', write_json=True)
2020-06-03 13:36:03.370928 (MainThread): Tracking: tracking
2020-06-03 13:36:03.376208 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff90b597ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff90b5a7640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff90b5a7610>]}
2020-06-03 13:36:03.376892 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff90b597ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff90b5a7640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff90b5a7610>]}
2020-06-03 13:36:03.377071 (MainThread): Flushing usage events
2020-06-03 13:36:04.415402 (MainThread): Encountered an error:
2020-06-03 13:36:04.415663 (MainThread): [Errno 2] No such file or directory: 'target'
2020-06-03 13:36:04.417499 (MainThread): Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dbt/task/serve.py", line 15, in run
    os.chdir(self.config.target_path)
FileNotFoundError: [Errno 2] No such file or directory: 'target'

2020-06-03 13:38:40.536212 (MainThread): Running with dbt=0.16.1
2020-06-03 13:38:41.050944 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2020-06-03 13:38:41.052352 (MainThread): Tracking: tracking
2020-06-03 13:38:41.058791 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffe3ec79b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffe3ec89700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffe3ec896d0>]}
2020-06-03 13:38:41.079791 (MainThread): Partial parsing not enabled
2020-06-03 13:38:41.082228 (MainThread): Parsing macros/core.sql
2020-06-03 13:38:41.086612 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:38:41.095159 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:38:41.096922 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:38:41.113078 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:38:41.146765 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:38:41.166860 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:38:41.168659 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:38:41.174450 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:38:41.186839 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:38:41.193390 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:38:41.199360 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:38:41.204000 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:38:41.204896 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:38:41.205905 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:38:41.207470 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:38:41.209416 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:38:41.217955 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:38:41.219974 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:38:41.221029 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:38:41.262191 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:38:41.263350 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:38:41.264240 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:38:41.265285 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:38:41.267520 (MainThread): Parsing macros/etc.sql
2020-06-03 13:38:41.268174 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:38:41.275627 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:38:41.296442 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:38:41.298343 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:38:41.299744 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:38:41.309135 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:38:41.321119 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:38:41.339359 (MainThread): Partial parsing not enabled
2020-06-03 13:38:41.339704 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:38:41.369647 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:38:41.369761 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:38:41.383999 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:38:41.384096 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:41.389868 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:38:41.389963 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:41.397097 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:38:41.397233 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:41.405376 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_macro".
2020-06-03 13:38:41.405505 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:41.438145 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:38:41.438266 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:41.446637 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:38:41.446733 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:41.678538 (MainThread): Found 5 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:38:41.682260 (MainThread): 
2020-06-03 13:38:41.682400 (MainThread): 23:38:41 | Concurrency: 1 threads (target='dev')
2020-06-03 13:38:41.682509 (MainThread): 23:38:41 | 
2020-06-03 13:38:41.685368 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:38:41.685698 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:38:41.685786 (Thread-1): Opening a new connection, currently in state init
2020-06-03 13:38:41.685867 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:38:41.700584 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:38:41.701121 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.701353 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.701685 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:38:41.701797 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:38:41.701999 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:38:41.702075 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:38:41.702310 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:38:41.708485 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:38:41.708799 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.708997 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.709306 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:38:41.709414 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:38:41.709613 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:38:41.709823 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:38:41.709921 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:38:41.717394 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:38:41.717785 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.717998 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.718377 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:38:41.718489 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-03 13:38:41.718697 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_macro".
2020-06-03 13:38:41.718860 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:38:41.719012 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-03 13:38:41.725899 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_macro"
2020-06-03 13:38:41.726250 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.726454 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.726772 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-03 13:38:41.726882 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:38:41.727082 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:38:41.727158 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:38:41.727231 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:38:41.739278 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"
2020-06-03 13:38:41.739727 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.739943 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.740291 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:38:41.740411 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:38:41.740629 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:38:41.740712 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:38:41.740796 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:38:41.748312 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:38:41.748629 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.748825 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.749129 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:38:41.749236 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:38:41.749434 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:38:41.749510 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:38:41.749593 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:38:41.756520 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"
2020-06-03 13:38:41.756882 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.757094 (Thread-1): finished collecting timing info
2020-06-03 13:38:41.757441 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:38:41.758171 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id' was properly closed.
2020-06-03 13:38:41.758284 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id' was properly closed.
2020-06-03 13:38:41.772440 (MainThread): 23:38:41 | Done.
2020-06-03 13:38:41.772615 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffe3ec5ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffe3ef4bf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffe3ef4ba60>]}
2020-06-03 13:38:41.772787 (MainThread): Flushing usage events
2020-06-03 13:38:43.900437 (MainThread): Running with dbt=0.16.1
2020-06-03 13:38:44.259000 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-06-03 13:38:44.259852 (MainThread): Tracking: tracking
2020-06-03 13:38:44.265332 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2e6498b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2e64a7700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2e64a76d0>]}
2020-06-03 13:38:44.285690 (MainThread): Partial parsing not enabled
2020-06-03 13:38:44.287554 (MainThread): Parsing macros/core.sql
2020-06-03 13:38:44.292101 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:38:44.299788 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:38:44.301495 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:38:44.317658 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:38:44.351246 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:38:44.371664 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:38:44.373508 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:38:44.379355 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:38:44.391820 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:38:44.398287 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:38:44.404249 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:38:44.408892 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:38:44.409800 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:38:44.410808 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:38:44.412353 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:38:44.414295 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:38:44.422870 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:38:44.424766 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:38:44.425770 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:38:44.466207 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:38:44.467297 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:38:44.468151 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:38:44.469160 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:38:44.471307 (MainThread): Parsing macros/etc.sql
2020-06-03 13:38:44.471930 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:38:44.479203 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:38:44.499898 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:38:44.501787 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:38:44.503169 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:38:44.512398 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:38:44.524128 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:38:44.542551 (MainThread): Partial parsing not enabled
2020-06-03 13:38:44.542896 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:38:44.572535 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:38:44.572655 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:38:44.587015 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:38:44.587113 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:44.592611 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:38:44.592695 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:44.598574 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:38:44.598660 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:44.605109 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_macro".
2020-06-03 13:38:44.605196 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:44.637865 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:38:44.637984 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:44.646335 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:38:44.646428 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:44.874236 (MainThread): Found 5 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:38:44.877854 (MainThread): 
2020-06-03 13:38:44.878121 (MainThread): Acquiring new bigquery connection "master".
2020-06-03 13:38:44.878198 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:44.890831 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:38:46.378114 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt".
2020-06-03 13:38:46.378503 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-06-03 13:38:46.379050 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:38:46.851424 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:38:47.783632 (MainThread): 23:38:47 | Concurrency: 1 threads (target='dev')
2020-06-03 13:38:47.783864 (MainThread): 23:38:47 | 
2020-06-03 13:38:47.787541 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:38:47.787747 (Thread-1): 23:38:47 | 1 of 2 START test not_null_provider_inpatient_charges_2011_inpatient_provider_id [RUN]
2020-06-03 13:38:47.788052 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:38:47.788155 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt).
2020-06-03 13:38:47.788273 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:38:47.809023 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"
2020-06-03 13:38:47.809585 (Thread-1): finished collecting timing info
2020-06-03 13:38:47.809903 (Thread-1): On test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
where inpatient_provider_id is null


2020-06-03 13:38:51.479674 (Thread-1): finished collecting timing info
2020-06-03 13:38:51.480563 (Thread-1): 23:38:51 | 1 of 2 PASS not_null_provider_inpatient_charges_2011_inpatient_provider_id [PASS in 3.69s]
2020-06-03 13:38:51.480810 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:38:51.481052 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:38:51.481294 (Thread-1): 23:38:51 | 2 of 2 START test not_null_provider_outpatient_charges_2011_outpatient_provider_id [RUN]
2020-06-03 13:38:51.481803 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:38:51.481950 (Thread-1): Re-using an available connection from the pool (formerly test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id).
2020-06-03 13:38:51.482082 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:38:51.492253 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"
2020-06-03 13:38:51.492700 (Thread-1): finished collecting timing info
2020-06-03 13:38:51.492979 (Thread-1): On test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"} */




select count(*)
from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
where outpatient_provider_id is null


2020-06-03 13:38:54.796556 (Thread-1): finished collecting timing info
2020-06-03 13:38:54.797279 (Thread-1): 23:38:54 | 2 of 2 PASS not_null_provider_outpatient_charges_2011_outpatient_provider_id [PASS in 3.32s]
2020-06-03 13:38:54.797467 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:38:54.798900 (MainThread): 23:38:54 | 
2020-06-03 13:38:54.799084 (MainThread): 23:38:54 | Finished running 2 tests in 9.92s.
2020-06-03 13:38:54.799237 (MainThread): Connection 'master' was left open.
2020-06-03 13:38:54.799352 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id' was left open.
2020-06-03 13:38:54.805952 (MainThread): 
2020-06-03 13:38:54.806108 (MainThread): Completed successfully
2020-06-03 13:38:54.806243 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-06-03 13:38:54.806474 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2e70324c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2e70327c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2e7032eb0>]}
2020-06-03 13:38:54.806732 (MainThread): Flushing usage events
2020-06-03 13:38:56.869495 (MainThread): Running with dbt=0.16.1
2020-06-03 13:38:57.231236 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-06-03 13:38:57.232088 (MainThread): Tracking: tracking
2020-06-03 13:38:57.237379 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12fd98fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12fda86d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12fda86a0>]}
2020-06-03 13:38:57.257437 (MainThread): Partial parsing not enabled
2020-06-03 13:38:57.259149 (MainThread): Parsing macros/core.sql
2020-06-03 13:38:57.263527 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:38:57.271168 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:38:57.272871 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:38:57.288947 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:38:57.322373 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:38:57.342499 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:38:57.344297 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:38:57.350045 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:38:57.362252 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:38:57.368501 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:38:57.374341 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:38:57.378840 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:38:57.379717 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:38:57.380694 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:38:57.382192 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:38:57.384078 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:38:57.392474 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:38:57.394307 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:38:57.395280 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:38:57.435267 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:38:57.436358 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:38:57.437211 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:38:57.438220 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:38:57.440369 (MainThread): Parsing macros/etc.sql
2020-06-03 13:38:57.440988 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:38:57.448230 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:38:57.468956 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:38:57.470815 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:38:57.472164 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:38:57.481230 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:38:57.492916 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:38:57.510859 (MainThread): Partial parsing not enabled
2020-06-03 13:38:57.511187 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:38:57.540570 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:38:57.540684 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:38:57.555050 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:38:57.555151 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:57.560592 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:38:57.560681 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:57.566479 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:38:57.566567 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:57.573034 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_macro".
2020-06-03 13:38:57.573122 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:57.604841 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:38:57.604955 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:57.613106 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:38:57.613197 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:57.841490 (MainThread): Found 5 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:38:57.845147 (MainThread): 
2020-06-03 13:38:57.845405 (MainThread): Acquiring new bigquery connection "master".
2020-06-03 13:38:57.845481 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:38:57.853362 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-06-03 13:38:57.853466 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-03 13:38:57.854313 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:38:59.261811 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:39:00.645440 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt".
2020-06-03 13:39:00.645910 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-06-03 13:39:00.646197 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:39:01.068296 (MainThread): 23:39:01 | Concurrency: 1 threads (target='dev')
2020-06-03 13:39:01.068523 (MainThread): 23:39:01 | 
2020-06-03 13:39:01.072157 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:39:01.072381 (Thread-1): 23:39:01 | 1 of 5 START table model medicare_provider_2011_analysis_dbt.provider_inpatient_charges_2011 [RUN]
2020-06-03 13:39:01.072732 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:39:01.072837 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt).
2020-06-03 13:39:01.072960 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:39:01.093440 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:39:01.093921 (Thread-1): finished collecting timing info
2020-06-03 13:39:01.134373 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:39:01.851951 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:39:01.852577 (Thread-1): On model.dbt_servian_demo.provider_inpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.provider_inpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
  provider_id as inpatient_provider_id,
  provider_name as inpatient_provider_name,
  provider_city as inpatient_provider_city,
  provider_state as inpatient_provider_state,
  ROUND(SUM(total_discharges),2) as inpatient_sum_total_discharges,
  ROUND(SUM(average_covered_charges),2) as inpatient_sum_average_covered_charges,
  ROUND(SUM(average_total_payments),2) as inpatient_sum_average_total_payments,
  ROUND(SUM(average_medicare_payments),2) as inpatient_average_medicare_payments
FROM
  `bigquery-public-data`.`medicare`.`inpatient_charges_2011`
GROUP BY
  1,
  2,
  3,
  4
  );
    
2020-06-03 13:39:04.977129 (Thread-1): finished collecting timing info
2020-06-03 13:39:04.978074 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca19e3c1-6682-4bd6-80cd-b546b80eb9fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff13002e550>]}
2020-06-03 13:39:04.978462 (Thread-1): 23:39:04 | 1 of 5 OK created table model medicare_provider_2011_analysis_dbt.provider_inpatient_charges_2011 [CREATE TABLE (3337) in 3.91s]
2020-06-03 13:39:04.978646 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:39:04.978830 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:39:04.979162 (Thread-1): 23:39:04 | 2 of 5 START table model medicare_provider_2011_analysis_dbt.provider_outpatient_charges_2011 [RUN]
2020-06-03 13:39:04.979532 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:39:04.979642 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.provider_inpatient_charges_2011).
2020-06-03 13:39:04.979750 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:39:04.988331 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:39:04.988792 (Thread-1): finished collecting timing info
2020-06-03 13:39:04.992861 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:39:05.470463 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:39:05.471085 (Thread-1): On model.dbt_servian_demo.provider_outpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.provider_outpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
  provider_id as outpatient_provider_id,
  provider_name as outpatient_provider_name,
  provider_city as outpatient_provider_city,
  provider_state as outpatient_provider_state,
  ROUND(SUM(outpatient_services),2) as outpatient_sum_outpatient_services,
  ROUND(SUM(average_estimated_submitted_charges),2) as outpatient_sum_average_estimated_submitted_charges,
  ROUND(SUM(average_total_payments),2) as outpatient_sum_average_total_payments
FROM
  `bigquery-public-data`.`medicare`.`outpatient_charges_2011`
GROUP BY
  1,
  2,
  3,
  4
  );
    
2020-06-03 13:39:08.352792 (Thread-1): finished collecting timing info
2020-06-03 13:39:08.353700 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca19e3c1-6682-4bd6-80cd-b546b80eb9fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff130072820>]}
2020-06-03 13:39:08.354036 (Thread-1): 23:39:08 | 2 of 5 OK created table model medicare_provider_2011_analysis_dbt.provider_outpatient_charges_2011 [CREATE TABLE (3135) in 3.37s]
2020-06-03 13:39:08.354215 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:39:08.354400 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:39:08.354585 (Thread-1): 23:39:08 | 3 of 5 START view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_analysis [RUN]
2020-06-03 13:39:08.355084 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:39:08.355202 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.provider_outpatient_charges_2011).
2020-06-03 13:39:08.355308 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:39:08.364963 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:39:08.365385 (Thread-1): finished collecting timing info
2020-06-03 13:39:08.382917 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:39:08.383339 (Thread-1): On model.dbt_servian_demo.physicians_supplier_2012_analysis: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.physicians_supplier_2012_analysis"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`physicians_supplier_2012_analysis`
  OPTIONS(
      description='This description for physicians_supplier_2012 was generated by dbt'
    )
  as (
     


SELECT
  nppes_provider_city,
 	
 		ROUND(SUM(line_srvc_cnt)) as sum_line_srvc_cnt,
	
 		ROUND(SUM(bene_unique_cnt)) as sum_bene_unique_cnt,
	
 		ROUND(SUM(bene_day_srvc_cnt)) as sum_bene_day_srvc_cnt,
	
 		ROUND(SUM(average_medicare_allowed_amt)) as sum_average_medicare_allowed_amt,
	
 		ROUND(SUM(stdev_medicare_allowed_amt)) as sum_stdev_medicare_allowed_amt,
	
 		ROUND(SUM(average_submitted_chrg_amt)) as sum_average_submitted_chrg_amt,
	
 		ROUND(SUM(stdev_submitted_chrg_amt)) as sum_stdev_submitted_chrg_amt,
	
 		ROUND(SUM(average_medicare_payment_amt)) as sum_average_medicare_payment_amt,
	
 		ROUND(SUM(stdev_medicare_payment_amt)) as sum_stdev_medicare_payment_amt,
	
FROM
  `bigquery-public-data`.`medicare`.`physicians_and_other_supplier_2012`
GROUP BY
  1
  );

2020-06-03 13:39:10.325740 (Thread-1): finished collecting timing info
2020-06-03 13:39:10.326665 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca19e3c1-6682-4bd6-80cd-b546b80eb9fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12ffc3fa0>]}
2020-06-03 13:39:10.327042 (Thread-1): 23:39:10 | 3 of 5 OK created view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_analysis [CREATE VIEW in 1.97s]
2020-06-03 13:39:10.327209 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:39:10.327377 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-03 13:39:10.327542 (Thread-1): 23:39:10 | 4 of 5 START view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_macro [RUN]
2020-06-03 13:39:10.328042 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_macro".
2020-06-03 13:39:10.328192 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.physicians_supplier_2012_analysis).
2020-06-03 13:39:10.328317 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-03 13:39:10.338167 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_macro"
2020-06-03 13:39:10.338622 (Thread-1): finished collecting timing info
2020-06-03 13:39:10.343277 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.physicians_supplier_2012_macro"
2020-06-03 13:39:10.343688 (Thread-1): On model.dbt_servian_demo.physicians_supplier_2012_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.physicians_supplier_2012_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`physicians_supplier_2012_macro`
  OPTIONS()
  as (
     


SELECT
 	nppes_provider_city,
	
	
		ROUND(SUM(line_srvc_cnt)) as sum_line_srvc_cnt,
	
		ROUND(SUM(bene_unique_cnt)) as sum_bene_unique_cnt,
	
		ROUND(SUM(bene_day_srvc_cnt)) as sum_bene_day_srvc_cnt,
	
		ROUND(SUM(average_medicare_allowed_amt)) as sum_average_medicare_allowed_amt,
	
		ROUND(SUM(stdev_medicare_allowed_amt)) as sum_stdev_medicare_allowed_amt,
	
		ROUND(SUM(average_submitted_chrg_amt)) as sum_average_submitted_chrg_amt,
	
		ROUND(SUM(stdev_submitted_chrg_amt)) as sum_stdev_submitted_chrg_amt,
	
		ROUND(SUM(average_medicare_payment_amt)) as sum_average_medicare_payment_amt,
	
		ROUND(SUM(stdev_medicare_payment_amt)) as sum_stdev_medicare_payment_amt,
	

FROM
  `bigquery-public-data`.`medicare`.`physicians_and_other_supplier_2012`
GROUP BY
  1
  );

2020-06-03 13:39:12.133114 (Thread-1): finished collecting timing info
2020-06-03 13:39:12.133987 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca19e3c1-6682-4bd6-80cd-b546b80eb9fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12ffd2640>]}
2020-06-03 13:39:12.134319 (Thread-1): 23:39:12 | 4 of 5 OK created view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_macro [CREATE VIEW in 1.81s]
2020-06-03 13:39:12.134497 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-03 13:39:12.134681 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:39:12.134880 (Thread-1): 23:39:12 | 5 of 5 START table model medicare_provider_2011_analysis_dbt.outpatient_inpatient_charges_2011 [RUN]
2020-06-03 13:39:12.135306 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:39:12.135435 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.physicians_supplier_2012_macro).
2020-06-03 13:39:12.135552 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:39:12.144546 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:39:12.144981 (Thread-1): finished collecting timing info
2020-06-03 13:39:12.148979 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-03 13:39:12.637303 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:39:12.637931 (Thread-1): On model.dbt_servian_demo.outpatient_inpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.outpatient_inpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`outpatient_inpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
	*
FROM
 	`graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011` outpatient
JOIN
	`graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011` inpatient
ON
	outpatient_provider_id = inpatient_provider_id
  );
    
2020-06-03 13:39:16.092040 (Thread-1): finished collecting timing info
2020-06-03 13:39:16.092939 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca19e3c1-6682-4bd6-80cd-b546b80eb9fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff13007af40>]}
2020-06-03 13:39:16.093276 (Thread-1): 23:39:16 | 5 of 5 OK created table model medicare_provider_2011_analysis_dbt.outpatient_inpatient_charges_2011 [CREATE TABLE (3135) in 3.96s]
2020-06-03 13:39:16.093458 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:39:16.095019 (MainThread): 23:39:16 | 
2020-06-03 13:39:16.095189 (MainThread): 23:39:16 | Finished running 3 table models, 2 view models in 18.25s.
2020-06-03 13:39:16.095327 (MainThread): Connection 'master' was left open.
2020-06-03 13:39:16.095430 (MainThread): Connection 'model.dbt_servian_demo.outpatient_inpatient_charges_2011' was left open.
2020-06-03 13:39:16.108923 (MainThread): 
2020-06-03 13:39:16.109079 (MainThread): Completed successfully
2020-06-03 13:39:16.109211 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2020-06-03 13:39:16.109426 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12ff30700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12ff2f550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12ff2b280>]}
2020-06-03 13:39:16.109626 (MainThread): Flushing usage events
2020-06-03 13:39:18.497484 (MainThread): Running with dbt=0.16.1
2020-06-03 13:39:18.860509 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.clean.CleanTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='clean', write_json=True)
2020-06-03 13:39:18.861217 (MainThread): Tracking: tracking
2020-06-03 13:39:18.866798 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6c7377eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6c7387610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6c73875e0>]}
2020-06-03 13:39:18.867435 (MainThread): Checking target/*
2020-06-03 13:39:18.869941 (MainThread):  Cleaned target/*
2020-06-03 13:39:18.870088 (MainThread): Checking dbt_modules/*
2020-06-03 13:39:18.870617 (MainThread):  Cleaned dbt_modules/*
2020-06-03 13:39:18.870731 (MainThread): Finished cleaning all paths.
2020-06-03 13:39:18.870930 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6c7377eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6c73875b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6c7387580>]}
2020-06-03 13:39:18.871133 (MainThread): Flushing usage events
2020-06-03 13:39:20.944462 (MainThread): Running with dbt=0.16.1
2020-06-03 13:39:21.311453 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2020-06-03 13:39:21.312222 (MainThread): Tracking: tracking
2020-06-03 13:39:21.317661 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd34df956d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd34dfa77c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd34dfa7790>]}
2020-06-03 13:39:21.337617 (MainThread): Partial parsing not enabled
2020-06-03 13:39:21.340072 (MainThread): Parsing macros/core.sql
2020-06-03 13:39:21.344529 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-03 13:39:21.352075 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-03 13:39:21.353826 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-03 13:39:21.369857 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-03 13:39:21.403343 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-03 13:39:21.423348 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-03 13:39:21.425107 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-03 13:39:21.430873 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-03 13:39:21.443354 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-03 13:39:21.450456 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-03 13:39:21.456378 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-03 13:39:21.461061 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-03 13:39:21.461947 (MainThread): Parsing macros/etc/query.sql
2020-06-03 13:39:21.462940 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-03 13:39:21.464459 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-03 13:39:21.466390 (MainThread): Parsing macros/etc/datetime.sql
2020-06-03 13:39:21.474877 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-03 13:39:21.476716 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-03 13:39:21.477697 (MainThread): Parsing macros/adapters/common.sql
2020-06-03 13:39:21.518412 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-03 13:39:21.519562 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-03 13:39:21.520418 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-03 13:39:21.521530 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-03 13:39:21.523696 (MainThread): Parsing macros/etc.sql
2020-06-03 13:39:21.524320 (MainThread): Parsing macros/catalog.sql
2020-06-03 13:39:21.531590 (MainThread): Parsing macros/adapters.sql
2020-06-03 13:39:21.552100 (MainThread): Parsing macros/materializations/seed.sql
2020-06-03 13:39:21.553945 (MainThread): Parsing macros/materializations/view.sql
2020-06-03 13:39:21.555297 (MainThread): Parsing macros/materializations/table.sql
2020-06-03 13:39:21.564496 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-03 13:39:21.576245 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-03 13:39:21.594010 (MainThread): Partial parsing not enabled
2020-06-03 13:39:21.594338 (MainThread): Parsing macros/project_macros.sql
2020-06-03 13:39:21.623408 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:39:21.623520 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:39:21.638105 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:39:21.638214 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:39:21.643681 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:39:21.643765 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:39:21.649683 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:39:21.649770 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:39:21.656183 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_macro".
2020-06-03 13:39:21.656270 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:39:21.688262 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:39:21.688425 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:39:21.696526 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:39:21.696618 (MainThread): Opening a new connection, currently in state closed
2020-06-03 13:39:21.927037 (MainThread): Found 5 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-03 13:39:21.930974 (MainThread): 
2020-06-03 13:39:21.931111 (MainThread): 23:39:21 | Concurrency: 1 threads (target='dev')
2020-06-03 13:39:21.931205 (MainThread): 23:39:21 | 
2020-06-03 13:39:21.933615 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:39:21.933899 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-03 13:39:21.933980 (Thread-1): Opening a new connection, currently in state init
2020-06-03 13:39:21.934057 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:39:21.949715 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-03 13:39:21.950318 (Thread-1): finished collecting timing info
2020-06-03 13:39:21.950542 (Thread-1): finished collecting timing info
2020-06-03 13:39:21.950872 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-03 13:39:21.951070 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:39:21.951634 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-03 13:39:21.951733 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:39:21.951811 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:39:21.958419 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-03 13:39:21.958750 (Thread-1): finished collecting timing info
2020-06-03 13:39:21.958954 (Thread-1): finished collecting timing info
2020-06-03 13:39:21.959267 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-03 13:39:21.959375 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:39:21.959649 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-03 13:39:21.959812 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:39:21.959903 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:39:21.968812 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-03 13:39:21.969223 (Thread-1): finished collecting timing info
2020-06-03 13:39:21.969614 (Thread-1): finished collecting timing info
2020-06-03 13:39:21.970028 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-03 13:39:21.970157 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-03 13:39:21.970452 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_macro".
2020-06-03 13:39:21.970541 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:39:21.970621 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-03 13:39:21.978255 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_macro"
2020-06-03 13:39:21.978704 (Thread-1): finished collecting timing info
2020-06-03 13:39:21.978946 (Thread-1): finished collecting timing info
2020-06-03 13:39:21.979307 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-03 13:39:21.979429 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:39:21.979763 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-03 13:39:21.979930 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:39:21.980048 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:39:21.993407 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"
2020-06-03 13:39:21.993870 (Thread-1): finished collecting timing info
2020-06-03 13:39:21.994099 (Thread-1): finished collecting timing info
2020-06-03 13:39:21.994504 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-03 13:39:21.994632 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:39:21.994865 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-03 13:39:21.994953 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:39:21.995038 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:39:22.002786 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-03 13:39:22.003192 (Thread-1): finished collecting timing info
2020-06-03 13:39:22.003427 (Thread-1): finished collecting timing info
2020-06-03 13:39:22.003785 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-03 13:39:22.003906 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:39:22.004127 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-03 13:39:22.004210 (Thread-1): Opening a new connection, currently in state closed
2020-06-03 13:39:22.004291 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:39:22.011876 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"
2020-06-03 13:39:22.012229 (Thread-1): finished collecting timing info
2020-06-03 13:39:22.012470 (Thread-1): finished collecting timing info
2020-06-03 13:39:22.012811 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-03 13:39:22.013542 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id' was properly closed.
2020-06-03 13:39:22.013639 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id' was properly closed.
2020-06-03 13:39:22.027677 (MainThread): 23:39:22 | Done.
2020-06-03 13:39:22.028699 (MainThread): Acquiring new bigquery connection "generate_catalog".
2020-06-03 13:39:22.028796 (MainThread): Opening a new connection, currently in state init
2020-06-03 13:39:22.028868 (MainThread): 23:39:22 | Building catalog
2020-06-03 13:39:22.044059 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:39:24.438429 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "graham-hamza-bq-dbt-webinar.information_schema".
2020-06-03 13:39:24.438831 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-03 13:39:24.515442 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-03 13:39:24.970931 (ThreadPoolExecutor-0_0): On graham-hamza-bq-dbt-webinar.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "graham-hamza-bq-dbt-webinar.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `graham-hamza-bq-dbt-webinar`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('medicare_provider_2011_analysis_dbt'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-03 13:39:30.156963 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "bigquery-public-data.information_schema".
2020-06-03 13:39:30.157179 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly graham-hamza-bq-dbt-webinar.information_schema).
2020-06-03 13:39:30.159661 (ThreadPoolExecutor-0_0): On bigquery-public-data.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "bigquery-public-data.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `bigquery-public-data`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('medicare'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bigquery-public-data`.`medicare`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `bigquery-public-data`.`medicare`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `bigquery-public-data`.`medicare`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-03 13:39:31.009043 (ThreadPoolExecutor-0_0): Unhandled error while running:
macro get_catalog
2020-06-03 13:39:31.009284 (ThreadPoolExecutor-0_0): Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-03 13:39:31.009851 (MainThread): Encountered an error while generating catalog: Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-03 13:39:31.104020 (MainThread): dbt encountered 1 failure while writing the catalog
2020-06-03 13:39:31.104252 (MainThread): 23:39:31 | Catalog written to /Users/hamzakhan/Desktop/Work/Servian/dbt-demo/dbt-demo-servian/target/catalog.json
2020-06-03 13:39:31.104502 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd34df956d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd34e129370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd34e129a00>]}
2020-06-03 13:39:31.104702 (MainThread): Flushing usage events
2020-06-03 13:39:32.135453 (MainThread): Connection 'generate_catalog' was left open.
2020-06-03 13:39:32.135649 (MainThread): Connection 'bigquery-public-data.information_schema' was left open.
2020-06-03 13:39:33.091391 (MainThread): Running with dbt=0.16.1
2020-06-03 13:39:33.458258 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, port=8001, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='serve', write_json=True)
2020-06-03 13:39:33.459054 (MainThread): Tracking: tracking
2020-06-03 13:39:33.464606 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f961e697730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f961e6a8730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f961e6a8700>]}
2020-06-03 13:39:33.466151 (MainThread): Serving docs at 0.0.0.0:8001
2020-06-03 13:39:33.466289 (MainThread): To access from your browser, navigate to:  http://localhost:8001
2020-06-03 13:39:33.466365 (MainThread): Press Ctrl+C to exit.


2020-06-03 13:40:51.519282 (MainThread): Flushing usage events
2020-06-03 13:40:52.555524 (MainThread): ctrl-c
2020-06-04 00:23:47.179360 (MainThread): Running with dbt=0.16.1
2020-06-04 00:23:47.893384 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-06-04 00:23:47.895116 (MainThread): Tracking: tracking
2020-06-04 00:23:47.904633 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd62f963d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd62fa7730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd62fa7700>]}
2020-06-04 00:23:47.928469 (MainThread): Partial parsing not enabled
2020-06-04 00:23:47.931473 (MainThread): Parsing macros/core.sql
2020-06-04 00:23:47.937192 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-04 00:23:47.946350 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-04 00:23:47.948697 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-04 00:23:47.967670 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-04 00:23:48.003499 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-04 00:23:48.024661 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-04 00:23:48.026939 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-04 00:23:48.034068 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-04 00:23:48.047579 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-04 00:23:48.054527 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-04 00:23:48.061418 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-04 00:23:48.066634 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-04 00:23:48.067814 (MainThread): Parsing macros/etc/query.sql
2020-06-04 00:23:48.069187 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-04 00:23:48.071432 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-04 00:23:48.074158 (MainThread): Parsing macros/etc/datetime.sql
2020-06-04 00:23:48.084480 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-04 00:23:48.086918 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-04 00:23:48.088617 (MainThread): Parsing macros/adapters/common.sql
2020-06-04 00:23:48.132548 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-04 00:23:48.134002 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-04 00:23:48.135151 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-04 00:23:48.136783 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-04 00:23:48.139894 (MainThread): Parsing macros/etc.sql
2020-06-04 00:23:48.141121 (MainThread): Parsing macros/catalog.sql
2020-06-04 00:23:48.150121 (MainThread): Parsing macros/adapters.sql
2020-06-04 00:23:48.173024 (MainThread): Parsing macros/materializations/seed.sql
2020-06-04 00:23:48.175196 (MainThread): Parsing macros/materializations/view.sql
2020-06-04 00:23:48.177043 (MainThread): Parsing macros/materializations/table.sql
2020-06-04 00:23:48.187052 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-04 00:23:48.200001 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-04 00:23:48.219624 (MainThread): Partial parsing not enabled
2020-06-04 00:23:48.220487 (MainThread): Parsing macros/project_macros.sql
2020-06-04 00:23:48.253556 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-04 00:23:48.253687 (MainThread): Opening a new connection, currently in state init
2020-06-04 00:23:48.271391 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-04 00:23:48.271540 (MainThread): Opening a new connection, currently in state closed
2020-06-04 00:23:48.278935 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-04 00:23:48.279079 (MainThread): Opening a new connection, currently in state closed
2020-06-04 00:23:48.286315 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-04 00:23:48.286446 (MainThread): Opening a new connection, currently in state closed
2020-06-04 00:23:48.295044 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_macro".
2020-06-04 00:23:48.295178 (MainThread): Opening a new connection, currently in state closed
2020-06-04 00:23:48.333754 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-04 00:23:48.333900 (MainThread): Opening a new connection, currently in state closed
2020-06-04 00:23:48.343598 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-04 00:23:48.343721 (MainThread): Opening a new connection, currently in state closed
2020-06-04 00:23:48.590451 (MainThread): Found 5 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-04 00:23:48.594732 (MainThread): 
2020-06-04 00:23:48.595278 (MainThread): Acquiring new bigquery connection "master".
2020-06-04 00:23:48.595412 (MainThread): Opening a new connection, currently in state closed
2020-06-04 00:23:48.605343 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-06-04 00:23:48.605574 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-04 00:23:48.608107 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-04 00:23:52.400351 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt".
2020-06-04 00:23:52.400697 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-06-04 00:23:52.400857 (ThreadPoolExecutor-0_0): Creating schema "graham-hamza-bq-dbt-webinar.medicare_provider_2011_analysis_dbt".
2020-06-04 00:23:52.401094 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-04 00:23:53.116085 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-04 00:23:55.198419 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt".
2020-06-04 00:23:55.198803 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly create_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt).
2020-06-04 00:23:55.199036 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-04 00:23:55.709356 (MainThread): 10:23:55 | Concurrency: 1 threads (target='dev')
2020-06-04 00:23:55.709590 (MainThread): 10:23:55 | 
2020-06-04 00:23:55.715875 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-04 00:23:55.716125 (Thread-1): 10:23:55 | 1 of 5 START table model medicare_provider_2011_analysis_dbt.provider_inpatient_charges_2011 [RUN]
2020-06-04 00:23:55.716492 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-04 00:23:55.716601 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt).
2020-06-04 00:23:55.716724 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-04 00:23:55.738012 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-04 00:23:55.738504 (Thread-1): finished collecting timing info
2020-06-04 00:23:55.865688 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-04 00:23:55.866341 (Thread-1): On model.dbt_servian_demo.provider_inpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.provider_inpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
  provider_id as inpatient_provider_id,
  provider_name as inpatient_provider_name,
  provider_city as inpatient_provider_city,
  provider_state as inpatient_provider_state,
  ROUND(SUM(total_discharges),2) as inpatient_sum_total_discharges,
  ROUND(SUM(average_covered_charges),2) as inpatient_sum_average_covered_charges,
  ROUND(SUM(average_total_payments),2) as inpatient_sum_average_total_payments,
  ROUND(SUM(average_medicare_payments),2) as inpatient_average_medicare_payments
FROM
  `bigquery-public-data`.`medicare`.`inpatient_charges_2011`
GROUP BY
  1,
  2,
  3,
  4
  );
    
2020-06-04 00:23:59.594737 (Thread-1): finished collecting timing info
2020-06-04 00:23:59.595703 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65eb6809-021a-4f7d-bcb3-d047abda35c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd63214040>]}
2020-06-04 00:23:59.596085 (Thread-1): 10:23:59 | 1 of 5 OK created table model medicare_provider_2011_analysis_dbt.provider_inpatient_charges_2011 [CREATE TABLE (3337) in 3.88s]
2020-06-04 00:23:59.596273 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-04 00:23:59.596457 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-04 00:23:59.596638 (Thread-1): 10:23:59 | 2 of 5 START table model medicare_provider_2011_analysis_dbt.provider_outpatient_charges_2011 [RUN]
2020-06-04 00:23:59.597230 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-04 00:23:59.597414 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.provider_inpatient_charges_2011).
2020-06-04 00:23:59.597549 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-04 00:23:59.606202 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-04 00:23:59.606648 (Thread-1): finished collecting timing info
2020-06-04 00:23:59.611723 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-04 00:23:59.612200 (Thread-1): On model.dbt_servian_demo.provider_outpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.provider_outpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
  provider_id as outpatient_provider_id,
  provider_name as outpatient_provider_name,
  provider_city as outpatient_provider_city,
  provider_state as outpatient_provider_state,
  ROUND(SUM(outpatient_services),2) as outpatient_sum_outpatient_services,
  ROUND(SUM(average_estimated_submitted_charges),2) as outpatient_sum_average_estimated_submitted_charges,
  ROUND(SUM(average_total_payments),2) as outpatient_sum_average_total_payments
FROM
  `bigquery-public-data`.`medicare`.`outpatient_charges_2011`
GROUP BY
  1,
  2,
  3,
  4
  );
    
2020-06-04 00:24:03.002112 (Thread-1): finished collecting timing info
2020-06-04 00:24:03.002863 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65eb6809-021a-4f7d-bcb3-d047abda35c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd63230700>]}
2020-06-04 00:24:03.003136 (Thread-1): 10:24:03 | 2 of 5 OK created table model medicare_provider_2011_analysis_dbt.provider_outpatient_charges_2011 [CREATE TABLE (3135) in 3.41s]
2020-06-04 00:24:03.003281 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-04 00:24:03.003429 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-04 00:24:03.003775 (Thread-1): 10:24:03 | 3 of 5 START view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_analysis [RUN]
2020-06-04 00:24:03.004066 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-04 00:24:03.004168 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.provider_outpatient_charges_2011).
2020-06-04 00:24:03.004266 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-04 00:24:03.014101 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-04 00:24:03.014575 (Thread-1): finished collecting timing info
2020-06-04 00:24:03.033548 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-04 00:24:03.034052 (Thread-1): On model.dbt_servian_demo.physicians_supplier_2012_analysis: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.physicians_supplier_2012_analysis"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`physicians_supplier_2012_analysis`
  OPTIONS(
      description='This description for physicians_supplier_2012 was generated by dbt'
    )
  as (
     


SELECT
  nppes_provider_city,
 	
 		ROUND(SUM(line_srvc_cnt)) as sum_line_srvc_cnt,
	
 		ROUND(SUM(bene_unique_cnt)) as sum_bene_unique_cnt,
	
 		ROUND(SUM(bene_day_srvc_cnt)) as sum_bene_day_srvc_cnt,
	
 		ROUND(SUM(average_medicare_allowed_amt)) as sum_average_medicare_allowed_amt,
	
 		ROUND(SUM(stdev_medicare_allowed_amt)) as sum_stdev_medicare_allowed_amt,
	
 		ROUND(SUM(average_submitted_chrg_amt)) as sum_average_submitted_chrg_amt,
	
 		ROUND(SUM(stdev_submitted_chrg_amt)) as sum_stdev_submitted_chrg_amt,
	
 		ROUND(SUM(average_medicare_payment_amt)) as sum_average_medicare_payment_amt,
	
 		ROUND(SUM(stdev_medicare_payment_amt)) as sum_stdev_medicare_payment_amt,
	
FROM
  `bigquery-public-data`.`medicare`.`physicians_and_other_supplier_2012`
GROUP BY
  1
  );

2020-06-04 00:24:04.970309 (Thread-1): finished collecting timing info
2020-06-04 00:24:04.971187 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65eb6809-021a-4f7d-bcb3-d047abda35c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd631dee80>]}
2020-06-04 00:24:04.971489 (Thread-1): 10:24:04 | 3 of 5 OK created view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_analysis [CREATE VIEW in 1.97s]
2020-06-04 00:24:04.971648 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-04 00:24:04.971779 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-04 00:24:04.971909 (Thread-1): 10:24:04 | 4 of 5 START view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_macro [RUN]
2020-06-04 00:24:04.972166 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_macro".
2020-06-04 00:24:04.972360 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.physicians_supplier_2012_analysis).
2020-06-04 00:24:04.972489 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-04 00:24:04.981564 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_macro"
2020-06-04 00:24:04.981971 (Thread-1): finished collecting timing info
2020-06-04 00:24:04.986609 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.physicians_supplier_2012_macro"
2020-06-04 00:24:04.987054 (Thread-1): On model.dbt_servian_demo.physicians_supplier_2012_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.physicians_supplier_2012_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`physicians_supplier_2012_macro`
  OPTIONS()
  as (
     


SELECT
 	nppes_provider_city,
	
	
		ROUND(SUM(line_srvc_cnt)) as sum_line_srvc_cnt,
	
		ROUND(SUM(bene_unique_cnt)) as sum_bene_unique_cnt,
	
		ROUND(SUM(bene_day_srvc_cnt)) as sum_bene_day_srvc_cnt,
	
		ROUND(SUM(average_medicare_allowed_amt)) as sum_average_medicare_allowed_amt,
	
		ROUND(SUM(stdev_medicare_allowed_amt)) as sum_stdev_medicare_allowed_amt,
	
		ROUND(SUM(average_submitted_chrg_amt)) as sum_average_submitted_chrg_amt,
	
		ROUND(SUM(stdev_submitted_chrg_amt)) as sum_stdev_submitted_chrg_amt,
	
		ROUND(SUM(average_medicare_payment_amt)) as sum_average_medicare_payment_amt,
	
		ROUND(SUM(stdev_medicare_payment_amt)) as sum_stdev_medicare_payment_amt,
	

FROM
  `bigquery-public-data`.`medicare`.`physicians_and_other_supplier_2012`
GROUP BY
  1
  );

2020-06-04 00:24:07.013360 (Thread-1): finished collecting timing info
2020-06-04 00:24:07.014110 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65eb6809-021a-4f7d-bcb3-d047abda35c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd631fe910>]}
2020-06-04 00:24:07.014388 (Thread-1): 10:24:07 | 4 of 5 OK created view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_macro [CREATE VIEW in 2.04s]
2020-06-04 00:24:07.014539 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-04 00:24:07.014690 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-04 00:24:07.014838 (Thread-1): 10:24:07 | 5 of 5 START table model medicare_provider_2011_analysis_dbt.outpatient_inpatient_charges_2011 [RUN]
2020-06-04 00:24:07.015112 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-04 00:24:07.015218 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.physicians_supplier_2012_macro).
2020-06-04 00:24:07.015322 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-04 00:24:07.024477 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-04 00:24:07.024988 (Thread-1): finished collecting timing info
2020-06-04 00:24:07.030274 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-04 00:24:07.030760 (Thread-1): On model.dbt_servian_demo.outpatient_inpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.outpatient_inpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`outpatient_inpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
	*
FROM
 	`graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011` outpatient
JOIN
	`graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011` inpatient
ON
	outpatient_provider_id = inpatient_provider_id
  );
    
2020-06-04 00:24:10.522925 (Thread-1): finished collecting timing info
2020-06-04 00:24:10.523845 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65eb6809-021a-4f7d-bcb3-d047abda35c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd631dee80>]}
2020-06-04 00:24:10.524120 (Thread-1): 10:24:10 | 5 of 5 OK created table model medicare_provider_2011_analysis_dbt.outpatient_inpatient_charges_2011 [CREATE TABLE (3135) in 3.51s]
2020-06-04 00:24:10.524269 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-04 00:24:10.525589 (MainThread): 10:24:10 | 
2020-06-04 00:24:10.525745 (MainThread): 10:24:10 | Finished running 3 table models, 2 view models in 21.93s.
2020-06-04 00:24:10.525870 (MainThread): Connection 'master' was left open.
2020-06-04 00:24:10.525962 (MainThread): Connection 'model.dbt_servian_demo.outpatient_inpatient_charges_2011' was left open.
2020-06-04 00:24:10.539334 (MainThread): 
2020-06-04 00:24:10.539510 (MainThread): Completed successfully
2020-06-04 00:24:10.539643 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2020-06-04 00:24:10.539857 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd631309a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd63130580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd63130820>]}
2020-06-04 00:24:10.540070 (MainThread): Flushing usage events
2020-06-04 01:48:53.940479 (MainThread): Running with dbt=0.16.1
2020-06-04 01:48:54.636116 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-06-04 01:48:54.637625 (MainThread): Tracking: tracking
2020-06-04 01:48:54.646886 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8baa1969d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8baa1a8700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8baa1a86d0>]}
2020-06-04 01:48:54.672184 (MainThread): Partial parsing not enabled
2020-06-04 01:48:54.675374 (MainThread): Parsing macros/core.sql
2020-06-04 01:48:54.681108 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-04 01:48:54.693074 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-04 01:48:54.695928 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-04 01:48:54.716969 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-04 01:48:54.760327 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-04 01:48:54.787479 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-04 01:48:54.790126 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-04 01:48:54.798021 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-04 01:48:54.815059 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-04 01:48:54.823919 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-04 01:48:54.832181 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-04 01:48:54.838575 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-04 01:48:54.840087 (MainThread): Parsing macros/etc/query.sql
2020-06-04 01:48:54.841624 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-04 01:48:54.843977 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-04 01:48:54.847933 (MainThread): Parsing macros/etc/datetime.sql
2020-06-04 01:48:54.859886 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-04 01:48:54.862422 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-04 01:48:54.864281 (MainThread): Parsing macros/adapters/common.sql
2020-06-04 01:48:54.914070 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-04 01:48:54.915752 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-04 01:48:54.916961 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-04 01:48:54.918454 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-04 01:48:54.921798 (MainThread): Parsing macros/etc.sql
2020-06-04 01:48:54.923076 (MainThread): Parsing macros/catalog.sql
2020-06-04 01:48:54.932462 (MainThread): Parsing macros/adapters.sql
2020-06-04 01:48:54.958374 (MainThread): Parsing macros/materializations/seed.sql
2020-06-04 01:48:54.960796 (MainThread): Parsing macros/materializations/view.sql
2020-06-04 01:48:54.963050 (MainThread): Parsing macros/materializations/table.sql
2020-06-04 01:48:54.975796 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-04 01:48:54.991119 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-04 01:48:55.013626 (MainThread): Partial parsing not enabled
2020-06-04 01:48:55.014609 (MainThread): Parsing macros/project_macros.sql
2020-06-04 01:48:55.052493 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-04 01:48:55.052643 (MainThread): Opening a new connection, currently in state init
2020-06-04 01:48:55.071166 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-04 01:48:55.071300 (MainThread): Opening a new connection, currently in state closed
2020-06-04 01:48:55.077981 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-04 01:48:55.078106 (MainThread): Opening a new connection, currently in state closed
2020-06-04 01:48:55.085305 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-04 01:48:55.085426 (MainThread): Opening a new connection, currently in state closed
2020-06-04 01:48:55.095408 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_macro".
2020-06-04 01:48:55.095540 (MainThread): Opening a new connection, currently in state closed
2020-06-04 01:48:55.137465 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-04 01:48:55.137617 (MainThread): Opening a new connection, currently in state closed
2020-06-04 01:48:55.147674 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-04 01:48:55.147815 (MainThread): Opening a new connection, currently in state closed
2020-06-04 01:48:55.431310 (MainThread): Found 5 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-04 01:48:55.436381 (MainThread): 
2020-06-04 01:48:55.436736 (MainThread): Acquiring new bigquery connection "master".
2020-06-04 01:48:55.436830 (MainThread): Opening a new connection, currently in state closed
2020-06-04 01:48:55.446512 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar".
2020-06-04 01:48:55.446735 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-04 01:48:55.449188 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-04 01:48:57.683327 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt".
2020-06-04 01:48:57.683611 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar).
2020-06-04 01:48:57.683739 (ThreadPoolExecutor-0_0): Creating schema "graham-hamza-bq-dbt-webinar.medicare_provider_2011_analysis_dbt".
2020-06-04 01:48:57.683933 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-04 01:48:58.577957 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-04 01:49:00.007436 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt".
2020-06-04 01:49:00.007760 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly create_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt).
2020-06-04 01:49:00.007942 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-06-04 01:49:00.520768 (MainThread): 11:49:00 | Concurrency: 1 threads (target='dev')
2020-06-04 01:49:00.521028 (MainThread): 11:49:00 | 
2020-06-04 01:49:00.528195 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-04 01:49:00.528515 (Thread-1): 11:49:00 | 1 of 5 START table model medicare_provider_2011_analysis_dbt.provider_inpatient_charges_2011 [RUN]
2020-06-04 01:49:00.529011 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-04 01:49:00.529124 (Thread-1): Re-using an available connection from the pool (formerly list_graham-hamza-bq-dbt-webinar_medicare_provider_2011_analysis_dbt).
2020-06-04 01:49:00.529255 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-04 01:49:00.551603 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-04 01:49:00.552137 (Thread-1): finished collecting timing info
2020-06-04 01:49:00.701574 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-04 01:49:00.702081 (Thread-1): On model.dbt_servian_demo.provider_inpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.provider_inpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
  provider_id as inpatient_provider_id,
  provider_name as inpatient_provider_name,
  provider_city as inpatient_provider_city,
  provider_state as inpatient_provider_state,
  ROUND(SUM(total_discharges),2) as inpatient_sum_total_discharges,
  ROUND(SUM(average_covered_charges),2) as inpatient_sum_average_covered_charges,
  ROUND(SUM(average_total_payments),2) as inpatient_sum_average_total_payments,
  ROUND(SUM(average_medicare_payments),2) as inpatient_average_medicare_payments
FROM
  `bigquery-public-data`.`medicare`.`inpatient_charges_2011`
GROUP BY
  1,
  2,
  3,
  4
  );
    
2020-06-04 01:49:04.508792 (Thread-1): finished collecting timing info
2020-06-04 01:49:04.509528 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a96740ee-62ca-4c0e-8719-eab28bc76b0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8baa26a1c0>]}
2020-06-04 01:49:04.509826 (Thread-1): 11:49:04 | 1 of 5 OK created table model medicare_provider_2011_analysis_dbt.provider_inpatient_charges_2011 [CREATE TABLE (3337) in 3.98s]
2020-06-04 01:49:04.509972 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-04 01:49:04.510111 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-04 01:49:04.510363 (Thread-1): 11:49:04 | 2 of 5 START table model medicare_provider_2011_analysis_dbt.provider_outpatient_charges_2011 [RUN]
2020-06-04 01:49:04.510655 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-04 01:49:04.510753 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.provider_inpatient_charges_2011).
2020-06-04 01:49:04.510850 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-04 01:49:04.519665 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-04 01:49:04.520120 (Thread-1): finished collecting timing info
2020-06-04 01:49:04.525328 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-04 01:49:04.525774 (Thread-1): On model.dbt_servian_demo.provider_outpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.provider_outpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
  provider_id as outpatient_provider_id,
  provider_name as outpatient_provider_name,
  provider_city as outpatient_provider_city,
  provider_state as outpatient_provider_state,
  ROUND(SUM(outpatient_services),2) as outpatient_sum_outpatient_services,
  ROUND(SUM(average_estimated_submitted_charges),2) as outpatient_sum_average_estimated_submitted_charges,
  ROUND(SUM(average_total_payments),2) as outpatient_sum_average_total_payments
FROM
  `bigquery-public-data`.`medicare`.`outpatient_charges_2011`
GROUP BY
  1,
  2,
  3,
  4
  );
    
2020-06-04 01:49:07.618889 (Thread-1): finished collecting timing info
2020-06-04 01:49:07.619651 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a96740ee-62ca-4c0e-8719-eab28bc76b0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8baa34c340>]}
2020-06-04 01:49:07.619930 (Thread-1): 11:49:07 | 2 of 5 OK created table model medicare_provider_2011_analysis_dbt.provider_outpatient_charges_2011 [CREATE TABLE (3135) in 3.11s]
2020-06-04 01:49:07.620076 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-04 01:49:07.620224 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-04 01:49:07.620553 (Thread-1): 11:49:07 | 3 of 5 START view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_analysis [RUN]
2020-06-04 01:49:07.620857 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-04 01:49:07.620961 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.provider_outpatient_charges_2011).
2020-06-04 01:49:07.621062 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-04 01:49:07.631973 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-04 01:49:07.632482 (Thread-1): finished collecting timing info
2020-06-04 01:49:07.652771 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-04 01:49:07.653288 (Thread-1): On model.dbt_servian_demo.physicians_supplier_2012_analysis: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.physicians_supplier_2012_analysis"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`physicians_supplier_2012_analysis`
  OPTIONS(
      description='This description for physicians_supplier_2012 was generated by dbt'
    )
  as (
     



SELECT
  nppes_provider_city,
 	
 		ROUND(SUM(line_srvc_cnt)) as sum_line_srvc_cnt,
	
 		ROUND(SUM(bene_unique_cnt)) as sum_bene_unique_cnt,
	
 		ROUND(SUM(bene_day_srvc_cnt)) as sum_bene_day_srvc_cnt,
	
 		ROUND(SUM(average_medicare_allowed_amt)) as sum_average_medicare_allowed_amt,
	
 		ROUND(SUM(stdev_medicare_allowed_amt)) as sum_stdev_medicare_allowed_amt,
	
 		ROUND(SUM(average_submitted_chrg_amt)) as sum_average_submitted_chrg_amt,
	
 		ROUND(SUM(stdev_submitted_chrg_amt)) as sum_stdev_submitted_chrg_amt,
	
 		ROUND(SUM(average_medicare_payment_amt)) as sum_average_medicare_payment_amt,
	
 		ROUND(SUM(stdev_medicare_payment_amt)) as sum_stdev_medicare_payment_amt,
	
FROM
  `bigquery-public-data`.`medicare`.`physicians_and_other_supplier_2012`
GROUP BY
  1
  );

2020-06-04 01:49:09.428535 (Thread-1): finished collecting timing info
2020-06-04 01:49:09.429307 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a96740ee-62ca-4c0e-8719-eab28bc76b0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8baa3dc280>]}
2020-06-04 01:49:09.429572 (Thread-1): 11:49:09 | 3 of 5 OK created view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_analysis [CREATE VIEW in 1.81s]
2020-06-04 01:49:09.429714 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-04 01:49:09.429854 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-04 01:49:09.429991 (Thread-1): 11:49:09 | 4 of 5 START view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_macro [RUN]
2020-06-04 01:49:09.430361 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_macro".
2020-06-04 01:49:09.430471 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.physicians_supplier_2012_analysis).
2020-06-04 01:49:09.430568 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-04 01:49:09.439858 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_macro"
2020-06-04 01:49:09.440313 (Thread-1): finished collecting timing info
2020-06-04 01:49:09.445042 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.physicians_supplier_2012_macro"
2020-06-04 01:49:09.445476 (Thread-1): On model.dbt_servian_demo.physicians_supplier_2012_macro: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.physicians_supplier_2012_macro"} */


  create or replace view `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`physicians_supplier_2012_macro`
  OPTIONS()
  as (
     


SELECT
 	nppes_provider_city,
	
	
		ROUND(SUM(line_srvc_cnt)) as sum_line_srvc_cnt,
	
		ROUND(SUM(bene_unique_cnt)) as sum_bene_unique_cnt,
	
		ROUND(SUM(bene_day_srvc_cnt)) as sum_bene_day_srvc_cnt,
	
		ROUND(SUM(average_medicare_allowed_amt)) as sum_average_medicare_allowed_amt,
	
		ROUND(SUM(stdev_medicare_allowed_amt)) as sum_stdev_medicare_allowed_amt,
	
		ROUND(SUM(average_submitted_chrg_amt)) as sum_average_submitted_chrg_amt,
	
		ROUND(SUM(stdev_submitted_chrg_amt)) as sum_stdev_submitted_chrg_amt,
	
		ROUND(SUM(average_medicare_payment_amt)) as sum_average_medicare_payment_amt,
	
		ROUND(SUM(stdev_medicare_payment_amt)) as sum_stdev_medicare_payment_amt,
	

FROM
  `bigquery-public-data`.`medicare`.`physicians_and_other_supplier_2012`
GROUP BY
  1
  );

2020-06-04 01:49:11.228647 (Thread-1): finished collecting timing info
2020-06-04 01:49:11.229402 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a96740ee-62ca-4c0e-8719-eab28bc76b0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8baa2e0850>]}
2020-06-04 01:49:11.229680 (Thread-1): 11:49:11 | 4 of 5 OK created view model medicare_provider_2011_analysis_dbt.physicians_supplier_2012_macro [CREATE VIEW in 1.80s]
2020-06-04 01:49:11.229829 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-04 01:49:11.229979 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-04 01:49:11.230126 (Thread-1): 11:49:11 | 5 of 5 START table model medicare_provider_2011_analysis_dbt.outpatient_inpatient_charges_2011 [RUN]
2020-06-04 01:49:11.230520 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-04 01:49:11.230638 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_servian_demo.physicians_supplier_2012_macro).
2020-06-04 01:49:11.230742 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-04 01:49:11.239689 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-04 01:49:11.240738 (Thread-1): finished collecting timing info
2020-06-04 01:49:11.246201 (Thread-1): Writing runtime SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-04 01:49:11.246688 (Thread-1): On model.dbt_servian_demo.outpatient_inpatient_charges_2011: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "node_id": "model.dbt_servian_demo.outpatient_inpatient_charges_2011"} */


  create or replace table `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`outpatient_inpatient_charges_2011`
  
  
  OPTIONS()
  as (
    SELECT
	*
FROM
 	`graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_inpatient_charges_2011` outpatient
JOIN
	`graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.`provider_outpatient_charges_2011` inpatient
ON
	outpatient_provider_id = inpatient_provider_id
  );
    
2020-06-04 01:49:14.617641 (Thread-1): finished collecting timing info
2020-06-04 01:49:14.618423 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a96740ee-62ca-4c0e-8719-eab28bc76b0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8baa3dc040>]}
2020-06-04 01:49:14.618741 (Thread-1): 11:49:14 | 5 of 5 OK created table model medicare_provider_2011_analysis_dbt.outpatient_inpatient_charges_2011 [CREATE TABLE (3135) in 3.39s]
2020-06-04 01:49:14.618901 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-04 01:49:14.620384 (MainThread): 11:49:14 | 
2020-06-04 01:49:14.620563 (MainThread): 11:49:14 | Finished running 3 table models, 2 view models in 19.18s.
2020-06-04 01:49:14.620689 (MainThread): Connection 'master' was left open.
2020-06-04 01:49:14.620790 (MainThread): Connection 'model.dbt_servian_demo.outpatient_inpatient_charges_2011' was left open.
2020-06-04 01:49:14.634150 (MainThread): 
2020-06-04 01:49:14.634436 (MainThread): Completed successfully
2020-06-04 01:49:14.634598 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2020-06-04 01:49:14.634840 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8baa4664c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8baa32ebe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8baa32eb50>]}
2020-06-04 01:49:14.635069 (MainThread): Flushing usage events
2020-06-04 01:56:17.233100 (MainThread): Running with dbt=0.16.1
2020-06-04 01:56:17.688388 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2020-06-04 01:56:17.689559 (MainThread): Tracking: tracking
2020-06-04 01:56:17.695912 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0cd175430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0cd186790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0cd186760>]}
2020-06-04 01:56:17.723559 (MainThread): Partial parsing not enabled
2020-06-04 01:56:17.725622 (MainThread): Parsing macros/core.sql
2020-06-04 01:56:17.731043 (MainThread): Parsing macros/materializations/helpers.sql
2020-06-04 01:56:17.741826 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-06-04 01:56:17.743921 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-06-04 01:56:17.763811 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-06-04 01:56:17.804789 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-06-04 01:56:17.829262 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-06-04 01:56:17.832461 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-06-04 01:56:17.839543 (MainThread): Parsing macros/materializations/common/merge.sql
2020-06-04 01:56:17.855317 (MainThread): Parsing macros/materializations/table/table.sql
2020-06-04 01:56:17.863675 (MainThread): Parsing macros/materializations/view/view.sql
2020-06-04 01:56:17.870969 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-06-04 01:56:17.877082 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-06-04 01:56:17.878256 (MainThread): Parsing macros/etc/query.sql
2020-06-04 01:56:17.879474 (MainThread): Parsing macros/etc/is_incremental.sql
2020-06-04 01:56:17.881242 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-06-04 01:56:17.885097 (MainThread): Parsing macros/etc/datetime.sql
2020-06-04 01:56:17.895788 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-06-04 01:56:17.898199 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-06-04 01:56:17.899411 (MainThread): Parsing macros/adapters/common.sql
2020-06-04 01:56:17.948470 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-06-04 01:56:17.949890 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-06-04 01:56:17.950906 (MainThread): Parsing macros/schema_tests/unique.sql
2020-06-04 01:56:17.952064 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-06-04 01:56:17.954522 (MainThread): Parsing macros/etc.sql
2020-06-04 01:56:17.955331 (MainThread): Parsing macros/catalog.sql
2020-06-04 01:56:17.964488 (MainThread): Parsing macros/adapters.sql
2020-06-04 01:56:17.990701 (MainThread): Parsing macros/materializations/seed.sql
2020-06-04 01:56:17.993143 (MainThread): Parsing macros/materializations/view.sql
2020-06-04 01:56:17.994909 (MainThread): Parsing macros/materializations/table.sql
2020-06-04 01:56:18.007345 (MainThread): Parsing macros/materializations/incremental.sql
2020-06-04 01:56:18.022352 (MainThread): Parsing macros/materializations/snapshot.sql
2020-06-04 01:56:18.045849 (MainThread): Partial parsing not enabled
2020-06-04 01:56:18.046259 (MainThread): Parsing macros/project_macros.sql
2020-06-04 01:56:18.083408 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-04 01:56:18.083625 (MainThread): Opening a new connection, currently in state init
2020-06-04 01:56:18.102057 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-04 01:56:18.102232 (MainThread): Opening a new connection, currently in state closed
2020-06-04 01:56:18.110796 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-04 01:56:18.110935 (MainThread): Opening a new connection, currently in state closed
2020-06-04 01:56:18.119253 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-04 01:56:18.119399 (MainThread): Opening a new connection, currently in state closed
2020-06-04 01:56:18.128412 (MainThread): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_macro".
2020-06-04 01:56:18.128590 (MainThread): Opening a new connection, currently in state closed
2020-06-04 01:56:18.171667 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-04 01:56:18.171830 (MainThread): Opening a new connection, currently in state closed
2020-06-04 01:56:18.182849 (MainThread): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-04 01:56:18.183035 (MainThread): Opening a new connection, currently in state closed
2020-06-04 01:56:18.462341 (MainThread): Found 5 models, 2 tests, 0 snapshots, 0 analyses, 142 macros, 0 operations, 0 seed files, 3 sources
2020-06-04 01:56:18.467697 (MainThread): 
2020-06-04 01:56:18.467913 (MainThread): 11:56:18 | Concurrency: 1 threads (target='dev')
2020-06-04 01:56:18.468024 (MainThread): 11:56:18 | 
2020-06-04 01:56:18.470702 (Thread-1): Began running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-04 01:56:18.471031 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_inpatient_charges_2011".
2020-06-04 01:56:18.471131 (Thread-1): Opening a new connection, currently in state init
2020-06-04 01:56:18.471223 (Thread-1): Compiling model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-04 01:56:18.489720 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_inpatient_charges_2011"
2020-06-04 01:56:18.490147 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.490407 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.490796 (Thread-1): Finished running node model.dbt_servian_demo.provider_inpatient_charges_2011
2020-06-04 01:56:18.490925 (Thread-1): Began running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-04 01:56:18.491158 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.provider_outpatient_charges_2011".
2020-06-04 01:56:18.491247 (Thread-1): Opening a new connection, currently in state closed
2020-06-04 01:56:18.491333 (Thread-1): Compiling model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-04 01:56:18.498698 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.provider_outpatient_charges_2011"
2020-06-04 01:56:18.499213 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.499457 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.499836 (Thread-1): Finished running node model.dbt_servian_demo.provider_outpatient_charges_2011
2020-06-04 01:56:18.499960 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-04 01:56:18.500189 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_analysis".
2020-06-04 01:56:18.500278 (Thread-1): Opening a new connection, currently in state closed
2020-06-04 01:56:18.500482 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-04 01:56:18.510028 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_analysis"
2020-06-04 01:56:18.510448 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.510689 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.511069 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_analysis
2020-06-04 01:56:18.511196 (Thread-1): Began running node model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-04 01:56:18.511430 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.physicians_supplier_2012_macro".
2020-06-04 01:56:18.511519 (Thread-1): Opening a new connection, currently in state closed
2020-06-04 01:56:18.511605 (Thread-1): Compiling model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-04 01:56:18.520318 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.physicians_supplier_2012_macro"
2020-06-04 01:56:18.520777 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.521134 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.521750 (Thread-1): Finished running node model.dbt_servian_demo.physicians_supplier_2012_macro
2020-06-04 01:56:18.522006 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-04 01:56:18.522557 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id".
2020-06-04 01:56:18.522670 (Thread-1): Opening a new connection, currently in state closed
2020-06-04 01:56:18.522766 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-04 01:56:18.538120 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id"
2020-06-04 01:56:18.539433 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.539701 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.540101 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id
2020-06-04 01:56:18.540239 (Thread-1): Began running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-04 01:56:18.540485 (Thread-1): Acquiring new bigquery connection "model.dbt_servian_demo.outpatient_inpatient_charges_2011".
2020-06-04 01:56:18.540647 (Thread-1): Opening a new connection, currently in state closed
2020-06-04 01:56:18.540759 (Thread-1): Compiling model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-04 01:56:18.548855 (Thread-1): Writing injected SQL for node "model.dbt_servian_demo.outpatient_inpatient_charges_2011"
2020-06-04 01:56:18.549264 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.549495 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.549861 (Thread-1): Finished running node model.dbt_servian_demo.outpatient_inpatient_charges_2011
2020-06-04 01:56:18.549987 (Thread-1): Began running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-04 01:56:18.550219 (Thread-1): Acquiring new bigquery connection "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id".
2020-06-04 01:56:18.550307 (Thread-1): Opening a new connection, currently in state closed
2020-06-04 01:56:18.550391 (Thread-1): Compiling test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-04 01:56:18.558136 (Thread-1): Writing injected SQL for node "test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id"
2020-06-04 01:56:18.558501 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.558733 (Thread-1): finished collecting timing info
2020-06-04 01:56:18.559095 (Thread-1): Finished running node test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id
2020-06-04 01:56:18.559885 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_inpatient_charges_2011_inpatient_provider_id' was properly closed.
2020-06-04 01:56:18.559988 (MainThread): Connection 'test.dbt_servian_demo.not_null_provider_outpatient_charges_2011_outpatient_provider_id' was properly closed.
2020-06-04 01:56:18.577053 (MainThread): 11:56:18 | Done.
2020-06-04 01:56:18.580112 (MainThread): Acquiring new bigquery connection "generate_catalog".
2020-06-04 01:56:18.580319 (MainThread): Opening a new connection, currently in state init
2020-06-04 01:56:18.580423 (MainThread): 11:56:18 | Building catalog
2020-06-04 01:56:18.600075 (MainThread): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-04 01:56:21.205117 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "graham-hamza-bq-dbt-webinar.information_schema".
2020-06-04 01:56:21.205444 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-06-04 01:56:21.292196 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a "quota exceeded" or "API not enabled" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-06-04 01:56:21.927030 (ThreadPoolExecutor-0_0): On graham-hamza-bq-dbt-webinar.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "graham-hamza-bq-dbt-webinar.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `graham-hamza-bq-dbt-webinar`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('medicare_provider_2011_analysis_dbt'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `graham-hamza-bq-dbt-webinar`.`medicare_provider_2011_analysis_dbt`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-04 01:56:26.258027 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "bigquery-public-data.information_schema".
2020-06-04 01:56:26.258300 (ThreadPoolExecutor-0_0): Re-using an available connection from the pool (formerly graham-hamza-bq-dbt-webinar.information_schema).
2020-06-04 01:56:26.260894 (ThreadPoolExecutor-0_0): On bigquery-public-data.information_schema: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt-servian-demo", "target_name": "dev", "connection_name": "bigquery-public-data.information_schema"} */

    with schemas as (

        select
          catalog_name as table_database,
          schema_name as table_schema,
          location

        from `bigquery-public-data`.INFORMATION_SCHEMA.SCHEMATA
        where (upper(schema_name) = upper('medicare'))
    ),

    tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bigquery-public-data`.`medicare`.__TABLES__

    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,
            cast(null as string) as column_comment,

            is_partitioning_column,
            clustering_ordinal_position

        from `bigquery-public-data`.`medicare`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name

        from `bigquery-public-data`.`medicare`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
        where data_type not like 'STRUCT%'

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Location' as `stats__location__label`,
        location as `stats__location__value`,
        'The geographic location of this table' as `stats__location__description`,
        location is not null as `stats__location__include`,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join schemas using(table_database, table_schema)
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-06-04 01:56:26.940246 (ThreadPoolExecutor-0_0): Unhandled error while running:
macro get_catalog
2020-06-04 01:56:26.940437 (ThreadPoolExecutor-0_0): Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-04 01:56:26.940916 (MainThread): Encountered an error while generating catalog: Database Error
  Access Denied: Table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA: User does not have permission to query table bigquery-public-data:INFORMATION_SCHEMA.SCHEMATA.
2020-06-04 01:56:27.049740 (MainThread): dbt encountered 1 failure while writing the catalog
2020-06-04 01:56:27.050030 (MainThread): 11:56:27 | Catalog written to /Users/hamzakhan/Desktop/Work/Servian/dbt-demo/dbt-demo-servian/target/catalog.json
2020-06-04 01:56:27.050328 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0cd175430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0cd4562b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0cd24eca0>]}
2020-06-04 01:56:27.050589 (MainThread): Flushing usage events
2020-06-04 01:56:27.996768 (MainThread): Connection 'generate_catalog' was left open.
2020-06-04 01:56:27.996988 (MainThread): Connection 'bigquery-public-data.information_schema' was left open.
2020-06-04 01:56:33.218426 (MainThread): Running with dbt=0.16.1
2020-06-04 01:56:33.671862 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, port=8001, profile=None, profiles_dir='/Users/hamzakhan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='serve', write_json=True)
2020-06-04 01:56:33.672756 (MainThread): Tracking: tracking
2020-06-04 01:56:33.678964 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa35d198700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa35d1a9700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa35d1a96d0>]}
2020-06-04 01:56:33.680852 (MainThread): Serving docs at 0.0.0.0:8001
2020-06-04 01:56:33.681031 (MainThread): To access from your browser, navigate to:  http://localhost:8001
2020-06-04 01:56:33.681126 (MainThread): Press Ctrl+C to exit.


2020-06-04 02:34:02.269973 (MainThread): Flushing usage events
2020-06-04 02:34:02.965450 (MainThread): ctrl-c
2020-06-04 02:34:02.965926 (MainThread): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.105', 55646), raddr=('52.0.42.206', 443)>
